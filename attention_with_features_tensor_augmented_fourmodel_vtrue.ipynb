{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Gerekli Kütüphaneler ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import DenseNet201, MobileNetV3Large\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, auc\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Sabitler ===\n",
    "EP = 100\n",
    "k  = 50\n",
    "num_outer_folds = 5\n",
    "num_inner_folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Veri Yükleme ===\n",
    "datadir = r\"C:\\Users\\Gokalp\\Desktop\\BOS 2 seviye Hastalar ve Normaller\\DS_DL_2\\CSV\\dataset_VS_T2.xlsx\"\n",
    "df = pd.read_excel(datadir)\n",
    "radiomics_cols   = [c for c in df.columns if c.startswith(\"feat\")]\n",
    "X_radiomics_all  = df[radiomics_cols].values.astype(np.float32)\n",
    "y_all            = df[\"label\"].values.astype(int)\n",
    "patient_ids_all  = df[\"patient_id\"].values\n",
    "img_paths_all    = df[\"image_path\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Radiomics Ön İşleme ===\n",
    "def radiomics_preprocessing(X_train, y_train, X_val=None, k=k):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train)\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    X_train_sel = selector.fit_transform(X_train_sc, y_train)\n",
    "    X_val_sel = None\n",
    "    if X_val is not None:\n",
    "        X_val_sc = scaler.transform(X_val)\n",
    "        X_val_sel = selector.transform(X_val_sc)\n",
    "    return X_train_sel, X_val_sel, scaler, selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Augmentasyon Katmanları ===\n",
    "# train_augs = Sequential([\n",
    "#     layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#     layers.RandomRotation(0.2),\n",
    "#     layers.RandomZoom(0.1),\n",
    "# ])\n",
    "train_augs = Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.3),\n",
    "    layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomBrightness(factor=0.2),\n",
    "    layers.RandomTranslation(0.1, 0.1),\n",
    "], name=\"train_augmentation\")\n",
    "\n",
    "val_augs = Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Augmented Dataset Fonksiyonu ===\n",
    "def create_augmented_dataset(img_paths, rad_features, labels, batch_size=8, shuffle=True, augmentation=None, n_augs=1):\n",
    "    def gen():\n",
    "        for i in range(len(img_paths)):\n",
    "            img = plt.imread(img_paths[i])\n",
    "            if img.ndim == 2:\n",
    "                img = np.stack([img]*3, axis=-1)\n",
    "            img = tf.image.resize(img, [224,224])\n",
    "            img = preprocess_input(img)\n",
    "            rad = rad_features[i].astype(np.float32)\n",
    "            label = labels[i]\n",
    "            yield (img, rad), label\n",
    "            if augmentation:\n",
    "                for _ in range(n_augs):\n",
    "                    yield (augmentation(img), rad), label\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_types=((tf.float32, tf.float32), tf.int32),\n",
    "        output_shapes=(((224,224,3), (rad_features.shape[1],)), ())\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(img_paths)*(n_augs+1))\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_dataset_single_input(img_paths, labels, batch_size=8, shuffle=True, augmentation=None, n_augs=1):\n",
    "    def gen():\n",
    "        for i in range(len(img_paths)):\n",
    "            img = plt.imread(img_paths[i])\n",
    "            if img.ndim == 2:\n",
    "                img = np.stack([img]*3, axis=-1)\n",
    "            img = tf.image.resize(img, [224,224])\n",
    "            img = preprocess_input(img)\n",
    "            label = labels[i]\n",
    "            yield img, label\n",
    "            if augmentation:\n",
    "                for _ in range(n_augs):\n",
    "                    yield augmentation(img), label\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_types=(tf.float32, tf.int32),\n",
    "        output_shapes=((224,224,3), ())\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(img_paths)*(n_augs+1))\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ASPP Blok ===\n",
    "class ASPP(layers.Layer):\n",
    "    def __init__(self, filters, dilations=[1,6,12,18], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.convs = [layers.Conv2D(filters, 3, dilation_rate=d, padding='same', use_bias=False) for d in dilations]\n",
    "        self.bns   = [layers.BatchNormalization() for _ in dilations]\n",
    "        self.global_pool_conv = layers.Conv2D(filters, 1, use_bias=False)\n",
    "        self.global_pool_bn = layers.BatchNormalization()\n",
    "        self.out_conv = layers.Conv2D(filters, 1, use_bias=False)\n",
    "        self.out_bn = layers.BatchNormalization()\n",
    "        self.relu = layers.ReLU()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        pooled = [self.relu(bn(conv(x), training=training)) for conv, bn in zip(self.convs, self.bns)]\n",
    "        gp = tf.reduce_mean(x, axis=[1,2], keepdims=True)\n",
    "        gp = self.relu(self.global_pool_bn(self.global_pool_conv(gp), training=training))\n",
    "        gp = tf.image.resize(gp, (x.shape[1], x.shape[2]))\n",
    "        pooled.append(gp)\n",
    "        y = tf.concat(pooled, axis=-1)\n",
    "        y = self.relu(self.out_bn(self.out_conv(y), training=training))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Freeze Fonksiyonları ===\n",
    "def freeze_densenet(model):\n",
    "    for layer in model.base_densenet.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "def unfreeze_densenet(model, trainable_ratio=0.3):\n",
    "    total = len(model.base_densenet.layers)\n",
    "    for i, layer in enumerate(model.base_densenet.layers):\n",
    "        layer.trainable = (i >= total - int(trainable_ratio * total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Tanımları ===\n",
    "def build_densenet_aspp_attention_fusion(num_radiomics, num_classes=2):\n",
    "    image_input = keras.Input((224,224,3))\n",
    "    rad_input = keras.Input((num_radiomics,))\n",
    "    base = DenseNet201(include_top=False, weights='imagenet', input_tensor=image_input)\n",
    "    feat_map = base.output\n",
    "    a1 = layers.Dense(512, activation='relu')(rad_input)\n",
    "    a2 = layers.Dense(1920, activation='sigmoid')(a1)\n",
    "    attn = layers.Reshape((1,1,1920))(a2)\n",
    "    feat_att = layers.multiply([feat_map, attn])\n",
    "    x = ASPP(512)(feat_att)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    r = layers.Dense(128, activation='relu')(rad_input)\n",
    "    r = layers.Dropout(0.3)(r)\n",
    "    concat = layers.Concatenate()([x, r])\n",
    "    x = layers.Dense(256, activation='relu')(concat)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model([image_input, rad_input], out)\n",
    "    model.base_densenet = base\n",
    "    return model\n",
    "\n",
    "# def build_densenet_standard(num_radiomics, num_classes=2):\n",
    "# # def build_densenet_standard(num_classes=2):\n",
    "#     image_input = keras.Input((224,224,3))\n",
    "#     # rad_input = keras.Input((num_radiomics,))\n",
    "#     base = DenseNet201(include_top=False, weights='imagenet', input_tensor=image_input)\n",
    "#     x = base.output\n",
    "#     # x = ASPP(512)(x)\n",
    "#     x = layers.GlobalAveragePooling2D()(x)\n",
    "#     # r = layers.Dense(128, activation='relu')(rad_input)\n",
    "#     # r = layers.Dropout(0.3)(r)\n",
    "#     # concat = layers.Concatenate()([x, r])\n",
    "#     x = layers.Dense(256, activation='relu')(x)\n",
    "#     x = layers.Dropout(0.3)(x)\n",
    "#     out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "#     model = Model([image_input], out)\n",
    "#     model.base_densenet = base\n",
    "#     return model\n",
    "def build_densenet_standard(num_radiomics, num_classes=2):\n",
    "    image_input = keras.Input((224,224,3))\n",
    "    base = DenseNet201(include_top=False, weights='imagenet', input_tensor=image_input)\n",
    "    x = base.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)  # Global Pooling eklendi\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model([image_input], out)\n",
    "    model.base_densenet = base\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_mobilenet_aspp_attention_fusion(num_radiomics, num_classes=2):\n",
    "    image_input = keras.Input((224, 224, 3))\n",
    "    rad_input = keras.Input((num_radiomics,))\n",
    "    base = MobileNetV3Large(include_top=False, weights='imagenet', input_tensor=image_input)\n",
    "    feat_map = base.output\n",
    "    a1 = layers.Dense(256, activation='relu')(rad_input)\n",
    "    a2 = layers.Dense(960, activation='sigmoid')(a1)\n",
    "    attn = layers.Reshape((1, 1, 960))(a2)\n",
    "    feat_att = layers.multiply([feat_map, attn])\n",
    "    x = ASPP(256)(feat_att)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    r = layers.Dense(128, activation='relu')(rad_input)\n",
    "    r = layers.Dropout(0.3)(r)\n",
    "    concat = layers.Concatenate()([x, r])\n",
    "    x = layers.Dense(256, activation='relu')(concat)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model([image_input, rad_input], out)\n",
    "    model.base_densenet = base\n",
    "    return model\n",
    "\n",
    "# def build_mobilenet_standard(num_radiomics, num_classes=2):\n",
    "# # def build_mobilenet_standard(num_classes=2):\n",
    "#     image_input = keras.Input((224, 224, 3))\n",
    "#     # rad_input = keras.Input((num_radiomics,))\n",
    "#     base = MobileNetV3Large(include_top=False, weights='imagenet', input_tensor=image_input)\n",
    "#     x = base.output\n",
    "#     # x = ASPP(256)(x)\n",
    "#     x = layers.GlobalAveragePooling2D()(x)\n",
    "#     # r = layers.Dense(128, activation='relu')(rad_input)\n",
    "#     # r = layers.Dropout(0.3)(r)\n",
    "#     # concat = layers.Concatenate()([x, r])\n",
    "#     x = layers.Dense(256, activation='relu')(x)\n",
    "#     x = layers.Dropout(0.3)(x)\n",
    "#     out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "#     model = Model([image_input], out)\n",
    "#     model.base_densenet = base\n",
    "#     return model\n",
    "def build_mobilenet_standard(num_radiomics, num_classes=2):\n",
    "    image_input = keras.Input((224,224,3))\n",
    "    base = MobileNetV3Large(include_top=False, weights='imagenet', input_tensor=image_input)\n",
    "    x = base.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)  # Global Pooling eklendi\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model([image_input], out)\n",
    "    model.base_densenet = base\n",
    "    return model\n",
    "\n",
    "# === Model Builder Sözlüğü ===\n",
    "model_builders = {\n",
    "    'std_densenet': build_densenet_standard,\n",
    "    'std_mobilenet': build_mobilenet_standard,\n",
    "    'att_densenet': build_densenet_aspp_attention_fusion,\n",
    "    'att_mobilenet': build_mobilenet_aspp_attention_fusion,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Outer Fold 1 | Model: std_densenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 32s 134ms/step - loss: 0.6954 - accuracy: 0.5636 - val_loss: 0.6059 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.6883 - accuracy: 0.5473 - val_loss: 0.6208 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.6678 - accuracy: 0.5491 - val_loss: 0.5547 - val_accuracy: 0.7768 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.6577 - accuracy: 0.5836 - val_loss: 0.5691 - val_accuracy: 0.7679 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.6497 - accuracy: 0.5673 - val_loss: 0.5275 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.6296 - accuracy: 0.6000 - val_loss: 0.5353 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 16s 60ms/step - loss: 0.6086 - accuracy: 0.6327 - val_loss: 0.5323 - val_accuracy: 0.7321 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 60ms/step - loss: 0.6151 - accuracy: 0.6055 - val_loss: 0.5087 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.6167 - accuracy: 0.6127 - val_loss: 0.5507 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 15s 58ms/step - loss: 0.5964 - accuracy: 0.6273 - val_loss: 0.5575 - val_accuracy: 0.7232 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 15s 58ms/step - loss: 0.5980 - accuracy: 0.6182 - val_loss: 0.5570 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5861 - accuracy: 0.6345 - val_loss: 0.5550 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5821 - accuracy: 0.6327 - val_loss: 0.5212 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5832 - accuracy: 0.6273 - val_loss: 0.5650 - val_accuracy: 0.7232 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 15s 58ms/step - loss: 0.5787 - accuracy: 0.6200 - val_loss: 0.5225 - val_accuracy: 0.6696 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5796 - accuracy: 0.6382 - val_loss: 0.5479 - val_accuracy: 0.6607 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5579 - accuracy: 0.6564 - val_loss: 0.5527 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 16s 61ms/step - loss: 0.5737 - accuracy: 0.6345 - val_loss: 0.5751 - val_accuracy: 0.6607 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 31s 126ms/step - loss: 0.7549 - accuracy: 0.5382 - val_loss: 0.6064 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 80ms/step - loss: 0.6529 - accuracy: 0.6109 - val_loss: 0.5847 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 77ms/step - loss: 0.6843 - accuracy: 0.5818 - val_loss: 0.5901 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 78ms/step - loss: 0.6653 - accuracy: 0.5982 - val_loss: 0.5904 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 0.6218 - accuracy: 0.6127 - val_loss: 0.5547 - val_accuracy: 0.7232 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 18s 78ms/step - loss: 0.6248 - accuracy: 0.6218 - val_loss: 0.5634 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 19s 87ms/step - loss: 0.6411 - accuracy: 0.5964 - val_loss: 0.4982 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 79ms/step - loss: 0.6183 - accuracy: 0.6418 - val_loss: 0.5382 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 18s 78ms/step - loss: 0.6465 - accuracy: 0.6127 - val_loss: 0.5819 - val_accuracy: 0.6964 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 18s 79ms/step - loss: 0.6127 - accuracy: 0.6255 - val_loss: 0.5649 - val_accuracy: 0.7054 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 79ms/step - loss: 0.6119 - accuracy: 0.6345 - val_loss: 0.5295 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 18s 79ms/step - loss: 0.5806 - accuracy: 0.6455 - val_loss: 0.6269 - val_accuracy: 0.7054 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 17s 78ms/step - loss: 0.5951 - accuracy: 0.6455 - val_loss: 0.5859 - val_accuracy: 0.7232 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 0.5583 - accuracy: 0.6673 - val_loss: 0.5314 - val_accuracy: 0.7589 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 17s 78ms/step - loss: 0.5758 - accuracy: 0.6509 - val_loss: 0.6406 - val_accuracy: 0.7054 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 18s 77ms/step - loss: 0.5838 - accuracy: 0.6273 - val_loss: 0.6086 - val_accuracy: 0.7321 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 0.5855 - accuracy: 0.6145 - val_loss: 0.5723 - val_accuracy: 0.7411 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 24s 99ms/step - loss: 0.6486 - accuracy: 0.5891 - val_loss: 0.3771 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 15s 59ms/step - loss: 0.6328 - accuracy: 0.6073 - val_loss: 0.2700 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.6199 - accuracy: 0.6164 - val_loss: 0.2514 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5977 - accuracy: 0.6055 - val_loss: 0.2370 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5695 - accuracy: 0.6382 - val_loss: 0.2424 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 57ms/step - loss: 0.5846 - accuracy: 0.6309 - val_loss: 0.2818 - val_accuracy: 0.8661 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5996 - accuracy: 0.6127 - val_loss: 0.2505 - val_accuracy: 0.9018 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 60ms/step - loss: 0.5531 - accuracy: 0.6673 - val_loss: 0.2332 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5496 - accuracy: 0.6636 - val_loss: 0.2287 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 14s 57ms/step - loss: 0.5480 - accuracy: 0.6782 - val_loss: 0.3608 - val_accuracy: 0.8482 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5495 - accuracy: 0.6600 - val_loss: 0.2931 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5575 - accuracy: 0.6618 - val_loss: 0.2755 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 14s 57ms/step - loss: 0.5518 - accuracy: 0.6436 - val_loss: 0.2734 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5665 - accuracy: 0.6145 - val_loss: 0.2603 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5429 - accuracy: 0.6455 - val_loss: 0.2461 - val_accuracy: 0.9196 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5386 - accuracy: 0.6400 - val_loss: 0.2375 - val_accuracy: 0.9018 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5383 - accuracy: 0.6800 - val_loss: 0.2740 - val_accuracy: 0.8929 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 15s 57ms/step - loss: 0.5177 - accuracy: 0.6964 - val_loss: 0.3053 - val_accuracy: 0.8482 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.5435 - accuracy: 0.6745 - val_loss: 0.2409 - val_accuracy: 0.9018 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 28s 117ms/step - loss: 0.6391 - accuracy: 0.6036 - val_loss: 0.2847 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 81ms/step - loss: 0.5996 - accuracy: 0.6218 - val_loss: 0.2676 - val_accuracy: 0.8929 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 81ms/step - loss: 0.5856 - accuracy: 0.6400 - val_loss: 0.2525 - val_accuracy: 0.9018 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 78ms/step - loss: 0.5944 - accuracy: 0.6255 - val_loss: 0.2609 - val_accuracy: 0.9018 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 78ms/step - loss: 0.5603 - accuracy: 0.6527 - val_loss: 0.2576 - val_accuracy: 0.8839 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 16s 83ms/step - loss: 0.5804 - accuracy: 0.6545 - val_loss: 0.2837 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 89ms/step - loss: 0.5595 - accuracy: 0.6491 - val_loss: 0.2394 - val_accuracy: 0.8839 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 77ms/step - loss: 0.5551 - accuracy: 0.6418 - val_loss: 0.2834 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 78ms/step - loss: 0.5657 - accuracy: 0.6382 - val_loss: 0.2580 - val_accuracy: 0.9018 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 77ms/step - loss: 0.5614 - accuracy: 0.6564 - val_loss: 0.2459 - val_accuracy: 0.8929 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 77ms/step - loss: 0.5423 - accuracy: 0.6600 - val_loss: 0.2711 - val_accuracy: 0.8571 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 16s 77ms/step - loss: 0.5719 - accuracy: 0.6200 - val_loss: 0.3338 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 16s 77ms/step - loss: 0.5213 - accuracy: 0.6836 - val_loss: 0.2956 - val_accuracy: 0.8839 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 16s 80ms/step - loss: 0.5498 - accuracy: 0.6564 - val_loss: 0.2706 - val_accuracy: 0.8839 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 17s 78ms/step - loss: 0.5306 - accuracy: 0.6509 - val_loss: 0.2868 - val_accuracy: 0.8750 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 16s 79ms/step - loss: 0.5405 - accuracy: 0.6709 - val_loss: 0.3152 - val_accuracy: 0.8571 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 17s 82ms/step - loss: 0.5371 - accuracy: 0.6455 - val_loss: 0.3218 - val_accuracy: 0.8571 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 27s 120ms/step - loss: 0.5512 - accuracy: 0.6393 - val_loss: 0.1947 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5445 - accuracy: 0.6446 - val_loss: 0.2488 - val_accuracy: 0.8796 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5535 - accuracy: 0.6500 - val_loss: 0.1958 - val_accuracy: 0.9074 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5124 - accuracy: 0.6804 - val_loss: 0.2224 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5400 - accuracy: 0.6500 - val_loss: 0.2037 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 60ms/step - loss: 0.5311 - accuracy: 0.6696 - val_loss: 0.1894 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 60ms/step - loss: 0.5534 - accuracy: 0.6482 - val_loss: 0.1716 - val_accuracy: 0.9352 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5211 - accuracy: 0.6750 - val_loss: 0.2069 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 57ms/step - loss: 0.5379 - accuracy: 0.6625 - val_loss: 0.2150 - val_accuracy: 0.8889 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 57ms/step - loss: 0.5260 - accuracy: 0.6964 - val_loss: 0.2216 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5145 - accuracy: 0.6786 - val_loss: 0.2392 - val_accuracy: 0.8889 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5232 - accuracy: 0.6679 - val_loss: 0.1771 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 16s 60ms/step - loss: 0.4978 - accuracy: 0.7268 - val_loss: 0.1352 - val_accuracy: 0.9352 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5113 - accuracy: 0.6946 - val_loss: 0.1922 - val_accuracy: 0.9352 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 15s 58ms/step - loss: 0.5129 - accuracy: 0.6696 - val_loss: 0.2709 - val_accuracy: 0.9074 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 16s 57ms/step - loss: 0.5096 - accuracy: 0.6643 - val_loss: 0.1471 - val_accuracy: 0.9537 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5265 - accuracy: 0.6446 - val_loss: 0.1893 - val_accuracy: 0.8981 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5023 - accuracy: 0.6964 - val_loss: 0.2093 - val_accuracy: 0.9074 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.4927 - accuracy: 0.7054 - val_loss: 0.2214 - val_accuracy: 0.9167 - lr: 2.5000e-05\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 15s 56ms/step - loss: 0.4970 - accuracy: 0.6839 - val_loss: 0.2091 - val_accuracy: 0.9352 - lr: 2.5000e-05\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5035 - accuracy: 0.6893 - val_loss: 0.2864 - val_accuracy: 0.8704 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 15s 59ms/step - loss: 0.5039 - accuracy: 0.6661 - val_loss: 0.1192 - val_accuracy: 0.9630 - lr: 2.5000e-05\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.4905 - accuracy: 0.6929 - val_loss: 0.2687 - val_accuracy: 0.8889 - lr: 2.5000e-05\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5187 - accuracy: 0.6679 - val_loss: 0.1958 - val_accuracy: 0.9352 - lr: 2.5000e-05\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5116 - accuracy: 0.6679 - val_loss: 0.2620 - val_accuracy: 0.9074 - lr: 2.5000e-05\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 15s 59ms/step - loss: 0.5148 - accuracy: 0.6625 - val_loss: 0.1853 - val_accuracy: 0.9167 - lr: 2.5000e-05\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 15s 58ms/step - loss: 0.5221 - accuracy: 0.6536 - val_loss: 0.2145 - val_accuracy: 0.9259 - lr: 2.5000e-05\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5043 - accuracy: 0.6982 - val_loss: 0.1553 - val_accuracy: 0.9352 - lr: 1.2500e-05\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.4861 - accuracy: 0.7054 - val_loss: 0.1461 - val_accuracy: 0.9444 - lr: 1.2500e-05\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5064 - accuracy: 0.6750 - val_loss: 0.2529 - val_accuracy: 0.9074 - lr: 1.2500e-05\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 15s 57ms/step - loss: 0.5118 - accuracy: 0.6875 - val_loss: 0.1355 - val_accuracy: 0.9537 - lr: 1.2500e-05\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 16s 60ms/step - loss: 0.5115 - accuracy: 0.6929 - val_loss: 0.2424 - val_accuracy: 0.8796 - lr: 1.2500e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 28s 116ms/step - loss: 0.5702 - accuracy: 0.6375 - val_loss: 0.1615 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 18s 82ms/step - loss: 0.5309 - accuracy: 0.6857 - val_loss: 0.2267 - val_accuracy: 0.9074 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 78ms/step - loss: 0.5470 - accuracy: 0.6643 - val_loss: 0.1671 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 77ms/step - loss: 0.5491 - accuracy: 0.6589 - val_loss: 0.2093 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 17s 77ms/step - loss: 0.5530 - accuracy: 0.6429 - val_loss: 0.1913 - val_accuracy: 0.9074 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 77ms/step - loss: 0.5534 - accuracy: 0.6500 - val_loss: 0.1999 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 17s 79ms/step - loss: 0.5428 - accuracy: 0.6286 - val_loss: 0.1803 - val_accuracy: 0.9167 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 80ms/step - loss: 0.5430 - accuracy: 0.6482 - val_loss: 0.1564 - val_accuracy: 0.9259 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 18s 78ms/step - loss: 0.5549 - accuracy: 0.6304 - val_loss: 0.2247 - val_accuracy: 0.8981 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 17s 78ms/step - loss: 0.5369 - accuracy: 0.6589 - val_loss: 0.2261 - val_accuracy: 0.9167 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 17s 79ms/step - loss: 0.5294 - accuracy: 0.6589 - val_loss: 0.2154 - val_accuracy: 0.9259 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 19s 82ms/step - loss: 0.5351 - accuracy: 0.6625 - val_loss: 0.2055 - val_accuracy: 0.9259 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 18s 79ms/step - loss: 0.5138 - accuracy: 0.6804 - val_loss: 0.2196 - val_accuracy: 0.8981 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 18s 81ms/step - loss: 0.5181 - accuracy: 0.6750 - val_loss: 0.1333 - val_accuracy: 0.9537 - lr: 2.5000e-06\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 18s 79ms/step - loss: 0.5196 - accuracy: 0.6893 - val_loss: 0.2593 - val_accuracy: 0.9259 - lr: 2.5000e-06\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 18s 79ms/step - loss: 0.5093 - accuracy: 0.6804 - val_loss: 0.1555 - val_accuracy: 0.9444 - lr: 2.5000e-06\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 17s 78ms/step - loss: 0.5288 - accuracy: 0.6571 - val_loss: 0.1602 - val_accuracy: 0.9352 - lr: 2.5000e-06\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 18s 78ms/step - loss: 0.5323 - accuracy: 0.6304 - val_loss: 0.2119 - val_accuracy: 0.8981 - lr: 2.5000e-06\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 17s 84ms/step - loss: 0.5330 - accuracy: 0.6554 - val_loss: 0.2166 - val_accuracy: 0.9074 - lr: 2.5000e-06\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 17s 77ms/step - loss: 0.5133 - accuracy: 0.6893 - val_loss: 0.2210 - val_accuracy: 0.9167 - lr: 1.2500e-06\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 16s 78ms/step - loss: 0.5275 - accuracy: 0.6750 - val_loss: 0.2170 - val_accuracy: 0.8796 - lr: 1.2500e-06\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 17s 79ms/step - loss: 0.5141 - accuracy: 0.6821 - val_loss: 0.1165 - val_accuracy: 0.9537 - lr: 1.2500e-06\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 16s 77ms/step - loss: 0.5194 - accuracy: 0.6589 - val_loss: 0.1873 - val_accuracy: 0.9259 - lr: 1.2500e-06\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 16s 76ms/step - loss: 0.5271 - accuracy: 0.6607 - val_loss: 0.1785 - val_accuracy: 0.9167 - lr: 1.2500e-06\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 16s 77ms/step - loss: 0.5202 - accuracy: 0.6768 - val_loss: 0.1834 - val_accuracy: 0.9444 - lr: 1.2500e-06\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 16s 77ms/step - loss: 0.5282 - accuracy: 0.6179 - val_loss: 0.2423 - val_accuracy: 0.8889 - lr: 1.2500e-06\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 16s 78ms/step - loss: 0.5164 - accuracy: 0.6786 - val_loss: 0.1492 - val_accuracy: 0.9259 - lr: 1.2500e-06\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 16s 77ms/step - loss: 0.5012 - accuracy: 0.7143 - val_loss: 0.2402 - val_accuracy: 0.8981 - lr: 6.2500e-07\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 17s 78ms/step - loss: 0.5051 - accuracy: 0.6946 - val_loss: 0.2340 - val_accuracy: 0.9167 - lr: 6.2500e-07\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 17s 77ms/step - loss: 0.5035 - accuracy: 0.6875 - val_loss: 0.1792 - val_accuracy: 0.9167 - lr: 6.2500e-07\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 16s 77ms/step - loss: 0.4962 - accuracy: 0.6929 - val_loss: 0.2456 - val_accuracy: 0.8611 - lr: 6.2500e-07\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 17s 81ms/step - loss: 0.5189 - accuracy: 0.6554 - val_loss: 0.1528 - val_accuracy: 0.9630 - lr: 6.2500e-07\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      "=== Outer Fold 1 | Model: std_mobilenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 17s 42ms/step - loss: 0.7363 - accuracy: 0.4800 - val_loss: 0.6787 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.7101 - accuracy: 0.5145 - val_loss: 0.6871 - val_accuracy: 0.5268 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7131 - accuracy: 0.5055 - val_loss: 0.6691 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.7424 - accuracy: 0.4927 - val_loss: 0.6669 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.7416 - accuracy: 0.4618 - val_loss: 0.6685 - val_accuracy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.7033 - accuracy: 0.5182 - val_loss: 0.6627 - val_accuracy: 0.6518 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.7115 - accuracy: 0.5255 - val_loss: 0.6580 - val_accuracy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.7156 - accuracy: 0.5055 - val_loss: 0.6598 - val_accuracy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 12s 27ms/step - loss: 0.7117 - accuracy: 0.5236 - val_loss: 0.6560 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.7068 - accuracy: 0.5073 - val_loss: 0.6498 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.7162 - accuracy: 0.5364 - val_loss: 0.6491 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6892 - accuracy: 0.5582 - val_loss: 0.6511 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.7066 - accuracy: 0.5055 - val_loss: 0.6493 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.6837 - accuracy: 0.5509 - val_loss: 0.6608 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6958 - accuracy: 0.5200 - val_loss: 0.6437 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.7174 - accuracy: 0.4564 - val_loss: 0.6499 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6938 - accuracy: 0.5436 - val_loss: 0.6443 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 14s 27ms/step - loss: 0.6986 - accuracy: 0.5327 - val_loss: 0.6485 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6970 - accuracy: 0.5236 - val_loss: 0.6480 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.6889 - accuracy: 0.5327 - val_loss: 0.6452 - val_accuracy: 0.5536 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6921 - accuracy: 0.5273 - val_loss: 0.6431 - val_accuracy: 0.7589 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6823 - accuracy: 0.5618 - val_loss: 0.6418 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6952 - accuracy: 0.4964 - val_loss: 0.6464 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.7004 - accuracy: 0.5000 - val_loss: 0.6410 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6940 - accuracy: 0.5091 - val_loss: 0.6423 - val_accuracy: 0.6518 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6927 - accuracy: 0.5345 - val_loss: 0.6411 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6762 - accuracy: 0.5600 - val_loss: 0.6382 - val_accuracy: 0.7411 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6779 - accuracy: 0.5600 - val_loss: 0.6403 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6877 - accuracy: 0.5236 - val_loss: 0.6395 - val_accuracy: 0.7054 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6849 - accuracy: 0.5473 - val_loss: 0.6380 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6845 - accuracy: 0.5400 - val_loss: 0.6378 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6812 - accuracy: 0.5618 - val_loss: 0.6378 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6826 - accuracy: 0.5582 - val_loss: 0.6369 - val_accuracy: 0.7411 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6836 - accuracy: 0.5364 - val_loss: 0.6335 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6903 - accuracy: 0.5255 - val_loss: 0.6362 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6868 - accuracy: 0.5527 - val_loss: 0.6371 - val_accuracy: 0.5714 - lr: 5.0000e-05\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6789 - accuracy: 0.5582 - val_loss: 0.6394 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6809 - accuracy: 0.5691 - val_loss: 0.6312 - val_accuracy: 0.7321 - lr: 5.0000e-05\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.6778 - accuracy: 0.5436 - val_loss: 0.6351 - val_accuracy: 0.7232 - lr: 5.0000e-05\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 12s 27ms/step - loss: 0.6803 - accuracy: 0.5473 - val_loss: 0.6373 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6858 - accuracy: 0.5218 - val_loss: 0.6358 - val_accuracy: 0.7500 - lr: 5.0000e-05\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6828 - accuracy: 0.5582 - val_loss: 0.6371 - val_accuracy: 0.6161 - lr: 5.0000e-05\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.6809 - accuracy: 0.5164 - val_loss: 0.6336 - val_accuracy: 0.7411 - lr: 5.0000e-05\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6826 - accuracy: 0.5236 - val_loss: 0.6375 - val_accuracy: 0.6786 - lr: 2.5000e-05\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6773 - accuracy: 0.5327 - val_loss: 0.6297 - val_accuracy: 0.7768 - lr: 2.5000e-05\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6778 - accuracy: 0.5382 - val_loss: 0.6327 - val_accuracy: 0.7679 - lr: 2.5000e-05\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6759 - accuracy: 0.5600 - val_loss: 0.6315 - val_accuracy: 0.7768 - lr: 2.5000e-05\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6775 - accuracy: 0.5618 - val_loss: 0.6326 - val_accuracy: 0.7589 - lr: 2.5000e-05\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.6811 - accuracy: 0.5473 - val_loss: 0.6333 - val_accuracy: 0.6786 - lr: 2.5000e-05\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6749 - accuracy: 0.5655 - val_loss: 0.6300 - val_accuracy: 0.7411 - lr: 2.5000e-05\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6780 - accuracy: 0.5455 - val_loss: 0.6281 - val_accuracy: 0.7946 - lr: 1.2500e-05\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6722 - accuracy: 0.5745 - val_loss: 0.6346 - val_accuracy: 0.7411 - lr: 1.2500e-05\n",
      "Epoch 53/100\n",
      "69/69 [==============================] - 14s 27ms/step - loss: 0.6802 - accuracy: 0.5582 - val_loss: 0.6316 - val_accuracy: 0.7232 - lr: 1.2500e-05\n",
      "Epoch 54/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6829 - accuracy: 0.5600 - val_loss: 0.6324 - val_accuracy: 0.6964 - lr: 1.2500e-05\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6794 - accuracy: 0.5327 - val_loss: 0.6300 - val_accuracy: 0.7589 - lr: 1.2500e-05\n",
      "Epoch 56/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6822 - accuracy: 0.5455 - val_loss: 0.6318 - val_accuracy: 0.7589 - lr: 1.2500e-05\n",
      "Epoch 57/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.6761 - accuracy: 0.5455 - val_loss: 0.6326 - val_accuracy: 0.7500 - lr: 6.2500e-06\n",
      "Epoch 58/100\n",
      "69/69 [==============================] - 14s 28ms/step - loss: 0.6779 - accuracy: 0.5382 - val_loss: 0.6338 - val_accuracy: 0.7500 - lr: 6.2500e-06\n",
      "Epoch 59/100\n",
      "69/69 [==============================] - 14s 27ms/step - loss: 0.6782 - accuracy: 0.5364 - val_loss: 0.6333 - val_accuracy: 0.7857 - lr: 6.2500e-06\n",
      "Epoch 60/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6758 - accuracy: 0.5345 - val_loss: 0.6311 - val_accuracy: 0.7143 - lr: 6.2500e-06\n",
      "Epoch 61/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6759 - accuracy: 0.5691 - val_loss: 0.6306 - val_accuracy: 0.7768 - lr: 6.2500e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 18s 50ms/step - loss: 1.1178 - accuracy: 0.4800 - val_loss: 0.6352 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 14s 33ms/step - loss: 0.8189 - accuracy: 0.4964 - val_loss: 0.6320 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.8023 - accuracy: 0.5200 - val_loss: 0.6294 - val_accuracy: 0.5446 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.7600 - accuracy: 0.5055 - val_loss: 0.6273 - val_accuracy: 0.5536 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 14s 33ms/step - loss: 0.7150 - accuracy: 0.5618 - val_loss: 0.6243 - val_accuracy: 0.5357 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.7316 - accuracy: 0.4855 - val_loss: 0.6227 - val_accuracy: 0.5446 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 34ms/step - loss: 0.7184 - accuracy: 0.5764 - val_loss: 0.6193 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.7248 - accuracy: 0.5200 - val_loss: 0.6171 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 14s 32ms/step - loss: 0.6961 - accuracy: 0.5309 - val_loss: 0.6184 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 15s 32ms/step - loss: 0.6921 - accuracy: 0.5455 - val_loss: 0.6179 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 14s 33ms/step - loss: 0.6878 - accuracy: 0.5727 - val_loss: 0.6162 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 14s 32ms/step - loss: 0.6664 - accuracy: 0.5764 - val_loss: 0.6188 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 14s 33ms/step - loss: 0.6710 - accuracy: 0.5600 - val_loss: 0.6152 - val_accuracy: 0.6339 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 14s 32ms/step - loss: 0.6600 - accuracy: 0.5818 - val_loss: 0.6114 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6899 - accuracy: 0.5582 - val_loss: 0.6196 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 13s 30ms/step - loss: 0.6628 - accuracy: 0.5600 - val_loss: 0.6313 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.6493 - accuracy: 0.5945 - val_loss: 0.6285 - val_accuracy: 0.6339 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6507 - accuracy: 0.6127 - val_loss: 0.6236 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.6537 - accuracy: 0.5800 - val_loss: 0.6378 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6387 - accuracy: 0.5800 - val_loss: 0.6450 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 13s 30ms/step - loss: 0.6467 - accuracy: 0.5945 - val_loss: 0.6407 - val_accuracy: 0.6607 - lr: 5.0000e-06\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.6431 - accuracy: 0.6000 - val_loss: 0.6446 - val_accuracy: 0.6429 - lr: 5.0000e-06\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 14s 31ms/step - loss: 0.6202 - accuracy: 0.6382 - val_loss: 0.6610 - val_accuracy: 0.6250 - lr: 5.0000e-06\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6367 - accuracy: 0.5800 - val_loss: 0.6921 - val_accuracy: 0.5804 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 16s 38ms/step - loss: 0.6988 - accuracy: 0.5400 - val_loss: 0.7309 - val_accuracy: 0.4732 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6864 - accuracy: 0.5491 - val_loss: 0.6989 - val_accuracy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6847 - accuracy: 0.5564 - val_loss: 0.6881 - val_accuracy: 0.5536 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 12s 28ms/step - loss: 0.6759 - accuracy: 0.5636 - val_loss: 0.6814 - val_accuracy: 0.5982 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6786 - accuracy: 0.5218 - val_loss: 0.6886 - val_accuracy: 0.5268 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6792 - accuracy: 0.5545 - val_loss: 0.6782 - val_accuracy: 0.5268 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6640 - accuracy: 0.5836 - val_loss: 0.6754 - val_accuracy: 0.6071 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6655 - accuracy: 0.5636 - val_loss: 0.6713 - val_accuracy: 0.5982 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6701 - accuracy: 0.5564 - val_loss: 0.6724 - val_accuracy: 0.5982 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6676 - accuracy: 0.5818 - val_loss: 0.6724 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6699 - accuracy: 0.5491 - val_loss: 0.6627 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 14s 27ms/step - loss: 0.6583 - accuracy: 0.5836 - val_loss: 0.6672 - val_accuracy: 0.5982 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6501 - accuracy: 0.5927 - val_loss: 0.6777 - val_accuracy: 0.6161 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 12s 27ms/step - loss: 0.6604 - accuracy: 0.5855 - val_loss: 0.6894 - val_accuracy: 0.5179 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6482 - accuracy: 0.5873 - val_loss: 0.6566 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 12s 27ms/step - loss: 0.6513 - accuracy: 0.5764 - val_loss: 0.6700 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 12s 27ms/step - loss: 0.6507 - accuracy: 0.6000 - val_loss: 0.6706 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6491 - accuracy: 0.5982 - val_loss: 0.6576 - val_accuracy: 0.5982 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6449 - accuracy: 0.6145 - val_loss: 0.6609 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6491 - accuracy: 0.5673 - val_loss: 0.6716 - val_accuracy: 0.6071 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6330 - accuracy: 0.6055 - val_loss: 0.6556 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6521 - accuracy: 0.5855 - val_loss: 0.6557 - val_accuracy: 0.6429 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 12s 28ms/step - loss: 0.6373 - accuracy: 0.6055 - val_loss: 0.6552 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6322 - accuracy: 0.5836 - val_loss: 0.6580 - val_accuracy: 0.5804 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 12s 24ms/step - loss: 0.6382 - accuracy: 0.6055 - val_loss: 0.6587 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6534 - accuracy: 0.5564 - val_loss: 0.6805 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6403 - accuracy: 0.5909 - val_loss: 0.6699 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 12s 27ms/step - loss: 0.6383 - accuracy: 0.5818 - val_loss: 0.6431 - val_accuracy: 0.6161 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 12s 26ms/step - loss: 0.6378 - accuracy: 0.6200 - val_loss: 0.6653 - val_accuracy: 0.5714 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 12s 24ms/step - loss: 0.6324 - accuracy: 0.6018 - val_loss: 0.6529 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 12s 24ms/step - loss: 0.6330 - accuracy: 0.6055 - val_loss: 0.6589 - val_accuracy: 0.5625 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6387 - accuracy: 0.5909 - val_loss: 0.6362 - val_accuracy: 0.6161 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6348 - accuracy: 0.5927 - val_loss: 0.6399 - val_accuracy: 0.6250 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 13s 24ms/step - loss: 0.6304 - accuracy: 0.6018 - val_loss: 0.6684 - val_accuracy: 0.6071 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6329 - accuracy: 0.5927 - val_loss: 0.6647 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6397 - accuracy: 0.6000 - val_loss: 0.6616 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6319 - accuracy: 0.5964 - val_loss: 0.6491 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.6315 - accuracy: 0.6327 - val_loss: 0.6532 - val_accuracy: 0.5804 - lr: 2.5000e-05\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 12s 27ms/step - loss: 0.6255 - accuracy: 0.6182 - val_loss: 0.6608 - val_accuracy: 0.5446 - lr: 2.5000e-05\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 12s 25ms/step - loss: 0.6287 - accuracy: 0.5891 - val_loss: 0.6662 - val_accuracy: 0.5804 - lr: 2.5000e-05\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 13s 25ms/step - loss: 0.6208 - accuracy: 0.6255 - val_loss: 0.6756 - val_accuracy: 0.5893 - lr: 2.5000e-05\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 12s 27ms/step - loss: 0.6292 - accuracy: 0.5855 - val_loss: 0.6742 - val_accuracy: 0.5982 - lr: 2.5000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 19s 44ms/step - loss: 0.6882 - accuracy: 0.5782 - val_loss: 0.6628 - val_accuracy: 0.5893 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 14s 37ms/step - loss: 0.6963 - accuracy: 0.5564 - val_loss: 0.6574 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 14s 33ms/step - loss: 0.6576 - accuracy: 0.5782 - val_loss: 0.6675 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.6671 - accuracy: 0.5764 - val_loss: 0.6543 - val_accuracy: 0.5982 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.6571 - accuracy: 0.5745 - val_loss: 0.6851 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6613 - accuracy: 0.5873 - val_loss: 0.6745 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.6310 - accuracy: 0.6127 - val_loss: 0.7066 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6477 - accuracy: 0.6309 - val_loss: 0.6976 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.6446 - accuracy: 0.5836 - val_loss: 0.7218 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6187 - accuracy: 0.6200 - val_loss: 0.7058 - val_accuracy: 0.6339 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6192 - accuracy: 0.6436 - val_loss: 0.6900 - val_accuracy: 0.6161 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.6047 - accuracy: 0.6236 - val_loss: 0.7330 - val_accuracy: 0.5625 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6300 - accuracy: 0.6091 - val_loss: 0.7586 - val_accuracy: 0.5000 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 14s 32ms/step - loss: 0.6502 - accuracy: 0.5582 - val_loss: 0.7284 - val_accuracy: 0.5179 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 17s 46ms/step - loss: 0.6715 - accuracy: 0.5482 - val_loss: 0.5250 - val_accuracy: 0.7130 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 26ms/step - loss: 0.6692 - accuracy: 0.5357 - val_loss: 0.4891 - val_accuracy: 0.7963 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 13s 27ms/step - loss: 0.6539 - accuracy: 0.5732 - val_loss: 0.5377 - val_accuracy: 0.5926 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 13s 28ms/step - loss: 0.6452 - accuracy: 0.5893 - val_loss: 0.4658 - val_accuracy: 0.7685 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 14s 28ms/step - loss: 0.6568 - accuracy: 0.5696 - val_loss: 0.4457 - val_accuracy: 0.8056 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 15s 28ms/step - loss: 0.6497 - accuracy: 0.5875 - val_loss: 0.4851 - val_accuracy: 0.7407 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 13s 26ms/step - loss: 0.6520 - accuracy: 0.5500 - val_loss: 0.4732 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 26ms/step - loss: 0.6526 - accuracy: 0.5500 - val_loss: 0.5236 - val_accuracy: 0.6481 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 27ms/step - loss: 0.6583 - accuracy: 0.5679 - val_loss: 0.4861 - val_accuracy: 0.7407 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 15s 30ms/step - loss: 0.6414 - accuracy: 0.5929 - val_loss: 0.4523 - val_accuracy: 0.7870 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 26ms/step - loss: 0.6452 - accuracy: 0.5714 - val_loss: 0.4567 - val_accuracy: 0.7963 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 15s 28ms/step - loss: 0.6322 - accuracy: 0.6143 - val_loss: 0.4880 - val_accuracy: 0.7593 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 15s 26ms/step - loss: 0.6460 - accuracy: 0.5857 - val_loss: 0.4572 - val_accuracy: 0.8333 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 14s 27ms/step - loss: 0.6443 - accuracy: 0.5911 - val_loss: 0.4944 - val_accuracy: 0.7685 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 15s 29ms/step - loss: 0.6363 - accuracy: 0.5893 - val_loss: 0.5088 - val_accuracy: 0.7870 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 19s 44ms/step - loss: 0.6954 - accuracy: 0.5750 - val_loss: 0.4564 - val_accuracy: 0.8148 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 33ms/step - loss: 0.6522 - accuracy: 0.6089 - val_loss: 0.4517 - val_accuracy: 0.8056 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 16s 32ms/step - loss: 0.6745 - accuracy: 0.5804 - val_loss: 0.4783 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 15s 32ms/step - loss: 0.6378 - accuracy: 0.5893 - val_loss: 0.4747 - val_accuracy: 0.7222 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 15s 32ms/step - loss: 0.6436 - accuracy: 0.5911 - val_loss: 0.4746 - val_accuracy: 0.7315 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 14s 32ms/step - loss: 0.6253 - accuracy: 0.6250 - val_loss: 0.4762 - val_accuracy: 0.6759 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 15s 32ms/step - loss: 0.6429 - accuracy: 0.5839 - val_loss: 0.4603 - val_accuracy: 0.7037 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 13s 31ms/step - loss: 0.5980 - accuracy: 0.6429 - val_loss: 0.4930 - val_accuracy: 0.6944 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 32ms/step - loss: 0.5840 - accuracy: 0.6536 - val_loss: 0.5029 - val_accuracy: 0.6574 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 13s 32ms/step - loss: 0.6257 - accuracy: 0.6089 - val_loss: 0.4958 - val_accuracy: 0.6667 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 13s 33ms/step - loss: 0.5965 - accuracy: 0.6393 - val_loss: 0.5235 - val_accuracy: 0.6481 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 14s 32ms/step - loss: 0.6129 - accuracy: 0.6161 - val_loss: 0.5368 - val_accuracy: 0.6389 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 1s 651ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "\n",
      "=== Outer Fold 1 | Model: att_densenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 52s 329ms/step - loss: 0.7630 - accuracy: 0.5964 - val_loss: 0.5485 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 23s 175ms/step - loss: 0.7228 - accuracy: 0.6018 - val_loss: 0.5204 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 23s 169ms/step - loss: 0.5739 - accuracy: 0.6836 - val_loss: 0.5264 - val_accuracy: 0.7232 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 23s 169ms/step - loss: 0.5304 - accuracy: 0.7255 - val_loss: 0.5989 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 23s 174ms/step - loss: 0.5241 - accuracy: 0.7345 - val_loss: 0.4686 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 24s 171ms/step - loss: 0.4557 - accuracy: 0.7800 - val_loss: 0.6757 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.4191 - accuracy: 0.7873 - val_loss: 0.9511 - val_accuracy: 0.6071 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 23s 173ms/step - loss: 0.3839 - accuracy: 0.8109 - val_loss: 0.8158 - val_accuracy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 23s 169ms/step - loss: 0.3294 - accuracy: 0.8655 - val_loss: 0.8675 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.3271 - accuracy: 0.8527 - val_loss: 0.6795 - val_accuracy: 0.7232 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.2685 - accuracy: 0.9000 - val_loss: 0.7573 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.2477 - accuracy: 0.9018 - val_loss: 1.0264 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.2514 - accuracy: 0.9000 - val_loss: 0.8561 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.2105 - accuracy: 0.9255 - val_loss: 0.7631 - val_accuracy: 0.6607 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 23s 175ms/step - loss: 0.1874 - accuracy: 0.9291 - val_loss: 0.7730 - val_accuracy: 0.7054 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 36s 230ms/step - loss: 0.5077 - accuracy: 0.7636 - val_loss: 0.5354 - val_accuracy: 0.6964 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4821 - accuracy: 0.7618 - val_loss: 0.5960 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.5128 - accuracy: 0.7418 - val_loss: 0.7021 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4547 - accuracy: 0.7636 - val_loss: 0.6063 - val_accuracy: 0.7054 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4575 - accuracy: 0.7600 - val_loss: 0.5722 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 26s 186ms/step - loss: 0.4432 - accuracy: 0.7764 - val_loss: 0.6050 - val_accuracy: 0.7232 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 23s 184ms/step - loss: 0.4351 - accuracy: 0.7782 - val_loss: 0.6094 - val_accuracy: 0.6964 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 23s 184ms/step - loss: 0.4359 - accuracy: 0.7964 - val_loss: 0.5786 - val_accuracy: 0.7321 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 24s 184ms/step - loss: 0.4067 - accuracy: 0.8018 - val_loss: 0.5902 - val_accuracy: 0.7500 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4240 - accuracy: 0.7891 - val_loss: 0.6000 - val_accuracy: 0.7232 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 24s 188ms/step - loss: 0.4140 - accuracy: 0.7982 - val_loss: 0.6649 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 34s 213ms/step - loss: 0.5213 - accuracy: 0.7109 - val_loss: 0.2026 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 23s 169ms/step - loss: 0.4681 - accuracy: 0.7691 - val_loss: 0.2207 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 22s 170ms/step - loss: 0.4653 - accuracy: 0.7636 - val_loss: 0.4221 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.4468 - accuracy: 0.7782 - val_loss: 0.5572 - val_accuracy: 0.7232 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.4007 - accuracy: 0.8073 - val_loss: 0.2734 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.3882 - accuracy: 0.7945 - val_loss: 0.3366 - val_accuracy: 0.8661 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 170ms/step - loss: 0.3784 - accuracy: 0.8073 - val_loss: 0.2776 - val_accuracy: 0.8929 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 23s 169ms/step - loss: 0.3130 - accuracy: 0.8473 - val_loss: 0.2360 - val_accuracy: 0.8839 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 22s 170ms/step - loss: 0.3035 - accuracy: 0.8673 - val_loss: 0.3162 - val_accuracy: 0.9018 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.3125 - accuracy: 0.8545 - val_loss: 0.3434 - val_accuracy: 0.8393 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 23s 174ms/step - loss: 0.2892 - accuracy: 0.8673 - val_loss: 0.3400 - val_accuracy: 0.8661 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 38s 229ms/step - loss: 0.4982 - accuracy: 0.7473 - val_loss: 0.2275 - val_accuracy: 0.8839 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4599 - accuracy: 0.7491 - val_loss: 0.2746 - val_accuracy: 0.8661 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4704 - accuracy: 0.7727 - val_loss: 0.2839 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4461 - accuracy: 0.7782 - val_loss: 0.2762 - val_accuracy: 0.8661 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 24s 184ms/step - loss: 0.4396 - accuracy: 0.7691 - val_loss: 0.3491 - val_accuracy: 0.8571 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 24s 184ms/step - loss: 0.4463 - accuracy: 0.7745 - val_loss: 0.2917 - val_accuracy: 0.8839 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 184ms/step - loss: 0.4183 - accuracy: 0.8000 - val_loss: 0.2683 - val_accuracy: 0.8750 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 25s 185ms/step - loss: 0.4153 - accuracy: 0.8000 - val_loss: 0.3517 - val_accuracy: 0.8482 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 24s 184ms/step - loss: 0.4265 - accuracy: 0.7945 - val_loss: 0.2780 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4234 - accuracy: 0.7945 - val_loss: 0.3084 - val_accuracy: 0.8839 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 25s 190ms/step - loss: 0.3971 - accuracy: 0.8055 - val_loss: 0.2503 - val_accuracy: 0.9018 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 36s 230ms/step - loss: 0.4745 - accuracy: 0.7875 - val_loss: 0.2254 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 23s 171ms/step - loss: 0.3931 - accuracy: 0.8411 - val_loss: 0.3679 - val_accuracy: 0.8056 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 23s 169ms/step - loss: 0.3946 - accuracy: 0.8339 - val_loss: 0.3648 - val_accuracy: 0.7870 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 23s 169ms/step - loss: 0.3161 - accuracy: 0.8661 - val_loss: 0.3918 - val_accuracy: 0.8426 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 24s 169ms/step - loss: 0.3073 - accuracy: 0.8589 - val_loss: 0.5441 - val_accuracy: 0.7870 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 25s 171ms/step - loss: 0.2686 - accuracy: 0.8857 - val_loss: 0.3768 - val_accuracy: 0.8056 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 24s 171ms/step - loss: 0.2529 - accuracy: 0.8911 - val_loss: 0.5997 - val_accuracy: 0.7870 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 23s 170ms/step - loss: 0.2021 - accuracy: 0.9143 - val_loss: 0.6057 - val_accuracy: 0.7870 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 24s 169ms/step - loss: 0.1984 - accuracy: 0.9107 - val_loss: 0.7546 - val_accuracy: 0.7778 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 24s 170ms/step - loss: 0.2071 - accuracy: 0.9179 - val_loss: 0.4856 - val_accuracy: 0.8056 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 24s 174ms/step - loss: 0.1966 - accuracy: 0.9250 - val_loss: 0.5508 - val_accuracy: 0.7685 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 37s 229ms/step - loss: 0.3911 - accuracy: 0.8286 - val_loss: 0.2597 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.3772 - accuracy: 0.8357 - val_loss: 0.2910 - val_accuracy: 0.8704 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 26s 186ms/step - loss: 0.3808 - accuracy: 0.8232 - val_loss: 0.2731 - val_accuracy: 0.8611 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 25s 191ms/step - loss: 0.3713 - accuracy: 0.8411 - val_loss: 0.2526 - val_accuracy: 0.8796 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 25s 184ms/step - loss: 0.3527 - accuracy: 0.8607 - val_loss: 0.2741 - val_accuracy: 0.8704 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 25s 190ms/step - loss: 0.3219 - accuracy: 0.8696 - val_loss: 0.2353 - val_accuracy: 0.8981 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.3243 - accuracy: 0.8714 - val_loss: 0.2702 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.3122 - accuracy: 0.8732 - val_loss: 0.3390 - val_accuracy: 0.8426 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.3159 - accuracy: 0.8643 - val_loss: 0.2806 - val_accuracy: 0.8704 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 25s 184ms/step - loss: 0.3179 - accuracy: 0.8554 - val_loss: 0.3492 - val_accuracy: 0.8796 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 25s 184ms/step - loss: 0.3123 - accuracy: 0.8643 - val_loss: 0.3294 - val_accuracy: 0.8426 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 25s 185ms/step - loss: 0.3095 - accuracy: 0.8750 - val_loss: 0.2403 - val_accuracy: 0.8981 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 26s 185ms/step - loss: 0.3135 - accuracy: 0.8821 - val_loss: 0.3180 - val_accuracy: 0.8426 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.2915 - accuracy: 0.8768 - val_loss: 0.3122 - val_accuracy: 0.8889 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.2948 - accuracy: 0.8607 - val_loss: 0.3202 - val_accuracy: 0.8519 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 25s 190ms/step - loss: 0.2733 - accuracy: 0.8732 - val_loss: 0.2896 - val_accuracy: 0.8241 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "\n",
      "=== Outer Fold 1 | Model: att_mobilenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 26s 112ms/step - loss: 0.6681 - accuracy: 0.6073 - val_loss: 0.5690 - val_accuracy: 0.7679 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 63ms/step - loss: 0.5871 - accuracy: 0.6855 - val_loss: 0.5281 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.5117 - accuracy: 0.7436 - val_loss: 0.5005 - val_accuracy: 0.8661 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.4471 - accuracy: 0.8000 - val_loss: 0.4724 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 15s 62ms/step - loss: 0.3852 - accuracy: 0.8364 - val_loss: 0.4674 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 62ms/step - loss: 0.3307 - accuracy: 0.8582 - val_loss: 0.4649 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.2914 - accuracy: 0.8782 - val_loss: 0.4850 - val_accuracy: 0.7232 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.2619 - accuracy: 0.9018 - val_loss: 0.5606 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.2292 - accuracy: 0.9000 - val_loss: 0.7357 - val_accuracy: 0.7411 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1689 - accuracy: 0.9291 - val_loss: 0.7566 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1614 - accuracy: 0.9473 - val_loss: 0.7007 - val_accuracy: 0.7679 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1085 - accuracy: 0.9618 - val_loss: 0.9563 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1071 - accuracy: 0.9709 - val_loss: 0.9151 - val_accuracy: 0.6696 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 16s 61ms/step - loss: 0.0914 - accuracy: 0.9655 - val_loss: 1.0345 - val_accuracy: 0.6250 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1216 - accuracy: 0.9473 - val_loss: 0.8678 - val_accuracy: 0.6518 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 15s 62ms/step - loss: 0.0812 - accuracy: 0.9745 - val_loss: 0.8656 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 21s 82ms/step - loss: 0.6006 - accuracy: 0.6655 - val_loss: 0.5852 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 15s 66ms/step - loss: 0.5867 - accuracy: 0.6909 - val_loss: 0.6174 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 15s 66ms/step - loss: 0.5388 - accuracy: 0.7309 - val_loss: 0.6212 - val_accuracy: 0.7054 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 0.5364 - accuracy: 0.7291 - val_loss: 0.6014 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.5360 - accuracy: 0.7291 - val_loss: 0.5511 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 15s 67ms/step - loss: 0.5327 - accuracy: 0.7073 - val_loss: 0.5185 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.5433 - accuracy: 0.7182 - val_loss: 0.4929 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 71ms/step - loss: 0.5137 - accuracy: 0.7382 - val_loss: 0.4657 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 68ms/step - loss: 0.4952 - accuracy: 0.7455 - val_loss: 0.4374 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.5095 - accuracy: 0.7545 - val_loss: 0.4270 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 68ms/step - loss: 0.4922 - accuracy: 0.7709 - val_loss: 0.4175 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 0.4808 - accuracy: 0.7764 - val_loss: 0.4230 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 0.4816 - accuracy: 0.7836 - val_loss: 0.4271 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 0.4773 - accuracy: 0.7491 - val_loss: 0.4424 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 15s 67ms/step - loss: 0.4660 - accuracy: 0.7709 - val_loss: 0.4832 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 16s 69ms/step - loss: 0.4648 - accuracy: 0.7836 - val_loss: 0.5000 - val_accuracy: 0.7411 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.4499 - accuracy: 0.7945 - val_loss: 0.5341 - val_accuracy: 0.7054 - lr: 5.0000e-06\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 15s 66ms/step - loss: 0.4345 - accuracy: 0.7945 - val_loss: 0.5641 - val_accuracy: 0.6429 - lr: 5.0000e-06\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 15s 66ms/step - loss: 0.4469 - accuracy: 0.8073 - val_loss: 0.5998 - val_accuracy: 0.6161 - lr: 5.0000e-06\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 0.4481 - accuracy: 0.7909 - val_loss: 0.6358 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 15s 67ms/step - loss: 0.4467 - accuracy: 0.7927 - val_loss: 0.6515 - val_accuracy: 0.5714 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 19s 77ms/step - loss: 0.4643 - accuracy: 0.7855 - val_loss: 0.4622 - val_accuracy: 0.7768 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 0.3782 - accuracy: 0.8345 - val_loss: 0.3692 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.3441 - accuracy: 0.8400 - val_loss: 0.3190 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.3149 - accuracy: 0.8545 - val_loss: 0.3356 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.2853 - accuracy: 0.8836 - val_loss: 0.3536 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.2414 - accuracy: 0.9000 - val_loss: 0.3948 - val_accuracy: 0.8482 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 62ms/step - loss: 0.2258 - accuracy: 0.9182 - val_loss: 0.5068 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 15s 62ms/step - loss: 0.2010 - accuracy: 0.9164 - val_loss: 0.3675 - val_accuracy: 0.8661 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 15s 62ms/step - loss: 0.1733 - accuracy: 0.9345 - val_loss: 0.4760 - val_accuracy: 0.8214 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 15s 63ms/step - loss: 0.1659 - accuracy: 0.9455 - val_loss: 0.3148 - val_accuracy: 0.8661 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 61ms/step - loss: 0.1666 - accuracy: 0.9400 - val_loss: 0.3774 - val_accuracy: 0.8482 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 15s 62ms/step - loss: 0.1689 - accuracy: 0.9255 - val_loss: 0.4101 - val_accuracy: 0.8571 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1608 - accuracy: 0.9436 - val_loss: 0.4003 - val_accuracy: 0.8571 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 16s 61ms/step - loss: 0.1171 - accuracy: 0.9655 - val_loss: 0.4388 - val_accuracy: 0.8482 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1055 - accuracy: 0.9618 - val_loss: 0.4647 - val_accuracy: 0.8304 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1106 - accuracy: 0.9636 - val_loss: 0.4437 - val_accuracy: 0.8393 - lr: 2.5000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 16s 61ms/step - loss: 0.1095 - accuracy: 0.9564 - val_loss: 0.4673 - val_accuracy: 0.8125 - lr: 2.5000e-05\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1249 - accuracy: 0.9473 - val_loss: 0.4945 - val_accuracy: 0.8393 - lr: 2.5000e-05\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.0918 - accuracy: 0.9691 - val_loss: 0.5345 - val_accuracy: 0.8036 - lr: 2.5000e-05\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 15s 63ms/step - loss: 0.0891 - accuracy: 0.9709 - val_loss: 0.5478 - val_accuracy: 0.7768 - lr: 2.5000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 20s 83ms/step - loss: 0.4425 - accuracy: 0.7655 - val_loss: 0.8363 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 65ms/step - loss: 0.4170 - accuracy: 0.8018 - val_loss: 1.2701 - val_accuracy: 0.4643 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 0.4113 - accuracy: 0.8164 - val_loss: 1.4949 - val_accuracy: 0.4643 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 69ms/step - loss: 0.4323 - accuracy: 0.7982 - val_loss: 1.5464 - val_accuracy: 0.4643 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 17s 66ms/step - loss: 0.4080 - accuracy: 0.8091 - val_loss: 1.6218 - val_accuracy: 0.4643 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 15s 65ms/step - loss: 0.3962 - accuracy: 0.8036 - val_loss: 1.7179 - val_accuracy: 0.4643 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 16s 65ms/step - loss: 0.3871 - accuracy: 0.8218 - val_loss: 1.7694 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 15s 65ms/step - loss: 0.3994 - accuracy: 0.8164 - val_loss: 1.7435 - val_accuracy: 0.4732 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 15s 66ms/step - loss: 0.3908 - accuracy: 0.8200 - val_loss: 1.8150 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 0.3795 - accuracy: 0.8291 - val_loss: 1.8749 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.3974 - accuracy: 0.8273 - val_loss: 1.8466 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 24s 86ms/step - loss: 0.2787 - accuracy: 0.8804 - val_loss: 0.1810 - val_accuracy: 0.9352 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 16s 61ms/step - loss: 0.2117 - accuracy: 0.9214 - val_loss: 0.1886 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.1746 - accuracy: 0.9321 - val_loss: 0.1629 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.1627 - accuracy: 0.9286 - val_loss: 0.1988 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 61ms/step - loss: 0.1337 - accuracy: 0.9482 - val_loss: 0.2016 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.1346 - accuracy: 0.9411 - val_loss: 0.1874 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.1164 - accuracy: 0.9643 - val_loss: 0.2713 - val_accuracy: 0.8889 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.1111 - accuracy: 0.9571 - val_loss: 0.2712 - val_accuracy: 0.8796 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 17s 62ms/step - loss: 0.0905 - accuracy: 0.9643 - val_loss: 0.2723 - val_accuracy: 0.9167 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 18s 61ms/step - loss: 0.0999 - accuracy: 0.9661 - val_loss: 0.2756 - val_accuracy: 0.8981 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 17s 62ms/step - loss: 0.0763 - accuracy: 0.9750 - val_loss: 0.1969 - val_accuracy: 0.9167 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.0728 - accuracy: 0.9768 - val_loss: 0.2887 - val_accuracy: 0.8889 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 17s 63ms/step - loss: 0.0617 - accuracy: 0.9768 - val_loss: 0.2523 - val_accuracy: 0.8981 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 23s 85ms/step - loss: 0.3944 - accuracy: 0.8143 - val_loss: 0.7408 - val_accuracy: 0.6389 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 18s 66ms/step - loss: 0.3644 - accuracy: 0.8446 - val_loss: 1.2199 - val_accuracy: 0.5370 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 18s 67ms/step - loss: 0.3602 - accuracy: 0.8446 - val_loss: 1.4240 - val_accuracy: 0.5185 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 66ms/step - loss: 0.3747 - accuracy: 0.8321 - val_loss: 1.4556 - val_accuracy: 0.5093 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 18s 68ms/step - loss: 0.3385 - accuracy: 0.8500 - val_loss: 1.4229 - val_accuracy: 0.5185 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.3429 - accuracy: 0.8750 - val_loss: 1.4145 - val_accuracy: 0.5278 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.3076 - accuracy: 0.8786 - val_loss: 1.3926 - val_accuracy: 0.5463 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.3403 - accuracy: 0.8411 - val_loss: 1.4372 - val_accuracy: 0.5556 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 66ms/step - loss: 0.3292 - accuracy: 0.8571 - val_loss: 1.4292 - val_accuracy: 0.5556 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.3300 - accuracy: 0.8661 - val_loss: 1.3568 - val_accuracy: 0.5556 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 17s 66ms/step - loss: 0.3221 - accuracy: 0.8714 - val_loss: 1.3750 - val_accuracy: 0.5648 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 1s 784ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 1s 567ms/step\n",
      "\n",
      "=== Outer Fold 2 | Model: std_densenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 25s 100ms/step - loss: 0.7595 - accuracy: 0.4873 - val_loss: 0.6696 - val_accuracy: 0.6161 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.6893 - accuracy: 0.5509 - val_loss: 0.6662 - val_accuracy: 0.5804 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 15s 65ms/step - loss: 0.6648 - accuracy: 0.5800 - val_loss: 0.6610 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.6521 - accuracy: 0.5800 - val_loss: 0.6799 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.6502 - accuracy: 0.5945 - val_loss: 0.6608 - val_accuracy: 0.6161 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 15s 63ms/step - loss: 0.6454 - accuracy: 0.5545 - val_loss: 0.6349 - val_accuracy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.6113 - accuracy: 0.6291 - val_loss: 0.6453 - val_accuracy: 0.6071 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.6106 - accuracy: 0.6000 - val_loss: 0.6663 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.6014 - accuracy: 0.6145 - val_loss: 0.6182 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.6001 - accuracy: 0.6382 - val_loss: 0.6270 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.6148 - accuracy: 0.6091 - val_loss: 0.6465 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 17s 60ms/step - loss: 0.5944 - accuracy: 0.6255 - val_loss: 0.6391 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 16s 59ms/step - loss: 0.5752 - accuracy: 0.6327 - val_loss: 0.6627 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5989 - accuracy: 0.6109 - val_loss: 0.6458 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5920 - accuracy: 0.6382 - val_loss: 0.6315 - val_accuracy: 0.6429 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 15s 63ms/step - loss: 0.5886 - accuracy: 0.6327 - val_loss: 0.6042 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5708 - accuracy: 0.6545 - val_loss: 0.6599 - val_accuracy: 0.6161 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5927 - accuracy: 0.6345 - val_loss: 0.6186 - val_accuracy: 0.6518 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 16s 60ms/step - loss: 0.5584 - accuracy: 0.6745 - val_loss: 0.6347 - val_accuracy: 0.6607 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 16s 60ms/step - loss: 0.5590 - accuracy: 0.6600 - val_loss: 0.6250 - val_accuracy: 0.6339 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 17s 60ms/step - loss: 0.5732 - accuracy: 0.6255 - val_loss: 0.6809 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 15s 63ms/step - loss: 0.5780 - accuracy: 0.6327 - val_loss: 0.6783 - val_accuracy: 0.6250 - lr: 2.5000e-05\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5533 - accuracy: 0.6582 - val_loss: 0.6838 - val_accuracy: 0.6250 - lr: 2.5000e-05\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5810 - accuracy: 0.6273 - val_loss: 0.6919 - val_accuracy: 0.6429 - lr: 2.5000e-05\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5731 - accuracy: 0.6164 - val_loss: 0.6895 - val_accuracy: 0.6429 - lr: 2.5000e-05\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 15s 64ms/step - loss: 0.5627 - accuracy: 0.6709 - val_loss: 0.6667 - val_accuracy: 0.6518 - lr: 2.5000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 29s 125ms/step - loss: 0.8312 - accuracy: 0.5382 - val_loss: 0.6406 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 18s 86ms/step - loss: 0.6707 - accuracy: 0.6000 - val_loss: 0.6036 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 91ms/step - loss: 0.6346 - accuracy: 0.6164 - val_loss: 0.5838 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 0.6534 - accuracy: 0.6236 - val_loss: 0.6840 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 0.6392 - accuracy: 0.6255 - val_loss: 0.7137 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 0.6498 - accuracy: 0.6055 - val_loss: 0.6775 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 0.6115 - accuracy: 0.6309 - val_loss: 0.6167 - val_accuracy: 0.6964 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 80ms/step - loss: 0.6154 - accuracy: 0.6273 - val_loss: 0.6766 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 80ms/step - loss: 0.5866 - accuracy: 0.6418 - val_loss: 0.7102 - val_accuracy: 0.6161 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.5756 - accuracy: 0.6327 - val_loss: 0.7335 - val_accuracy: 0.6250 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 0.5543 - accuracy: 0.6691 - val_loss: 0.7197 - val_accuracy: 0.6429 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 17s 81ms/step - loss: 0.6071 - accuracy: 0.6400 - val_loss: 0.7117 - val_accuracy: 0.6696 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 17s 88ms/step - loss: 0.5786 - accuracy: 0.6309 - val_loss: 0.6794 - val_accuracy: 0.6696 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 26s 102ms/step - loss: 0.6726 - accuracy: 0.5800 - val_loss: 0.1976 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 15s 63ms/step - loss: 0.6409 - accuracy: 0.6218 - val_loss: 0.1960 - val_accuracy: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5995 - accuracy: 0.6218 - val_loss: 0.2349 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5771 - accuracy: 0.6236 - val_loss: 0.2327 - val_accuracy: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.6224 - accuracy: 0.6091 - val_loss: 0.2375 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 16s 60ms/step - loss: 0.5859 - accuracy: 0.6418 - val_loss: 0.2530 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5791 - accuracy: 0.6345 - val_loss: 0.2352 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 61ms/step - loss: 0.5872 - accuracy: 0.6055 - val_loss: 0.2519 - val_accuracy: 0.8929 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.6003 - accuracy: 0.6091 - val_loss: 0.2899 - val_accuracy: 0.9018 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 60ms/step - loss: 0.5693 - accuracy: 0.6582 - val_loss: 0.2662 - val_accuracy: 0.8929 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 15s 60ms/step - loss: 0.5423 - accuracy: 0.6509 - val_loss: 0.2906 - val_accuracy: 0.8750 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 15s 64ms/step - loss: 0.5609 - accuracy: 0.6655 - val_loss: 0.2404 - val_accuracy: 0.9196 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 30s 124ms/step - loss: 0.6803 - accuracy: 0.6000 - val_loss: 0.2413 - val_accuracy: 0.9107 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 85ms/step - loss: 0.6746 - accuracy: 0.5909 - val_loss: 0.2752 - val_accuracy: 0.8661 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 18s 87ms/step - loss: 0.6472 - accuracy: 0.6182 - val_loss: 0.2396 - val_accuracy: 0.9107 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 85ms/step - loss: 0.6016 - accuracy: 0.6291 - val_loss: 0.2295 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 17s 89ms/step - loss: 0.6287 - accuracy: 0.6000 - val_loss: 0.1967 - val_accuracy: 0.9196 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 82ms/step - loss: 0.6052 - accuracy: 0.6400 - val_loss: 0.2526 - val_accuracy: 0.9196 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 82ms/step - loss: 0.6112 - accuracy: 0.6218 - val_loss: 0.2950 - val_accuracy: 0.9107 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 82ms/step - loss: 0.5989 - accuracy: 0.6400 - val_loss: 0.2520 - val_accuracy: 0.8929 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 82ms/step - loss: 0.6194 - accuracy: 0.6055 - val_loss: 0.3338 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5879 - accuracy: 0.6218 - val_loss: 0.2577 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 86ms/step - loss: 0.5866 - accuracy: 0.5964 - val_loss: 0.2460 - val_accuracy: 0.8750 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 17s 82ms/step - loss: 0.5737 - accuracy: 0.6418 - val_loss: 0.2508 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5643 - accuracy: 0.6473 - val_loss: 0.2737 - val_accuracy: 0.8661 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5976 - accuracy: 0.6018 - val_loss: 0.2362 - val_accuracy: 0.9018 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.5704 - accuracy: 0.6418 - val_loss: 0.2634 - val_accuracy: 0.9018 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 27s 104ms/step - loss: 0.5958 - accuracy: 0.6482 - val_loss: 0.1502 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.5752 - accuracy: 0.6482 - val_loss: 0.1767 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.5796 - accuracy: 0.6393 - val_loss: 0.1996 - val_accuracy: 0.9352 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.5702 - accuracy: 0.6196 - val_loss: 0.1894 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.5596 - accuracy: 0.6393 - val_loss: 0.1972 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.5542 - accuracy: 0.6625 - val_loss: 0.1786 - val_accuracy: 0.9352 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 18s 61ms/step - loss: 0.5454 - accuracy: 0.6518 - val_loss: 0.1978 - val_accuracy: 0.9259 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.5296 - accuracy: 0.6643 - val_loss: 0.2383 - val_accuracy: 0.9167 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 17s 61ms/step - loss: 0.5383 - accuracy: 0.6482 - val_loss: 0.1737 - val_accuracy: 0.9352 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 61ms/step - loss: 0.5634 - accuracy: 0.6482 - val_loss: 0.2094 - val_accuracy: 0.9167 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 18s 65ms/step - loss: 0.5479 - accuracy: 0.6321 - val_loss: 0.2350 - val_accuracy: 0.9352 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 31s 126ms/step - loss: 0.5943 - accuracy: 0.6411 - val_loss: 0.2200 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 20s 86ms/step - loss: 0.5938 - accuracy: 0.6375 - val_loss: 0.1560 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 18s 83ms/step - loss: 0.5891 - accuracy: 0.6268 - val_loss: 0.2497 - val_accuracy: 0.9074 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 19s 85ms/step - loss: 0.6061 - accuracy: 0.6125 - val_loss: 0.3215 - val_accuracy: 0.8796 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 19s 83ms/step - loss: 0.6084 - accuracy: 0.6018 - val_loss: 0.2566 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 18s 82ms/step - loss: 0.5959 - accuracy: 0.6429 - val_loss: 0.1647 - val_accuracy: 0.9352 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 17s 81ms/step - loss: 0.5773 - accuracy: 0.6357 - val_loss: 0.1869 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 81ms/step - loss: 0.5327 - accuracy: 0.6804 - val_loss: 0.2246 - val_accuracy: 0.9352 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 18s 81ms/step - loss: 0.5743 - accuracy: 0.6464 - val_loss: 0.1738 - val_accuracy: 0.9352 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 18s 81ms/step - loss: 0.5524 - accuracy: 0.6393 - val_loss: 0.2037 - val_accuracy: 0.9074 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 17s 82ms/step - loss: 0.5523 - accuracy: 0.6482 - val_loss: 0.2203 - val_accuracy: 0.9074 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.5607 - accuracy: 0.6464 - val_loss: 0.2959 - val_accuracy: 0.8704 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "\n",
      "=== Outer Fold 2 | Model: std_mobilenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 17s 40ms/step - loss: 0.7467 - accuracy: 0.4945 - val_loss: 0.6824 - val_accuracy: 0.5268 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7264 - accuracy: 0.5164 - val_loss: 0.6783 - val_accuracy: 0.5089 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.7103 - accuracy: 0.5236 - val_loss: 0.6782 - val_accuracy: 0.5179 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.7166 - accuracy: 0.5182 - val_loss: 0.6791 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.7221 - accuracy: 0.5273 - val_loss: 0.6732 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7147 - accuracy: 0.5055 - val_loss: 0.6748 - val_accuracy: 0.5089 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 14s 28ms/step - loss: 0.7084 - accuracy: 0.5345 - val_loss: 0.6797 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.7113 - accuracy: 0.5327 - val_loss: 0.6779 - val_accuracy: 0.4554 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6998 - accuracy: 0.5509 - val_loss: 0.6854 - val_accuracy: 0.5268 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.7057 - accuracy: 0.5127 - val_loss: 0.6892 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 14s 32ms/step - loss: 0.7096 - accuracy: 0.5164 - val_loss: 0.6818 - val_accuracy: 0.5357 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6901 - accuracy: 0.5618 - val_loss: 0.6802 - val_accuracy: 0.4911 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7055 - accuracy: 0.5182 - val_loss: 0.6801 - val_accuracy: 0.4643 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.7118 - accuracy: 0.5145 - val_loss: 0.6756 - val_accuracy: 0.4821 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 13s 30ms/step - loss: 0.7071 - accuracy: 0.5091 - val_loss: 0.6801 - val_accuracy: 0.5179 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 17s 46ms/step - loss: 0.7642 - accuracy: 0.4855 - val_loss: 0.6772 - val_accuracy: 0.5089 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.7238 - accuracy: 0.5436 - val_loss: 0.6792 - val_accuracy: 0.4821 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.7277 - accuracy: 0.5091 - val_loss: 0.6815 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.7089 - accuracy: 0.5200 - val_loss: 0.6842 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.7022 - accuracy: 0.5655 - val_loss: 0.6888 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6741 - accuracy: 0.5836 - val_loss: 0.6971 - val_accuracy: 0.4821 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.6878 - accuracy: 0.5636 - val_loss: 0.7001 - val_accuracy: 0.5268 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.6512 - accuracy: 0.6000 - val_loss: 0.7113 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.6603 - accuracy: 0.5800 - val_loss: 0.7310 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.6608 - accuracy: 0.5982 - val_loss: 0.7336 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 14s 40ms/step - loss: 0.6430 - accuracy: 0.6073 - val_loss: 0.7444 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 19s 41ms/step - loss: 0.7204 - accuracy: 0.5036 - val_loss: 0.6670 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7152 - accuracy: 0.5091 - val_loss: 0.6748 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.7102 - accuracy: 0.5255 - val_loss: 0.6658 - val_accuracy: 0.5982 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7285 - accuracy: 0.4855 - val_loss: 0.6610 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7122 - accuracy: 0.4873 - val_loss: 0.6692 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7030 - accuracy: 0.5200 - val_loss: 0.6544 - val_accuracy: 0.7321 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6998 - accuracy: 0.5582 - val_loss: 0.6543 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 13s 26ms/step - loss: 0.7140 - accuracy: 0.4982 - val_loss: 0.6687 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.7070 - accuracy: 0.4982 - val_loss: 0.6636 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.7080 - accuracy: 0.5200 - val_loss: 0.6701 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6903 - accuracy: 0.5145 - val_loss: 0.6845 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7049 - accuracy: 0.4982 - val_loss: 0.6616 - val_accuracy: 0.7054 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 13s 30ms/step - loss: 0.6991 - accuracy: 0.5255 - val_loss: 0.6707 - val_accuracy: 0.5268 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6976 - accuracy: 0.5164 - val_loss: 0.6616 - val_accuracy: 0.6696 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6950 - accuracy: 0.5309 - val_loss: 0.6779 - val_accuracy: 0.4732 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6949 - accuracy: 0.5236 - val_loss: 0.6670 - val_accuracy: 0.6518 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6927 - accuracy: 0.5291 - val_loss: 0.6688 - val_accuracy: 0.6161 - lr: 2.5000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 17s 45ms/step - loss: 0.7712 - accuracy: 0.5000 - val_loss: 0.6570 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.7509 - accuracy: 0.4836 - val_loss: 0.6511 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.7028 - accuracy: 0.5164 - val_loss: 0.6468 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.7079 - accuracy: 0.5255 - val_loss: 0.6468 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.7021 - accuracy: 0.5382 - val_loss: 0.6409 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.7049 - accuracy: 0.5509 - val_loss: 0.6386 - val_accuracy: 0.7054 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.7079 - accuracy: 0.5436 - val_loss: 0.6415 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 13s 32ms/step - loss: 0.6827 - accuracy: 0.5509 - val_loss: 0.6396 - val_accuracy: 0.5714 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.6667 - accuracy: 0.5709 - val_loss: 0.6437 - val_accuracy: 0.5446 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.6773 - accuracy: 0.5836 - val_loss: 0.6410 - val_accuracy: 0.4554 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.6433 - accuracy: 0.6018 - val_loss: 0.6523 - val_accuracy: 0.4554 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.6609 - accuracy: 0.5527 - val_loss: 0.6515 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.6743 - accuracy: 0.5618 - val_loss: 0.6652 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 14s 37ms/step - loss: 0.6545 - accuracy: 0.5891 - val_loss: 0.6799 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6563 - accuracy: 0.6182 - val_loss: 0.6719 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6434 - accuracy: 0.6018 - val_loss: 0.6843 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 17s 41ms/step - loss: 0.6769 - accuracy: 0.5768 - val_loss: 0.7134 - val_accuracy: 0.4907 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.7013 - accuracy: 0.5500 - val_loss: 0.7098 - val_accuracy: 0.4907 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 13s 28ms/step - loss: 0.6988 - accuracy: 0.5357 - val_loss: 0.6984 - val_accuracy: 0.6204 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6936 - accuracy: 0.5250 - val_loss: 0.7126 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 15s 31ms/step - loss: 0.6847 - accuracy: 0.5554 - val_loss: 0.7177 - val_accuracy: 0.6296 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 15s 30ms/step - loss: 0.6905 - accuracy: 0.5161 - val_loss: 0.7065 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 14s 28ms/step - loss: 0.6802 - accuracy: 0.5446 - val_loss: 0.7056 - val_accuracy: 0.6852 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 27ms/step - loss: 0.6854 - accuracy: 0.5304 - val_loss: 0.7295 - val_accuracy: 0.5463 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6892 - accuracy: 0.4964 - val_loss: 0.7294 - val_accuracy: 0.6389 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 14s 28ms/step - loss: 0.6820 - accuracy: 0.5214 - val_loss: 0.7045 - val_accuracy: 0.6111 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 28ms/step - loss: 0.6794 - accuracy: 0.5339 - val_loss: 0.7181 - val_accuracy: 0.6481 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 15s 28ms/step - loss: 0.6760 - accuracy: 0.5732 - val_loss: 0.7187 - val_accuracy: 0.6111 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6815 - accuracy: 0.5357 - val_loss: 0.7299 - val_accuracy: 0.6389 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 18s 47ms/step - loss: 0.6978 - accuracy: 0.5446 - val_loss: 0.7034 - val_accuracy: 0.6296 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 15s 35ms/step - loss: 0.6980 - accuracy: 0.5321 - val_loss: 0.6997 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 35ms/step - loss: 0.6770 - accuracy: 0.5714 - val_loss: 0.7228 - val_accuracy: 0.6019 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 15s 34ms/step - loss: 0.6653 - accuracy: 0.5714 - val_loss: 0.7257 - val_accuracy: 0.6019 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 15s 34ms/step - loss: 0.6727 - accuracy: 0.5643 - val_loss: 0.7216 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 33ms/step - loss: 0.6699 - accuracy: 0.5643 - val_loss: 0.7458 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 15s 34ms/step - loss: 0.6501 - accuracy: 0.6054 - val_loss: 0.7576 - val_accuracy: 0.6296 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 34ms/step - loss: 0.6455 - accuracy: 0.5732 - val_loss: 0.7802 - val_accuracy: 0.4815 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 33ms/step - loss: 0.6299 - accuracy: 0.5982 - val_loss: 0.7850 - val_accuracy: 0.4815 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 13s 33ms/step - loss: 0.6499 - accuracy: 0.5839 - val_loss: 0.7862 - val_accuracy: 0.5463 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 32ms/step - loss: 0.6369 - accuracy: 0.5786 - val_loss: 0.8165 - val_accuracy: 0.5185 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 15s 39ms/step - loss: 0.6375 - accuracy: 0.5857 - val_loss: 0.8284 - val_accuracy: 0.5093 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 1s 734ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "\n",
      "=== Outer Fold 2 | Model: att_densenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 33s 217ms/step - loss: 0.7494 - accuracy: 0.5782 - val_loss: 0.5845 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 23s 176ms/step - loss: 0.6530 - accuracy: 0.6582 - val_loss: 0.5586 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 23s 175ms/step - loss: 0.5547 - accuracy: 0.7091 - val_loss: 0.5245 - val_accuracy: 0.7232 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 23s 175ms/step - loss: 0.5462 - accuracy: 0.7164 - val_loss: 0.5242 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 23s 171ms/step - loss: 0.4924 - accuracy: 0.7255 - val_loss: 0.5626 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 24s 171ms/step - loss: 0.4249 - accuracy: 0.8018 - val_loss: 0.5841 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.4488 - accuracy: 0.7727 - val_loss: 0.5989 - val_accuracy: 0.7232 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.3639 - accuracy: 0.8345 - val_loss: 0.8253 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 23s 169ms/step - loss: 0.2946 - accuracy: 0.8891 - val_loss: 0.7933 - val_accuracy: 0.6518 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 23s 171ms/step - loss: 0.2714 - accuracy: 0.8782 - val_loss: 0.9382 - val_accuracy: 0.6429 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.2194 - accuracy: 0.9091 - val_loss: 0.7596 - val_accuracy: 0.6518 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.2298 - accuracy: 0.9145 - val_loss: 1.0615 - val_accuracy: 0.6250 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 24s 170ms/step - loss: 0.1891 - accuracy: 0.9236 - val_loss: 1.1549 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 23s 174ms/step - loss: 0.1874 - accuracy: 0.9182 - val_loss: 0.9724 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 38s 237ms/step - loss: 0.5860 - accuracy: 0.6836 - val_loss: 0.4717 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.5280 - accuracy: 0.7145 - val_loss: 0.5173 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 24s 191ms/step - loss: 0.5404 - accuracy: 0.7218 - val_loss: 0.4708 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 24s 190ms/step - loss: 0.5130 - accuracy: 0.7455 - val_loss: 0.4585 - val_accuracy: 0.7857 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 24s 184ms/step - loss: 0.5086 - accuracy: 0.7400 - val_loss: 0.4844 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.5017 - accuracy: 0.7545 - val_loss: 0.4857 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 191ms/step - loss: 0.4789 - accuracy: 0.7636 - val_loss: 0.4542 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4641 - accuracy: 0.7727 - val_loss: 0.5409 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4713 - accuracy: 0.7636 - val_loss: 0.5035 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4459 - accuracy: 0.7764 - val_loss: 0.5401 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4380 - accuracy: 0.7727 - val_loss: 0.5403 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4567 - accuracy: 0.7727 - val_loss: 0.4802 - val_accuracy: 0.7857 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4600 - accuracy: 0.7782 - val_loss: 0.5905 - val_accuracy: 0.7232 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4316 - accuracy: 0.7782 - val_loss: 0.5036 - val_accuracy: 0.7589 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4488 - accuracy: 0.7873 - val_loss: 0.5293 - val_accuracy: 0.7500 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4272 - accuracy: 0.8000 - val_loss: 0.5973 - val_accuracy: 0.7768 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 24s 190ms/step - loss: 0.4444 - accuracy: 0.7927 - val_loss: 0.5757 - val_accuracy: 0.7321 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 34s 217ms/step - loss: 0.5495 - accuracy: 0.7127 - val_loss: 0.2089 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.4826 - accuracy: 0.7600 - val_loss: 0.2796 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.4691 - accuracy: 0.7582 - val_loss: 0.3372 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.4184 - accuracy: 0.7909 - val_loss: 0.4721 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.4039 - accuracy: 0.8182 - val_loss: 0.3935 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.3776 - accuracy: 0.8055 - val_loss: 0.6834 - val_accuracy: 0.7679 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 23s 170ms/step - loss: 0.3227 - accuracy: 0.8400 - val_loss: 0.4937 - val_accuracy: 0.8393 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 23s 171ms/step - loss: 0.3144 - accuracy: 0.8564 - val_loss: 0.4938 - val_accuracy: 0.8750 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 23s 171ms/step - loss: 0.3126 - accuracy: 0.8600 - val_loss: 0.5753 - val_accuracy: 0.7857 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 23s 171ms/step - loss: 0.2914 - accuracy: 0.8618 - val_loss: 0.4552 - val_accuracy: 0.8393 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 24s 175ms/step - loss: 0.2834 - accuracy: 0.8800 - val_loss: 0.4572 - val_accuracy: 0.8304 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 37s 233ms/step - loss: 0.4794 - accuracy: 0.7636 - val_loss: 0.2830 - val_accuracy: 0.8571 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 24s 191ms/step - loss: 0.4554 - accuracy: 0.7891 - val_loss: 0.2597 - val_accuracy: 0.8929 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4220 - accuracy: 0.7964 - val_loss: 0.2960 - val_accuracy: 0.8661 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4563 - accuracy: 0.7836 - val_loss: 0.2932 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4249 - accuracy: 0.7964 - val_loss: 0.3360 - val_accuracy: 0.8571 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 25s 189ms/step - loss: 0.4191 - accuracy: 0.7836 - val_loss: 0.3437 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4233 - accuracy: 0.8109 - val_loss: 0.3837 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4027 - accuracy: 0.8018 - val_loss: 0.3271 - val_accuracy: 0.8482 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.3820 - accuracy: 0.8109 - val_loss: 0.4211 - val_accuracy: 0.8214 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 185ms/step - loss: 0.4074 - accuracy: 0.8091 - val_loss: 0.3530 - val_accuracy: 0.8661 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4024 - accuracy: 0.8036 - val_loss: 0.3785 - val_accuracy: 0.8482 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 24s 191ms/step - loss: 0.4030 - accuracy: 0.8036 - val_loss: 0.3779 - val_accuracy: 0.8571 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 35s 219ms/step - loss: 0.4354 - accuracy: 0.7875 - val_loss: 0.2131 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 24s 176ms/step - loss: 0.3957 - accuracy: 0.8107 - val_loss: 0.1539 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 24s 170ms/step - loss: 0.3371 - accuracy: 0.8429 - val_loss: 0.3728 - val_accuracy: 0.8704 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 23s 170ms/step - loss: 0.3312 - accuracy: 0.8411 - val_loss: 0.3471 - val_accuracy: 0.8889 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 23s 170ms/step - loss: 0.3216 - accuracy: 0.8482 - val_loss: 0.5783 - val_accuracy: 0.8056 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 24s 171ms/step - loss: 0.2935 - accuracy: 0.8732 - val_loss: 0.4360 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 23s 171ms/step - loss: 0.3146 - accuracy: 0.8554 - val_loss: 0.3425 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 24s 170ms/step - loss: 0.2715 - accuracy: 0.8786 - val_loss: 0.2994 - val_accuracy: 0.8889 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 24s 170ms/step - loss: 0.2382 - accuracy: 0.8875 - val_loss: 0.4502 - val_accuracy: 0.8889 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 24s 170ms/step - loss: 0.2383 - accuracy: 0.8911 - val_loss: 0.5169 - val_accuracy: 0.8796 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 24s 171ms/step - loss: 0.2386 - accuracy: 0.8875 - val_loss: 0.3934 - val_accuracy: 0.8519 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 24s 175ms/step - loss: 0.2174 - accuracy: 0.9036 - val_loss: 0.4838 - val_accuracy: 0.9167 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 40s 240ms/step - loss: 0.3757 - accuracy: 0.8196 - val_loss: 0.2548 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 26s 192ms/step - loss: 0.3675 - accuracy: 0.8286 - val_loss: 0.1892 - val_accuracy: 0.9352 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.3340 - accuracy: 0.8304 - val_loss: 0.2242 - val_accuracy: 0.9074 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 26s 187ms/step - loss: 0.3390 - accuracy: 0.8357 - val_loss: 0.2759 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 25s 185ms/step - loss: 0.3254 - accuracy: 0.8554 - val_loss: 0.1952 - val_accuracy: 0.9074 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 26s 185ms/step - loss: 0.3200 - accuracy: 0.8518 - val_loss: 0.2911 - val_accuracy: 0.9074 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 26s 185ms/step - loss: 0.3517 - accuracy: 0.8321 - val_loss: 0.3000 - val_accuracy: 0.9074 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 25s 185ms/step - loss: 0.3153 - accuracy: 0.8625 - val_loss: 0.2183 - val_accuracy: 0.8981 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.3050 - accuracy: 0.8393 - val_loss: 0.2886 - val_accuracy: 0.8889 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 26s 192ms/step - loss: 0.3070 - accuracy: 0.8500 - val_loss: 0.1514 - val_accuracy: 0.9259 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 26s 186ms/step - loss: 0.3055 - accuracy: 0.8589 - val_loss: 0.3502 - val_accuracy: 0.8981 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.2951 - accuracy: 0.8661 - val_loss: 0.1979 - val_accuracy: 0.9259 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 26s 187ms/step - loss: 0.3010 - accuracy: 0.8750 - val_loss: 0.3345 - val_accuracy: 0.8889 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 26s 186ms/step - loss: 0.2942 - accuracy: 0.8661 - val_loss: 0.3231 - val_accuracy: 0.9074 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 25s 187ms/step - loss: 0.3067 - accuracy: 0.8679 - val_loss: 0.3186 - val_accuracy: 0.8981 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 24s 185ms/step - loss: 0.2925 - accuracy: 0.8643 - val_loss: 0.2282 - val_accuracy: 0.8981 - lr: 2.5000e-06\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 24s 186ms/step - loss: 0.3018 - accuracy: 0.8607 - val_loss: 0.2614 - val_accuracy: 0.9074 - lr: 2.5000e-06\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 24s 185ms/step - loss: 0.3159 - accuracy: 0.8446 - val_loss: 0.3488 - val_accuracy: 0.8796 - lr: 2.5000e-06\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 24s 185ms/step - loss: 0.2776 - accuracy: 0.8714 - val_loss: 0.1811 - val_accuracy: 0.9167 - lr: 2.5000e-06\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 24s 189ms/step - loss: 0.3041 - accuracy: 0.8589 - val_loss: 0.2111 - val_accuracy: 0.8889 - lr: 2.5000e-06\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "\n",
      "=== Outer Fold 2 | Model: att_mobilenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 20s 78ms/step - loss: 0.6593 - accuracy: 0.6473 - val_loss: 0.6045 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 15s 63ms/step - loss: 0.6096 - accuracy: 0.6618 - val_loss: 0.5805 - val_accuracy: 0.7679 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.5408 - accuracy: 0.7164 - val_loss: 0.5507 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 15s 62ms/step - loss: 0.4484 - accuracy: 0.7891 - val_loss: 0.5418 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 15s 63ms/step - loss: 0.3797 - accuracy: 0.8345 - val_loss: 0.5373 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.2910 - accuracy: 0.8782 - val_loss: 0.7099 - val_accuracy: 0.6071 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.2545 - accuracy: 0.8982 - val_loss: 0.7355 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.2325 - accuracy: 0.9073 - val_loss: 0.7703 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1852 - accuracy: 0.9327 - val_loss: 0.7181 - val_accuracy: 0.7321 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1445 - accuracy: 0.9436 - val_loss: 1.0356 - val_accuracy: 0.6518 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 61ms/step - loss: 0.0899 - accuracy: 0.9745 - val_loss: 1.0849 - val_accuracy: 0.7232 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.1190 - accuracy: 0.9509 - val_loss: 1.0673 - val_accuracy: 0.7054 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.0907 - accuracy: 0.9636 - val_loss: 1.0023 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 15s 63ms/step - loss: 0.0949 - accuracy: 0.9618 - val_loss: 1.4053 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 15s 62ms/step - loss: 0.0826 - accuracy: 0.9727 - val_loss: 1.3711 - val_accuracy: 0.6518 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 20s 83ms/step - loss: 0.6095 - accuracy: 0.6818 - val_loss: 0.5425 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.5754 - accuracy: 0.6945 - val_loss: 0.5492 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 69ms/step - loss: 0.5656 - accuracy: 0.6945 - val_loss: 0.5741 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 68ms/step - loss: 0.5572 - accuracy: 0.7109 - val_loss: 0.5806 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.5429 - accuracy: 0.7073 - val_loss: 0.6058 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.5462 - accuracy: 0.7164 - val_loss: 0.6301 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 66ms/step - loss: 0.5221 - accuracy: 0.7364 - val_loss: 0.6472 - val_accuracy: 0.5982 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.5221 - accuracy: 0.7509 - val_loss: 0.6666 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 66ms/step - loss: 0.5176 - accuracy: 0.7600 - val_loss: 0.6808 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 15s 67ms/step - loss: 0.5157 - accuracy: 0.7527 - val_loss: 0.7094 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 68ms/step - loss: 0.5245 - accuracy: 0.7364 - val_loss: 0.7248 - val_accuracy: 0.5982 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 20s 77ms/step - loss: 0.4235 - accuracy: 0.8127 - val_loss: 0.5662 - val_accuracy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.3131 - accuracy: 0.8600 - val_loss: 0.6031 - val_accuracy: 0.6161 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.3056 - accuracy: 0.8655 - val_loss: 0.4319 - val_accuracy: 0.8036 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 15s 61ms/step - loss: 0.2512 - accuracy: 0.9145 - val_loss: 0.4436 - val_accuracy: 0.7679 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.1866 - accuracy: 0.9309 - val_loss: 0.3488 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 16s 65ms/step - loss: 0.2118 - accuracy: 0.9109 - val_loss: 0.8991 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 16s 61ms/step - loss: 0.1403 - accuracy: 0.9564 - val_loss: 0.5056 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 15s 62ms/step - loss: 0.1455 - accuracy: 0.9545 - val_loss: 0.5403 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 15s 64ms/step - loss: 0.1095 - accuracy: 0.9636 - val_loss: 0.7211 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 17s 63ms/step - loss: 0.1212 - accuracy: 0.9491 - val_loss: 0.8692 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 18s 64ms/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 0.7907 - val_accuracy: 0.7500 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 18s 64ms/step - loss: 0.0994 - accuracy: 0.9618 - val_loss: 0.9284 - val_accuracy: 0.7411 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 18s 64ms/step - loss: 0.0661 - accuracy: 0.9782 - val_loss: 0.7813 - val_accuracy: 0.7500 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 18s 64ms/step - loss: 0.0630 - accuracy: 0.9836 - val_loss: 0.8533 - val_accuracy: 0.7321 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 18s 66ms/step - loss: 0.0632 - accuracy: 0.9800 - val_loss: 0.7061 - val_accuracy: 0.7500 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 24s 89ms/step - loss: 0.5295 - accuracy: 0.7255 - val_loss: 0.4875 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4937 - accuracy: 0.7527 - val_loss: 0.5579 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 68ms/step - loss: 0.5071 - accuracy: 0.7436 - val_loss: 0.6438 - val_accuracy: 0.5982 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 68ms/step - loss: 0.4983 - accuracy: 0.7455 - val_loss: 0.6952 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.4730 - accuracy: 0.7836 - val_loss: 0.7168 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4574 - accuracy: 0.7691 - val_loss: 0.6977 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 16s 68ms/step - loss: 0.4521 - accuracy: 0.7745 - val_loss: 0.6958 - val_accuracy: 0.5982 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.4512 - accuracy: 0.7909 - val_loss: 0.7225 - val_accuracy: 0.5982 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 67ms/step - loss: 0.4341 - accuracy: 0.7909 - val_loss: 0.7337 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 69ms/step - loss: 0.4647 - accuracy: 0.7673 - val_loss: 0.7438 - val_accuracy: 0.5804 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 67ms/step - loss: 0.4374 - accuracy: 0.7927 - val_loss: 0.7223 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 23s 77ms/step - loss: 0.3153 - accuracy: 0.8536 - val_loss: 0.3690 - val_accuracy: 0.8519 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 62ms/step - loss: 0.2551 - accuracy: 0.8893 - val_loss: 0.3102 - val_accuracy: 0.8796 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.2143 - accuracy: 0.9071 - val_loss: 0.2834 - val_accuracy: 0.8519 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 61ms/step - loss: 0.1941 - accuracy: 0.9232 - val_loss: 0.4190 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 61ms/step - loss: 0.1596 - accuracy: 0.9393 - val_loss: 0.4625 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 61ms/step - loss: 0.1605 - accuracy: 0.9286 - val_loss: 0.4227 - val_accuracy: 0.8241 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 61ms/step - loss: 0.1221 - accuracy: 0.9589 - val_loss: 0.5236 - val_accuracy: 0.8056 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.0923 - accuracy: 0.9696 - val_loss: 0.5789 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 18s 65ms/step - loss: 0.1038 - accuracy: 0.9661 - val_loss: 0.4681 - val_accuracy: 0.8333 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 19s 66ms/step - loss: 0.0966 - accuracy: 0.9643 - val_loss: 0.5671 - val_accuracy: 0.7963 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 19s 66ms/step - loss: 0.0693 - accuracy: 0.9768 - val_loss: 0.4681 - val_accuracy: 0.8241 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 19s 65ms/step - loss: 0.0538 - accuracy: 0.9857 - val_loss: 0.5445 - val_accuracy: 0.8241 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 18s 66ms/step - loss: 0.0697 - accuracy: 0.9714 - val_loss: 0.3366 - val_accuracy: 0.8519 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 23s 88ms/step - loss: 0.4999 - accuracy: 0.7321 - val_loss: 0.4779 - val_accuracy: 0.7778 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 18s 69ms/step - loss: 0.4420 - accuracy: 0.7875 - val_loss: 0.5020 - val_accuracy: 0.7685 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.4359 - accuracy: 0.7857 - val_loss: 0.5419 - val_accuracy: 0.7870 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.4275 - accuracy: 0.8018 - val_loss: 0.5750 - val_accuracy: 0.7407 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 17s 72ms/step - loss: 0.4135 - accuracy: 0.8036 - val_loss: 0.6086 - val_accuracy: 0.7037 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.4059 - accuracy: 0.7946 - val_loss: 0.6583 - val_accuracy: 0.6574 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.3852 - accuracy: 0.8268 - val_loss: 0.7005 - val_accuracy: 0.6481 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.4067 - accuracy: 0.7839 - val_loss: 0.7284 - val_accuracy: 0.6389 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 18s 66ms/step - loss: 0.3939 - accuracy: 0.8125 - val_loss: 0.7501 - val_accuracy: 0.6204 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 17s 66ms/step - loss: 0.3882 - accuracy: 0.8196 - val_loss: 0.7977 - val_accuracy: 0.6204 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3787 - accuracy: 0.8107 - val_loss: 0.8651 - val_accuracy: 0.6296 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 1s 795ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "\n",
      "=== Outer Fold 3 | Model: std_densenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 27s 106ms/step - loss: 0.7440 - accuracy: 0.4945 - val_loss: 0.6674 - val_accuracy: 0.5982 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 67ms/step - loss: 0.6899 - accuracy: 0.5309 - val_loss: 0.6003 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.6516 - accuracy: 0.5836 - val_loss: 0.5901 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 71ms/step - loss: 0.6537 - accuracy: 0.5527 - val_loss: 0.5811 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 19s 65ms/step - loss: 0.6493 - accuracy: 0.6091 - val_loss: 0.5884 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 19s 71ms/step - loss: 0.6197 - accuracy: 0.6091 - val_loss: 0.5803 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 19s 71ms/step - loss: 0.6077 - accuracy: 0.6327 - val_loss: 0.5755 - val_accuracy: 0.7411 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.6101 - accuracy: 0.6073 - val_loss: 0.5816 - val_accuracy: 0.7411 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 65ms/step - loss: 0.6039 - accuracy: 0.6345 - val_loss: 0.5969 - val_accuracy: 0.7232 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.6232 - accuracy: 0.5927 - val_loss: 0.6707 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.6040 - accuracy: 0.6164 - val_loss: 0.5957 - val_accuracy: 0.7679 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.5988 - accuracy: 0.6327 - val_loss: 0.5858 - val_accuracy: 0.7411 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.5901 - accuracy: 0.6273 - val_loss: 0.6383 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.5682 - accuracy: 0.6436 - val_loss: 0.6457 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5820 - accuracy: 0.6291 - val_loss: 0.6256 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5709 - accuracy: 0.6564 - val_loss: 0.5940 - val_accuracy: 0.7411 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 19s 71ms/step - loss: 0.5889 - accuracy: 0.6182 - val_loss: 0.6303 - val_accuracy: 0.7054 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 36s 153ms/step - loss: 0.7602 - accuracy: 0.5436 - val_loss: 0.6683 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 20s 90ms/step - loss: 0.6538 - accuracy: 0.5909 - val_loss: 0.6889 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 19s 88ms/step - loss: 0.6558 - accuracy: 0.6055 - val_loss: 0.7112 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 19s 93ms/step - loss: 0.6692 - accuracy: 0.5782 - val_loss: 0.6481 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 17s 89ms/step - loss: 0.6174 - accuracy: 0.6218 - val_loss: 0.6934 - val_accuracy: 0.7232 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 18s 89ms/step - loss: 0.6368 - accuracy: 0.5836 - val_loss: 0.6592 - val_accuracy: 0.7054 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 18s 93ms/step - loss: 0.6084 - accuracy: 0.6164 - val_loss: 0.6226 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 18s 87ms/step - loss: 0.5918 - accuracy: 0.6436 - val_loss: 0.6454 - val_accuracy: 0.7232 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 18s 91ms/step - loss: 0.5890 - accuracy: 0.6709 - val_loss: 0.6671 - val_accuracy: 0.7143 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.6092 - accuracy: 0.6236 - val_loss: 0.6694 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 20s 93ms/step - loss: 0.6014 - accuracy: 0.6618 - val_loss: 0.6096 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 19s 89ms/step - loss: 0.5789 - accuracy: 0.6545 - val_loss: 0.6557 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 20s 91ms/step - loss: 0.5542 - accuracy: 0.6727 - val_loss: 0.6625 - val_accuracy: 0.7411 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 20s 91ms/step - loss: 0.6014 - accuracy: 0.6109 - val_loss: 0.6541 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 19s 89ms/step - loss: 0.6040 - accuracy: 0.6000 - val_loss: 0.7276 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 18s 87ms/step - loss: 0.5602 - accuracy: 0.6545 - val_loss: 0.6923 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 19s 89ms/step - loss: 0.5742 - accuracy: 0.6327 - val_loss: 0.7168 - val_accuracy: 0.7232 - lr: 5.0000e-06\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 19s 88ms/step - loss: 0.5440 - accuracy: 0.6836 - val_loss: 0.6613 - val_accuracy: 0.7589 - lr: 5.0000e-06\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 19s 90ms/step - loss: 0.5695 - accuracy: 0.6291 - val_loss: 0.7307 - val_accuracy: 0.7411 - lr: 5.0000e-06\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.5698 - accuracy: 0.6418 - val_loss: 0.8043 - val_accuracy: 0.7143 - lr: 5.0000e-06\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 19s 102ms/step - loss: 0.5610 - accuracy: 0.6273 - val_loss: 0.7628 - val_accuracy: 0.7054 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 30s 120ms/step - loss: 0.6550 - accuracy: 0.5945 - val_loss: 0.1720 - val_accuracy: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 18s 70ms/step - loss: 0.6318 - accuracy: 0.6109 - val_loss: 0.1651 - val_accuracy: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.6265 - accuracy: 0.6164 - val_loss: 0.1756 - val_accuracy: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 70ms/step - loss: 0.6213 - accuracy: 0.6000 - val_loss: 0.1554 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.6027 - accuracy: 0.5964 - val_loss: 0.2100 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5889 - accuracy: 0.6091 - val_loss: 0.1800 - val_accuracy: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.5824 - accuracy: 0.6255 - val_loss: 0.1717 - val_accuracy: 0.9554 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5676 - accuracy: 0.6400 - val_loss: 0.2028 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.5651 - accuracy: 0.6382 - val_loss: 0.2721 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5670 - accuracy: 0.6291 - val_loss: 0.1770 - val_accuracy: 0.9554 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 66ms/step - loss: 0.5678 - accuracy: 0.6236 - val_loss: 0.1952 - val_accuracy: 0.9464 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 19s 66ms/step - loss: 0.5437 - accuracy: 0.6473 - val_loss: 0.1996 - val_accuracy: 0.9375 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 18s 65ms/step - loss: 0.5403 - accuracy: 0.6491 - val_loss: 0.2159 - val_accuracy: 0.9286 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 18s 69ms/step - loss: 0.5565 - accuracy: 0.6182 - val_loss: 0.2189 - val_accuracy: 0.9196 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 31s 138ms/step - loss: 0.6321 - accuracy: 0.6091 - val_loss: 0.1805 - val_accuracy: 0.9643 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 19s 95ms/step - loss: 0.6005 - accuracy: 0.6309 - val_loss: 0.1752 - val_accuracy: 0.9643 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.6025 - accuracy: 0.6473 - val_loss: 0.1809 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 88ms/step - loss: 0.5884 - accuracy: 0.6091 - val_loss: 0.1892 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.5905 - accuracy: 0.6382 - val_loss: 0.1925 - val_accuracy: 0.9375 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 19s 93ms/step - loss: 0.5977 - accuracy: 0.6200 - val_loss: 0.1434 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 18s 83ms/step - loss: 0.5769 - accuracy: 0.6145 - val_loss: 0.1836 - val_accuracy: 0.9375 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.5787 - accuracy: 0.6600 - val_loss: 0.1814 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.5581 - accuracy: 0.6782 - val_loss: 0.1318 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 18s 91ms/step - loss: 0.5766 - accuracy: 0.6200 - val_loss: 0.1512 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 19s 89ms/step - loss: 0.5561 - accuracy: 0.6600 - val_loss: 0.1843 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.5701 - accuracy: 0.6400 - val_loss: 0.1620 - val_accuracy: 0.9375 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.5569 - accuracy: 0.6455 - val_loss: 0.1655 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 19s 88ms/step - loss: 0.5590 - accuracy: 0.6236 - val_loss: 0.1414 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.5460 - accuracy: 0.6473 - val_loss: 0.2139 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 18s 90ms/step - loss: 0.5473 - accuracy: 0.6545 - val_loss: 0.1850 - val_accuracy: 0.9196 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 19s 89ms/step - loss: 0.5414 - accuracy: 0.6509 - val_loss: 0.2181 - val_accuracy: 0.9196 - lr: 5.0000e-06\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 18s 91ms/step - loss: 0.5437 - accuracy: 0.6418 - val_loss: 0.1753 - val_accuracy: 0.9375 - lr: 5.0000e-06\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 18s 93ms/step - loss: 0.5462 - accuracy: 0.6109 - val_loss: 0.1699 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 28s 111ms/step - loss: 0.5805 - accuracy: 0.6089 - val_loss: 0.1890 - val_accuracy: 0.9352 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 74ms/step - loss: 0.5356 - accuracy: 0.6429 - val_loss: 0.1632 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 64ms/step - loss: 0.5414 - accuracy: 0.6661 - val_loss: 0.2912 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 66ms/step - loss: 0.5641 - accuracy: 0.6500 - val_loss: 0.2336 - val_accuracy: 0.8889 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.5265 - accuracy: 0.6536 - val_loss: 0.2061 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.5565 - accuracy: 0.6411 - val_loss: 0.1090 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 17s 64ms/step - loss: 0.5517 - accuracy: 0.6393 - val_loss: 0.1589 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.5215 - accuracy: 0.6714 - val_loss: 0.1732 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.5537 - accuracy: 0.6411 - val_loss: 0.2025 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 17s 64ms/step - loss: 0.5275 - accuracy: 0.6696 - val_loss: 0.2201 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.5389 - accuracy: 0.6536 - val_loss: 0.1321 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.5160 - accuracy: 0.6500 - val_loss: 0.1835 - val_accuracy: 0.9074 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.5221 - accuracy: 0.6786 - val_loss: 0.1668 - val_accuracy: 0.9074 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.5336 - accuracy: 0.6589 - val_loss: 0.2302 - val_accuracy: 0.9259 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 19s 67ms/step - loss: 0.5222 - accuracy: 0.6554 - val_loss: 0.2546 - val_accuracy: 0.8981 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 18s 69ms/step - loss: 0.5163 - accuracy: 0.6304 - val_loss: 0.1810 - val_accuracy: 0.9074 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 31s 134ms/step - loss: 0.5983 - accuracy: 0.6196 - val_loss: 0.2364 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 19s 92ms/step - loss: 0.5750 - accuracy: 0.6196 - val_loss: 0.1679 - val_accuracy: 0.9352 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 19s 90ms/step - loss: 0.5458 - accuracy: 0.6661 - val_loss: 0.2164 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 18s 90ms/step - loss: 0.5642 - accuracy: 0.6464 - val_loss: 0.2807 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 20s 88ms/step - loss: 0.5671 - accuracy: 0.6482 - val_loss: 0.2120 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 18s 88ms/step - loss: 0.5377 - accuracy: 0.6732 - val_loss: 0.3076 - val_accuracy: 0.8704 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 18s 89ms/step - loss: 0.5373 - accuracy: 0.6661 - val_loss: 0.2199 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 18s 88ms/step - loss: 0.5359 - accuracy: 0.6357 - val_loss: 0.2065 - val_accuracy: 0.9259 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 18s 89ms/step - loss: 0.5513 - accuracy: 0.6500 - val_loss: 0.2536 - val_accuracy: 0.8889 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 18s 88ms/step - loss: 0.5394 - accuracy: 0.6589 - val_loss: 0.2641 - val_accuracy: 0.9259 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 19s 89ms/step - loss: 0.5287 - accuracy: 0.6821 - val_loss: 0.1839 - val_accuracy: 0.9167 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 20s 95ms/step - loss: 0.5487 - accuracy: 0.6607 - val_loss: 0.2310 - val_accuracy: 0.9167 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "\n",
      "=== Outer Fold 3 | Model: std_mobilenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 19s 45ms/step - loss: 0.7153 - accuracy: 0.4982 - val_loss: 0.6910 - val_accuracy: 0.5179 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 32ms/step - loss: 0.7234 - accuracy: 0.5182 - val_loss: 0.6916 - val_accuracy: 0.5179 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 15s 32ms/step - loss: 0.7195 - accuracy: 0.5073 - val_loss: 0.6842 - val_accuracy: 0.5536 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 14s 31ms/step - loss: 0.7122 - accuracy: 0.5127 - val_loss: 0.6821 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 15s 31ms/step - loss: 0.7172 - accuracy: 0.5145 - val_loss: 0.6806 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 15s 31ms/step - loss: 0.7145 - accuracy: 0.5018 - val_loss: 0.6792 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 30ms/step - loss: 0.7016 - accuracy: 0.5091 - val_loss: 0.6718 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.6927 - accuracy: 0.5382 - val_loss: 0.6727 - val_accuracy: 0.5089 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.7088 - accuracy: 0.4964 - val_loss: 0.6715 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 14s 32ms/step - loss: 0.7058 - accuracy: 0.4945 - val_loss: 0.6761 - val_accuracy: 0.6161 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 14s 31ms/step - loss: 0.7070 - accuracy: 0.4909 - val_loss: 0.6742 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 15s 33ms/step - loss: 0.6815 - accuracy: 0.5600 - val_loss: 0.6703 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.6975 - accuracy: 0.5200 - val_loss: 0.6722 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6946 - accuracy: 0.5400 - val_loss: 0.6711 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6897 - accuracy: 0.5291 - val_loss: 0.6739 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 15s 31ms/step - loss: 0.7005 - accuracy: 0.5145 - val_loss: 0.6718 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 17s 35ms/step - loss: 0.6797 - accuracy: 0.5727 - val_loss: 0.6648 - val_accuracy: 0.5446 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 15s 28ms/step - loss: 0.6952 - accuracy: 0.5218 - val_loss: 0.6685 - val_accuracy: 0.5089 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6949 - accuracy: 0.4927 - val_loss: 0.6733 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6895 - accuracy: 0.5400 - val_loss: 0.6663 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6861 - accuracy: 0.5509 - val_loss: 0.6651 - val_accuracy: 0.6518 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6868 - accuracy: 0.5455 - val_loss: 0.6763 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6841 - accuracy: 0.5309 - val_loss: 0.6685 - val_accuracy: 0.5357 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 13s 30ms/step - loss: 0.6842 - accuracy: 0.5400 - val_loss: 0.6644 - val_accuracy: 0.5089 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6768 - accuracy: 0.5618 - val_loss: 0.6747 - val_accuracy: 0.5268 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 13s 30ms/step - loss: 0.6840 - accuracy: 0.5382 - val_loss: 0.6603 - val_accuracy: 0.5089 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6919 - accuracy: 0.5073 - val_loss: 0.6723 - val_accuracy: 0.5179 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6791 - accuracy: 0.5473 - val_loss: 0.6654 - val_accuracy: 0.5089 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 13s 30ms/step - loss: 0.6810 - accuracy: 0.5509 - val_loss: 0.6626 - val_accuracy: 0.5089 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6738 - accuracy: 0.5709 - val_loss: 0.6662 - val_accuracy: 0.4821 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6793 - accuracy: 0.5455 - val_loss: 0.6635 - val_accuracy: 0.5179 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6791 - accuracy: 0.5418 - val_loss: 0.6607 - val_accuracy: 0.5179 - lr: 2.5000e-05\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6800 - accuracy: 0.5455 - val_loss: 0.6723 - val_accuracy: 0.4821 - lr: 2.5000e-05\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6748 - accuracy: 0.5782 - val_loss: 0.6733 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6803 - accuracy: 0.5527 - val_loss: 0.6682 - val_accuracy: 0.5179 - lr: 2.5000e-05\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 13s 30ms/step - loss: 0.6772 - accuracy: 0.5509 - val_loss: 0.6615 - val_accuracy: 0.5000 - lr: 2.5000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 18s 48ms/step - loss: 1.2199 - accuracy: 0.5236 - val_loss: 0.6852 - val_accuracy: 0.5268 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.7764 - accuracy: 0.5073 - val_loss: 0.6757 - val_accuracy: 0.5357 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 14s 38ms/step - loss: 0.7678 - accuracy: 0.4964 - val_loss: 0.6701 - val_accuracy: 0.5179 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.7277 - accuracy: 0.5364 - val_loss: 0.6626 - val_accuracy: 0.5179 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.7010 - accuracy: 0.5709 - val_loss: 0.6558 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.7167 - accuracy: 0.5400 - val_loss: 0.6519 - val_accuracy: 0.5982 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6939 - accuracy: 0.5527 - val_loss: 0.6489 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6759 - accuracy: 0.5618 - val_loss: 0.6482 - val_accuracy: 0.6339 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6711 - accuracy: 0.5800 - val_loss: 0.6456 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6693 - accuracy: 0.5600 - val_loss: 0.6593 - val_accuracy: 0.6339 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6555 - accuracy: 0.5982 - val_loss: 0.6565 - val_accuracy: 0.5982 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6812 - accuracy: 0.5636 - val_loss: 0.6580 - val_accuracy: 0.5893 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 14s 38ms/step - loss: 0.6515 - accuracy: 0.5836 - val_loss: 0.6516 - val_accuracy: 0.5893 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6512 - accuracy: 0.6000 - val_loss: 0.6659 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6421 - accuracy: 0.6036 - val_loss: 0.6700 - val_accuracy: 0.5804 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6374 - accuracy: 0.5818 - val_loss: 0.6736 - val_accuracy: 0.5179 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6411 - accuracy: 0.6073 - val_loss: 0.6784 - val_accuracy: 0.5625 - lr: 5.0000e-06\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6385 - accuracy: 0.6109 - val_loss: 0.6816 - val_accuracy: 0.5625 - lr: 5.0000e-06\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 14s 38ms/step - loss: 0.6399 - accuracy: 0.6200 - val_loss: 0.6870 - val_accuracy: 0.5536 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 18s 42ms/step - loss: 0.6943 - accuracy: 0.5400 - val_loss: 0.6804 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6867 - accuracy: 0.5291 - val_loss: 0.7216 - val_accuracy: 0.3839 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.6916 - accuracy: 0.5291 - val_loss: 0.7090 - val_accuracy: 0.3839 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 15s 30ms/step - loss: 0.6895 - accuracy: 0.5400 - val_loss: 0.7305 - val_accuracy: 0.3304 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6884 - accuracy: 0.5055 - val_loss: 0.7228 - val_accuracy: 0.3482 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.6820 - accuracy: 0.5455 - val_loss: 0.7140 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 29ms/step - loss: 0.6818 - accuracy: 0.5036 - val_loss: 0.7052 - val_accuracy: 0.5446 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 15s 30ms/step - loss: 0.6865 - accuracy: 0.4909 - val_loss: 0.6990 - val_accuracy: 0.4464 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 14s 28ms/step - loss: 0.6717 - accuracy: 0.5364 - val_loss: 0.7052 - val_accuracy: 0.4107 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6716 - accuracy: 0.5564 - val_loss: 0.7141 - val_accuracy: 0.3661 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 15s 31ms/step - loss: 0.6688 - accuracy: 0.5873 - val_loss: 0.7221 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 20s 49ms/step - loss: 0.7147 - accuracy: 0.5564 - val_loss: 0.6802 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 15s 36ms/step - loss: 0.7117 - accuracy: 0.5364 - val_loss: 0.6879 - val_accuracy: 0.5714 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 15s 35ms/step - loss: 0.6898 - accuracy: 0.5527 - val_loss: 0.6817 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 37ms/step - loss: 0.6784 - accuracy: 0.5655 - val_loss: 0.6775 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 15s 35ms/step - loss: 0.6686 - accuracy: 0.5855 - val_loss: 0.6961 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 15s 35ms/step - loss: 0.6613 - accuracy: 0.5982 - val_loss: 0.6907 - val_accuracy: 0.5714 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6644 - accuracy: 0.5782 - val_loss: 0.6879 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6487 - accuracy: 0.6127 - val_loss: 0.6827 - val_accuracy: 0.5714 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6674 - accuracy: 0.6000 - val_loss: 0.6813 - val_accuracy: 0.5714 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.6462 - accuracy: 0.5873 - val_loss: 0.6783 - val_accuracy: 0.5625 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 14s 37ms/step - loss: 0.6433 - accuracy: 0.5964 - val_loss: 0.6693 - val_accuracy: 0.5714 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6374 - accuracy: 0.6000 - val_loss: 0.6724 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6662 - accuracy: 0.5618 - val_loss: 0.6684 - val_accuracy: 0.5982 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6370 - accuracy: 0.6200 - val_loss: 0.6537 - val_accuracy: 0.6071 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6410 - accuracy: 0.5618 - val_loss: 0.6714 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6327 - accuracy: 0.6200 - val_loss: 0.6641 - val_accuracy: 0.5804 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6437 - accuracy: 0.5927 - val_loss: 0.6475 - val_accuracy: 0.5982 - lr: 5.0000e-06\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6509 - accuracy: 0.5582 - val_loss: 0.6514 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6416 - accuracy: 0.5709 - val_loss: 0.6494 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 14s 37ms/step - loss: 0.6401 - accuracy: 0.6255 - val_loss: 0.6524 - val_accuracy: 0.6429 - lr: 5.0000e-06\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6388 - accuracy: 0.6091 - val_loss: 0.6621 - val_accuracy: 0.6161 - lr: 5.0000e-06\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6206 - accuracy: 0.5945 - val_loss: 0.6151 - val_accuracy: 0.7143 - lr: 5.0000e-06\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6574 - accuracy: 0.5727 - val_loss: 0.6264 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6400 - accuracy: 0.5764 - val_loss: 0.6277 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6358 - accuracy: 0.6255 - val_loss: 0.6284 - val_accuracy: 0.7054 - lr: 5.0000e-06\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6306 - accuracy: 0.6055 - val_loss: 0.6179 - val_accuracy: 0.6964 - lr: 5.0000e-06\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6392 - accuracy: 0.6018 - val_loss: 0.6220 - val_accuracy: 0.7143 - lr: 5.0000e-06\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6374 - accuracy: 0.5909 - val_loss: 0.6180 - val_accuracy: 0.6964 - lr: 2.5000e-06\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6394 - accuracy: 0.5782 - val_loss: 0.6085 - val_accuracy: 0.7143 - lr: 2.5000e-06\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6257 - accuracy: 0.5964 - val_loss: 0.6081 - val_accuracy: 0.7143 - lr: 2.5000e-06\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6348 - accuracy: 0.5764 - val_loss: 0.6153 - val_accuracy: 0.6696 - lr: 2.5000e-06\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6131 - accuracy: 0.6164 - val_loss: 0.5915 - val_accuracy: 0.7411 - lr: 2.5000e-06\n",
      "Epoch 33/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6185 - accuracy: 0.6236 - val_loss: 0.6140 - val_accuracy: 0.6875 - lr: 2.5000e-06\n",
      "Epoch 34/100\n",
      "69/69 [==============================] - 13s 33ms/step - loss: 0.6086 - accuracy: 0.6273 - val_loss: 0.6177 - val_accuracy: 0.6964 - lr: 2.5000e-06\n",
      "Epoch 35/100\n",
      "69/69 [==============================] - 14s 39ms/step - loss: 0.6468 - accuracy: 0.5691 - val_loss: 0.5784 - val_accuracy: 0.7411 - lr: 2.5000e-06\n",
      "Epoch 36/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6194 - accuracy: 0.6145 - val_loss: 0.5926 - val_accuracy: 0.7143 - lr: 2.5000e-06\n",
      "Epoch 37/100\n",
      "69/69 [==============================] - 14s 37ms/step - loss: 0.6354 - accuracy: 0.6145 - val_loss: 0.5931 - val_accuracy: 0.7143 - lr: 2.5000e-06\n",
      "Epoch 38/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6236 - accuracy: 0.5964 - val_loss: 0.5628 - val_accuracy: 0.7321 - lr: 2.5000e-06\n",
      "Epoch 39/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6152 - accuracy: 0.6309 - val_loss: 0.5879 - val_accuracy: 0.7143 - lr: 2.5000e-06\n",
      "Epoch 40/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6191 - accuracy: 0.6273 - val_loss: 0.6066 - val_accuracy: 0.7054 - lr: 2.5000e-06\n",
      "Epoch 41/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.5903 - accuracy: 0.6527 - val_loss: 0.5832 - val_accuracy: 0.7054 - lr: 2.5000e-06\n",
      "Epoch 42/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6045 - accuracy: 0.6400 - val_loss: 0.5743 - val_accuracy: 0.7321 - lr: 2.5000e-06\n",
      "Epoch 43/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6178 - accuracy: 0.6236 - val_loss: 0.5868 - val_accuracy: 0.7321 - lr: 2.5000e-06\n",
      "Epoch 44/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6218 - accuracy: 0.6055 - val_loss: 0.5698 - val_accuracy: 0.7143 - lr: 1.2500e-06\n",
      "Epoch 45/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6148 - accuracy: 0.6436 - val_loss: 0.5588 - val_accuracy: 0.7232 - lr: 1.2500e-06\n",
      "Epoch 46/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.5997 - accuracy: 0.6382 - val_loss: 0.5673 - val_accuracy: 0.7232 - lr: 1.2500e-06\n",
      "Epoch 47/100\n",
      "69/69 [==============================] - 14s 38ms/step - loss: 0.5910 - accuracy: 0.6400 - val_loss: 0.5455 - val_accuracy: 0.7411 - lr: 1.2500e-06\n",
      "Epoch 48/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6230 - accuracy: 0.6364 - val_loss: 0.5774 - val_accuracy: 0.7321 - lr: 1.2500e-06\n",
      "Epoch 49/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6447 - accuracy: 0.5818 - val_loss: 0.5833 - val_accuracy: 0.7143 - lr: 1.2500e-06\n",
      "Epoch 50/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6308 - accuracy: 0.5800 - val_loss: 0.5577 - val_accuracy: 0.7321 - lr: 1.2500e-06\n",
      "Epoch 51/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6201 - accuracy: 0.6109 - val_loss: 0.5588 - val_accuracy: 0.7679 - lr: 1.2500e-06\n",
      "Epoch 52/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.5846 - accuracy: 0.6709 - val_loss: 0.5877 - val_accuracy: 0.6875 - lr: 1.2500e-06\n",
      "Epoch 53/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6050 - accuracy: 0.6109 - val_loss: 0.5604 - val_accuracy: 0.7232 - lr: 6.2500e-07\n",
      "Epoch 54/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6096 - accuracy: 0.6327 - val_loss: 0.5836 - val_accuracy: 0.7143 - lr: 6.2500e-07\n",
      "Epoch 55/100\n",
      "69/69 [==============================] - 13s 35ms/step - loss: 0.6129 - accuracy: 0.6527 - val_loss: 0.5704 - val_accuracy: 0.7321 - lr: 6.2500e-07\n",
      "Epoch 56/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6142 - accuracy: 0.6145 - val_loss: 0.5655 - val_accuracy: 0.6964 - lr: 6.2500e-07\n",
      "Epoch 57/100\n",
      "69/69 [==============================] - 14s 37ms/step - loss: 0.5998 - accuracy: 0.6527 - val_loss: 0.5965 - val_accuracy: 0.6875 - lr: 6.2500e-07\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 20s 82ms/step - loss: 0.6309 - accuracy: 0.6089 - val_loss: 0.5025 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.6192 - accuracy: 0.6107 - val_loss: 0.5748 - val_accuracy: 0.6111 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.5971 - accuracy: 0.6286 - val_loss: 0.5065 - val_accuracy: 0.6389 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.5875 - accuracy: 0.6429 - val_loss: 0.5496 - val_accuracy: 0.6204 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 15s 30ms/step - loss: 0.5877 - accuracy: 0.6268 - val_loss: 0.5335 - val_accuracy: 0.6481 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 15s 29ms/step - loss: 0.5903 - accuracy: 0.6304 - val_loss: 0.5471 - val_accuracy: 0.6481 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.5811 - accuracy: 0.6429 - val_loss: 0.5742 - val_accuracy: 0.6296 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 31ms/step - loss: 0.5897 - accuracy: 0.6179 - val_loss: 0.5763 - val_accuracy: 0.6204 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.5542 - accuracy: 0.6625 - val_loss: 0.5549 - val_accuracy: 0.6759 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 14s 34ms/step - loss: 0.5681 - accuracy: 0.6714 - val_loss: 0.5510 - val_accuracy: 0.6296 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.5642 - accuracy: 0.6732 - val_loss: 0.5465 - val_accuracy: 0.7037 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 19s 52ms/step - loss: 0.6084 - accuracy: 0.6214 - val_loss: 0.5098 - val_accuracy: 0.6574 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 35ms/step - loss: 0.6178 - accuracy: 0.6125 - val_loss: 0.5405 - val_accuracy: 0.6389 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 39ms/step - loss: 0.5969 - accuracy: 0.6393 - val_loss: 0.5548 - val_accuracy: 0.6296 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 14s 35ms/step - loss: 0.6248 - accuracy: 0.5929 - val_loss: 0.5701 - val_accuracy: 0.6481 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.5913 - accuracy: 0.6536 - val_loss: 0.6299 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 14s 34ms/step - loss: 0.5922 - accuracy: 0.6286 - val_loss: 0.6124 - val_accuracy: 0.6204 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 15s 37ms/step - loss: 0.6056 - accuracy: 0.6214 - val_loss: 0.5673 - val_accuracy: 0.6204 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 15s 35ms/step - loss: 0.6025 - accuracy: 0.6161 - val_loss: 0.6407 - val_accuracy: 0.5926 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 37ms/step - loss: 0.6124 - accuracy: 0.6125 - val_loss: 0.5291 - val_accuracy: 0.6296 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 36ms/step - loss: 0.5815 - accuracy: 0.6554 - val_loss: 0.5912 - val_accuracy: 0.6111 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 15s 37ms/step - loss: 0.6077 - accuracy: 0.6250 - val_loss: 0.5672 - val_accuracy: 0.6296 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 1s 700ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "\n",
      "=== Outer Fold 3 | Model: att_densenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 37s 223ms/step - loss: 0.7509 - accuracy: 0.6018 - val_loss: 0.5986 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 25s 172ms/step - loss: 0.5704 - accuracy: 0.7200 - val_loss: 0.7139 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 25s 172ms/step - loss: 0.4671 - accuracy: 0.7836 - val_loss: 0.6690 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 25s 174ms/step - loss: 0.4341 - accuracy: 0.7927 - val_loss: 0.8263 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 25s 173ms/step - loss: 0.3785 - accuracy: 0.8273 - val_loss: 0.6755 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 25s 173ms/step - loss: 0.3278 - accuracy: 0.8600 - val_loss: 0.7197 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 173ms/step - loss: 0.3157 - accuracy: 0.8673 - val_loss: 0.8984 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.2960 - accuracy: 0.8782 - val_loss: 0.7842 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 25s 173ms/step - loss: 0.2827 - accuracy: 0.8836 - val_loss: 0.7697 - val_accuracy: 0.7589 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 25s 174ms/step - loss: 0.2420 - accuracy: 0.9000 - val_loss: 0.8406 - val_accuracy: 0.7321 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 25s 177ms/step - loss: 0.2112 - accuracy: 0.9236 - val_loss: 0.8769 - val_accuracy: 0.7321 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 38s 236ms/step - loss: 0.5766 - accuracy: 0.6909 - val_loss: 0.6323 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 26s 195ms/step - loss: 0.5609 - accuracy: 0.7091 - val_loss: 0.6292 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 24s 188ms/step - loss: 0.5384 - accuracy: 0.7255 - val_loss: 0.6879 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4913 - accuracy: 0.7600 - val_loss: 0.7043 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.4995 - accuracy: 0.7491 - val_loss: 0.7654 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4805 - accuracy: 0.7545 - val_loss: 0.6511 - val_accuracy: 0.6964 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4608 - accuracy: 0.7673 - val_loss: 0.6909 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4514 - accuracy: 0.7800 - val_loss: 0.7338 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4338 - accuracy: 0.8036 - val_loss: 0.6922 - val_accuracy: 0.7143 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4407 - accuracy: 0.8073 - val_loss: 0.7791 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.4265 - accuracy: 0.8000 - val_loss: 0.7291 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 25s 191ms/step - loss: 0.4411 - accuracy: 0.7909 - val_loss: 0.8180 - val_accuracy: 0.6607 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 34s 221ms/step - loss: 0.6585 - accuracy: 0.6491 - val_loss: 0.3347 - val_accuracy: 0.8661 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 24s 178ms/step - loss: 0.5851 - accuracy: 0.6927 - val_loss: 0.2938 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 23s 175ms/step - loss: 0.5309 - accuracy: 0.7145 - val_loss: 0.3534 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 23s 173ms/step - loss: 0.5180 - accuracy: 0.7127 - val_loss: 0.3589 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.4951 - accuracy: 0.7418 - val_loss: 0.3865 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.4786 - accuracy: 0.7509 - val_loss: 0.3576 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.4452 - accuracy: 0.7636 - val_loss: 0.9391 - val_accuracy: 0.6518 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.4464 - accuracy: 0.7582 - val_loss: 0.4272 - val_accuracy: 0.8036 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.3831 - accuracy: 0.8000 - val_loss: 0.4071 - val_accuracy: 0.7946 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.3880 - accuracy: 0.8000 - val_loss: 0.3976 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 23s 171ms/step - loss: 0.3506 - accuracy: 0.8273 - val_loss: 0.3576 - val_accuracy: 0.8036 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 23s 176ms/step - loss: 0.3815 - accuracy: 0.7982 - val_loss: 0.3602 - val_accuracy: 0.8214 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 37s 235ms/step - loss: 0.5165 - accuracy: 0.7527 - val_loss: 0.3117 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 26s 192ms/step - loss: 0.5072 - accuracy: 0.7455 - val_loss: 0.3075 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.5058 - accuracy: 0.7273 - val_loss: 0.3267 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 24s 188ms/step - loss: 0.4625 - accuracy: 0.7745 - val_loss: 0.3482 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4857 - accuracy: 0.7436 - val_loss: 0.3252 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 24s 192ms/step - loss: 0.4700 - accuracy: 0.7309 - val_loss: 0.2891 - val_accuracy: 0.8661 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4705 - accuracy: 0.7564 - val_loss: 0.3117 - val_accuracy: 0.8393 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4648 - accuracy: 0.7418 - val_loss: 0.3292 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.4534 - accuracy: 0.7545 - val_loss: 0.3274 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4761 - accuracy: 0.7345 - val_loss: 0.3836 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4516 - accuracy: 0.7636 - val_loss: 0.3287 - val_accuracy: 0.8661 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4470 - accuracy: 0.7509 - val_loss: 0.3970 - val_accuracy: 0.7946 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.4268 - accuracy: 0.7818 - val_loss: 0.3421 - val_accuracy: 0.8393 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.4429 - accuracy: 0.7455 - val_loss: 0.3361 - val_accuracy: 0.8482 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.4087 - accuracy: 0.7945 - val_loss: 0.3894 - val_accuracy: 0.8125 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 25s 193ms/step - loss: 0.4256 - accuracy: 0.7618 - val_loss: 0.3452 - val_accuracy: 0.8214 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 36s 222ms/step - loss: 0.5240 - accuracy: 0.7214 - val_loss: 0.1325 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 24s 171ms/step - loss: 0.4484 - accuracy: 0.7679 - val_loss: 0.2241 - val_accuracy: 0.9074 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 24s 171ms/step - loss: 0.4045 - accuracy: 0.8054 - val_loss: 0.3884 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 24s 171ms/step - loss: 0.3834 - accuracy: 0.8214 - val_loss: 0.4127 - val_accuracy: 0.8704 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 24s 174ms/step - loss: 0.3398 - accuracy: 0.8339 - val_loss: 0.2426 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.3425 - accuracy: 0.8446 - val_loss: 0.2955 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.3031 - accuracy: 0.8554 - val_loss: 0.3838 - val_accuracy: 0.8704 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.2842 - accuracy: 0.8589 - val_loss: 0.3158 - val_accuracy: 0.8981 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.2704 - accuracy: 0.8679 - val_loss: 0.5396 - val_accuracy: 0.8519 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 25s 172ms/step - loss: 0.2750 - accuracy: 0.8714 - val_loss: 0.2119 - val_accuracy: 0.9259 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 24s 177ms/step - loss: 0.2462 - accuracy: 0.9000 - val_loss: 0.3326 - val_accuracy: 0.9074 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 40s 239ms/step - loss: 0.4491 - accuracy: 0.7768 - val_loss: 0.1964 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 25s 187ms/step - loss: 0.4419 - accuracy: 0.7857 - val_loss: 0.2891 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 25s 186ms/step - loss: 0.4513 - accuracy: 0.7714 - val_loss: 0.2263 - val_accuracy: 0.9074 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 25s 187ms/step - loss: 0.3882 - accuracy: 0.8071 - val_loss: 0.2885 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3908 - accuracy: 0.8107 - val_loss: 0.2093 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 26s 195ms/step - loss: 0.3924 - accuracy: 0.8125 - val_loss: 0.1157 - val_accuracy: 0.9537 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.4050 - accuracy: 0.8000 - val_loss: 0.2483 - val_accuracy: 0.8981 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 25s 187ms/step - loss: 0.3950 - accuracy: 0.8143 - val_loss: 0.2462 - val_accuracy: 0.8704 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3817 - accuracy: 0.8125 - val_loss: 0.1978 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.3772 - accuracy: 0.8304 - val_loss: 0.2198 - val_accuracy: 0.9074 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3437 - accuracy: 0.8536 - val_loss: 0.1815 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3642 - accuracy: 0.8321 - val_loss: 0.1445 - val_accuracy: 0.9444 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 25s 187ms/step - loss: 0.3704 - accuracy: 0.8071 - val_loss: 0.1788 - val_accuracy: 0.9259 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 25s 187ms/step - loss: 0.3530 - accuracy: 0.8286 - val_loss: 0.1414 - val_accuracy: 0.9537 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 25s 187ms/step - loss: 0.3495 - accuracy: 0.8464 - val_loss: 0.2182 - val_accuracy: 0.8981 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 25s 192ms/step - loss: 0.3545 - accuracy: 0.8411 - val_loss: 0.1719 - val_accuracy: 0.9352 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "\n",
      "=== Outer Fold 3 | Model: att_mobilenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 21s 82ms/step - loss: 0.5757 - accuracy: 0.6836 - val_loss: 0.6302 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.4509 - accuracy: 0.8073 - val_loss: 0.6117 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.3733 - accuracy: 0.8273 - val_loss: 0.6500 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 63ms/step - loss: 0.3552 - accuracy: 0.8364 - val_loss: 0.6674 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.3129 - accuracy: 0.8745 - val_loss: 0.7131 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 63ms/step - loss: 0.2775 - accuracy: 0.8836 - val_loss: 0.7685 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 65ms/step - loss: 0.2054 - accuracy: 0.9218 - val_loss: 1.0371 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 63ms/step - loss: 0.1786 - accuracy: 0.9345 - val_loss: 1.0873 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 63ms/step - loss: 0.1668 - accuracy: 0.9364 - val_loss: 1.0818 - val_accuracy: 0.5804 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 17s 63ms/step - loss: 0.1382 - accuracy: 0.9527 - val_loss: 1.1910 - val_accuracy: 0.6161 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.1039 - accuracy: 0.9636 - val_loss: 1.2838 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.0960 - accuracy: 0.9655 - val_loss: 1.6903 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 22s 86ms/step - loss: 0.5589 - accuracy: 0.7273 - val_loss: 0.6392 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 18s 69ms/step - loss: 0.5024 - accuracy: 0.7655 - val_loss: 0.6826 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4873 - accuracy: 0.7618 - val_loss: 0.7375 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4785 - accuracy: 0.7673 - val_loss: 0.7900 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 18s 68ms/step - loss: 0.4974 - accuracy: 0.7345 - val_loss: 0.8142 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4717 - accuracy: 0.7618 - val_loss: 0.8081 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4723 - accuracy: 0.7873 - val_loss: 0.8192 - val_accuracy: 0.6518 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.4637 - accuracy: 0.8018 - val_loss: 0.8278 - val_accuracy: 0.6607 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 67ms/step - loss: 0.4670 - accuracy: 0.7782 - val_loss: 0.8345 - val_accuracy: 0.6607 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.4651 - accuracy: 0.7818 - val_loss: 0.8494 - val_accuracy: 0.6607 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 68ms/step - loss: 0.4642 - accuracy: 0.7727 - val_loss: 0.8507 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 24s 126ms/step - loss: 0.5487 - accuracy: 0.7145 - val_loss: 0.4259 - val_accuracy: 0.8036 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.4855 - accuracy: 0.7418 - val_loss: 0.4125 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.4541 - accuracy: 0.7691 - val_loss: 0.3877 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.4221 - accuracy: 0.7800 - val_loss: 0.3867 - val_accuracy: 0.8036 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.3564 - accuracy: 0.8273 - val_loss: 0.3607 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.3360 - accuracy: 0.8418 - val_loss: 0.3366 - val_accuracy: 0.9018 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.3024 - accuracy: 0.8545 - val_loss: 0.3403 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.2414 - accuracy: 0.9127 - val_loss: 0.4087 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.2465 - accuracy: 0.8964 - val_loss: 0.5323 - val_accuracy: 0.7411 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.1742 - accuracy: 0.9327 - val_loss: 0.5769 - val_accuracy: 0.7321 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.1892 - accuracy: 0.9182 - val_loss: 0.3716 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.1601 - accuracy: 0.9327 - val_loss: 0.4230 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.1359 - accuracy: 0.9545 - val_loss: 0.5924 - val_accuracy: 0.7589 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.1162 - accuracy: 0.9600 - val_loss: 0.4209 - val_accuracy: 0.8036 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.1146 - accuracy: 0.9509 - val_loss: 0.4017 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.0734 - accuracy: 0.9800 - val_loss: 0.4248 - val_accuracy: 0.8214 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 21s 84ms/step - loss: 0.5364 - accuracy: 0.7309 - val_loss: 0.7204 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.5341 - accuracy: 0.7000 - val_loss: 0.9225 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 69ms/step - loss: 0.5111 - accuracy: 0.7473 - val_loss: 0.9977 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.5125 - accuracy: 0.7345 - val_loss: 0.9699 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 17s 70ms/step - loss: 0.5019 - accuracy: 0.7527 - val_loss: 0.9517 - val_accuracy: 0.6071 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4954 - accuracy: 0.7436 - val_loss: 0.9117 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.5040 - accuracy: 0.7236 - val_loss: 0.8825 - val_accuracy: 0.6339 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.8340 - val_accuracy: 0.6518 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4874 - accuracy: 0.7364 - val_loss: 0.8053 - val_accuracy: 0.6607 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4737 - accuracy: 0.7655 - val_loss: 0.7745 - val_accuracy: 0.6607 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 18s 70ms/step - loss: 0.4704 - accuracy: 0.7800 - val_loss: 0.7309 - val_accuracy: 0.6607 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 21s 79ms/step - loss: 0.3289 - accuracy: 0.8411 - val_loss: 0.5439 - val_accuracy: 0.7593 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 64ms/step - loss: 0.2794 - accuracy: 0.8696 - val_loss: 0.4554 - val_accuracy: 0.8148 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 63ms/step - loss: 0.2286 - accuracy: 0.9071 - val_loss: 0.4700 - val_accuracy: 0.8519 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.1864 - accuracy: 0.9339 - val_loss: 0.3090 - val_accuracy: 0.8241 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.1547 - accuracy: 0.9464 - val_loss: 0.3931 - val_accuracy: 0.8704 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1179 - accuracy: 0.9643 - val_loss: 0.5473 - val_accuracy: 0.8056 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.1024 - accuracy: 0.9643 - val_loss: 0.4545 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0978 - accuracy: 0.9714 - val_loss: 0.5679 - val_accuracy: 0.8611 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.1004 - accuracy: 0.9607 - val_loss: 0.7184 - val_accuracy: 0.8241 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0982 - accuracy: 0.9679 - val_loss: 0.5585 - val_accuracy: 0.8241 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.0418 - accuracy: 0.9964 - val_loss: 0.6892 - val_accuracy: 0.8148 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0553 - accuracy: 0.9768 - val_loss: 0.7898 - val_accuracy: 0.8241 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0504 - accuracy: 0.9857 - val_loss: 0.6810 - val_accuracy: 0.8241 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.0583 - accuracy: 0.9857 - val_loss: 0.7058 - val_accuracy: 0.8241 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 21s 83ms/step - loss: 0.5216 - accuracy: 0.7214 - val_loss: 0.8457 - val_accuracy: 0.6944 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.4925 - accuracy: 0.7482 - val_loss: 1.1274 - val_accuracy: 0.6204 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.4587 - accuracy: 0.7661 - val_loss: 1.2257 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.4421 - accuracy: 0.7946 - val_loss: 1.2097 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 18s 67ms/step - loss: 0.4354 - accuracy: 0.7946 - val_loss: 1.1341 - val_accuracy: 0.6111 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.4317 - accuracy: 0.7857 - val_loss: 1.0450 - val_accuracy: 0.6296 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.4239 - accuracy: 0.7893 - val_loss: 0.9448 - val_accuracy: 0.6667 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.4172 - accuracy: 0.8036 - val_loss: 0.8756 - val_accuracy: 0.6759 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.4276 - accuracy: 0.7804 - val_loss: 0.8217 - val_accuracy: 0.6852 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 17s 71ms/step - loss: 0.4105 - accuracy: 0.7893 - val_loss: 0.7586 - val_accuracy: 0.7222 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.4062 - accuracy: 0.8125 - val_loss: 0.7422 - val_accuracy: 0.7222 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 16s 69ms/step - loss: 0.4042 - accuracy: 0.8286 - val_loss: 0.7323 - val_accuracy: 0.7222 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.4027 - accuracy: 0.7964 - val_loss: 0.6894 - val_accuracy: 0.7407 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.3945 - accuracy: 0.8161 - val_loss: 0.6866 - val_accuracy: 0.7315 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 16s 66ms/step - loss: 0.4032 - accuracy: 0.8107 - val_loss: 0.6922 - val_accuracy: 0.7222 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3967 - accuracy: 0.8107 - val_loss: 0.6847 - val_accuracy: 0.7315 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.4190 - accuracy: 0.7982 - val_loss: 0.6722 - val_accuracy: 0.7315 - lr: 5.0000e-06\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.3969 - accuracy: 0.8286 - val_loss: 0.6865 - val_accuracy: 0.7130 - lr: 5.0000e-06\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.3862 - accuracy: 0.8232 - val_loss: 0.6656 - val_accuracy: 0.7315 - lr: 5.0000e-06\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.3935 - accuracy: 0.8071 - val_loss: 0.6894 - val_accuracy: 0.6852 - lr: 5.0000e-06\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.3656 - accuracy: 0.8357 - val_loss: 0.7083 - val_accuracy: 0.7130 - lr: 5.0000e-06\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.3867 - accuracy: 0.8286 - val_loss: 0.7224 - val_accuracy: 0.7037 - lr: 5.0000e-06\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.3738 - accuracy: 0.8286 - val_loss: 0.7496 - val_accuracy: 0.6944 - lr: 5.0000e-06\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3673 - accuracy: 0.8429 - val_loss: 0.7530 - val_accuracy: 0.6852 - lr: 5.0000e-06\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 18s 67ms/step - loss: 0.3662 - accuracy: 0.8339 - val_loss: 0.7660 - val_accuracy: 0.6852 - lr: 2.5000e-06\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 18s 68ms/step - loss: 0.3775 - accuracy: 0.8232 - val_loss: 0.7386 - val_accuracy: 0.6944 - lr: 2.5000e-06\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.3613 - accuracy: 0.8375 - val_loss: 0.7602 - val_accuracy: 0.6852 - lr: 2.5000e-06\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 18s 68ms/step - loss: 0.3726 - accuracy: 0.8232 - val_loss: 0.7585 - val_accuracy: 0.7037 - lr: 2.5000e-06\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.3471 - accuracy: 0.8393 - val_loss: 0.7707 - val_accuracy: 0.6944 - lr: 2.5000e-06\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "=== Outer Fold 4 | Model: std_densenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 29s 111ms/step - loss: 0.7335 - accuracy: 0.4873 - val_loss: 0.6260 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 18s 69ms/step - loss: 0.6885 - accuracy: 0.5345 - val_loss: 0.5948 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 70ms/step - loss: 0.6608 - accuracy: 0.5691 - val_loss: 0.5823 - val_accuracy: 0.6518 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 18s 69ms/step - loss: 0.6617 - accuracy: 0.5691 - val_loss: 0.5778 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 18s 64ms/step - loss: 0.6371 - accuracy: 0.5855 - val_loss: 0.6225 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.6379 - accuracy: 0.5509 - val_loss: 0.5929 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.6390 - accuracy: 0.5618 - val_loss: 0.5630 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 18s 64ms/step - loss: 0.6220 - accuracy: 0.6182 - val_loss: 0.5744 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 65ms/step - loss: 0.6067 - accuracy: 0.6255 - val_loss: 0.5765 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.6174 - accuracy: 0.5909 - val_loss: 0.5921 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 18s 73ms/step - loss: 0.6150 - accuracy: 0.5836 - val_loss: 0.5586 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.5958 - accuracy: 0.6127 - val_loss: 0.5741 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5841 - accuracy: 0.6273 - val_loss: 0.5712 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.5949 - accuracy: 0.6164 - val_loss: 0.6048 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 17s 67ms/step - loss: 0.5954 - accuracy: 0.5800 - val_loss: 0.5757 - val_accuracy: 0.7321 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5867 - accuracy: 0.5945 - val_loss: 0.6063 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5867 - accuracy: 0.6127 - val_loss: 0.5773 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5606 - accuracy: 0.6236 - val_loss: 0.5652 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.5691 - accuracy: 0.6236 - val_loss: 0.5740 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.5794 - accuracy: 0.6273 - val_loss: 0.5556 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.5728 - accuracy: 0.5945 - val_loss: 0.5712 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5540 - accuracy: 0.6709 - val_loss: 0.6321 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5647 - accuracy: 0.6218 - val_loss: 0.5722 - val_accuracy: 0.6607 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5671 - accuracy: 0.6564 - val_loss: 0.6260 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5598 - accuracy: 0.6600 - val_loss: 0.6265 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5579 - accuracy: 0.6418 - val_loss: 0.5898 - val_accuracy: 0.6875 - lr: 2.5000e-05\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5592 - accuracy: 0.6527 - val_loss: 0.6108 - val_accuracy: 0.6964 - lr: 2.5000e-05\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.5597 - accuracy: 0.6091 - val_loss: 0.6499 - val_accuracy: 0.6786 - lr: 2.5000e-05\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 16s 67ms/step - loss: 0.5614 - accuracy: 0.6273 - val_loss: 0.5892 - val_accuracy: 0.6964 - lr: 2.5000e-05\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.5660 - accuracy: 0.6218 - val_loss: 0.5937 - val_accuracy: 0.6696 - lr: 2.5000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 30s 131ms/step - loss: 1.0405 - accuracy: 0.5709 - val_loss: 0.7397 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 87ms/step - loss: 0.7129 - accuracy: 0.5764 - val_loss: 0.9971 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 85ms/step - loss: 0.6384 - accuracy: 0.6291 - val_loss: 0.8922 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 87ms/step - loss: 0.6705 - accuracy: 0.6109 - val_loss: 0.7131 - val_accuracy: 0.6964 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.6745 - accuracy: 0.6036 - val_loss: 0.7129 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.6423 - accuracy: 0.6200 - val_loss: 0.8801 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.6123 - accuracy: 0.6400 - val_loss: 0.8593 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5883 - accuracy: 0.6782 - val_loss: 0.7280 - val_accuracy: 0.7054 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.6274 - accuracy: 0.6145 - val_loss: 0.7232 - val_accuracy: 0.6964 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 17s 87ms/step - loss: 0.6156 - accuracy: 0.6218 - val_loss: 0.7694 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 18s 87ms/step - loss: 0.5999 - accuracy: 0.6164 - val_loss: 0.7317 - val_accuracy: 0.6696 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.6078 - accuracy: 0.6218 - val_loss: 0.8421 - val_accuracy: 0.6875 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.5956 - accuracy: 0.6418 - val_loss: 0.7615 - val_accuracy: 0.6696 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.6097 - accuracy: 0.5964 - val_loss: 0.7925 - val_accuracy: 0.6696 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 17s 87ms/step - loss: 0.5897 - accuracy: 0.6618 - val_loss: 0.6710 - val_accuracy: 0.7054 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 17s 82ms/step - loss: 0.5933 - accuracy: 0.6255 - val_loss: 0.7891 - val_accuracy: 0.6964 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.5951 - accuracy: 0.6273 - val_loss: 0.6722 - val_accuracy: 0.7232 - lr: 5.0000e-06\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.6038 - accuracy: 0.6255 - val_loss: 0.7284 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.5466 - accuracy: 0.6764 - val_loss: 0.7701 - val_accuracy: 0.6964 - lr: 5.0000e-06\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 18s 84ms/step - loss: 0.5918 - accuracy: 0.6655 - val_loss: 0.7619 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.5779 - accuracy: 0.6200 - val_loss: 0.6920 - val_accuracy: 0.7232 - lr: 2.5000e-06\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 17s 88ms/step - loss: 0.5946 - accuracy: 0.6400 - val_loss: 0.6018 - val_accuracy: 0.7143 - lr: 2.5000e-06\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5780 - accuracy: 0.6582 - val_loss: 0.7914 - val_accuracy: 0.6696 - lr: 2.5000e-06\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5785 - accuracy: 0.6582 - val_loss: 0.8018 - val_accuracy: 0.6607 - lr: 2.5000e-06\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.5545 - accuracy: 0.6491 - val_loss: 0.6811 - val_accuracy: 0.7054 - lr: 2.5000e-06\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5715 - accuracy: 0.6273 - val_loss: 0.6277 - val_accuracy: 0.7143 - lr: 2.5000e-06\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5346 - accuracy: 0.6673 - val_loss: 0.7334 - val_accuracy: 0.7054 - lr: 2.5000e-06\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5693 - accuracy: 0.6382 - val_loss: 0.7408 - val_accuracy: 0.7143 - lr: 1.2500e-06\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.5745 - accuracy: 0.6418 - val_loss: 0.7326 - val_accuracy: 0.6964 - lr: 1.2500e-06\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 17s 83ms/step - loss: 0.5934 - accuracy: 0.6236 - val_loss: 0.6736 - val_accuracy: 0.6875 - lr: 1.2500e-06\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 17s 85ms/step - loss: 0.5777 - accuracy: 0.6309 - val_loss: 0.6572 - val_accuracy: 0.6786 - lr: 1.2500e-06\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 17s 88ms/step - loss: 0.5660 - accuracy: 0.6400 - val_loss: 0.7402 - val_accuracy: 0.6875 - lr: 1.2500e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 26s 108ms/step - loss: 0.6461 - accuracy: 0.5964 - val_loss: 0.1508 - val_accuracy: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.6062 - accuracy: 0.5982 - val_loss: 0.1772 - val_accuracy: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.6003 - accuracy: 0.6291 - val_loss: 0.2114 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 65ms/step - loss: 0.6134 - accuracy: 0.6018 - val_loss: 0.3599 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.5575 - accuracy: 0.6527 - val_loss: 0.1547 - val_accuracy: 0.9554 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.5823 - accuracy: 0.6436 - val_loss: 0.2093 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.5597 - accuracy: 0.6400 - val_loss: 0.2818 - val_accuracy: 0.8839 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.5343 - accuracy: 0.6964 - val_loss: 0.2132 - val_accuracy: 0.9464 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.5461 - accuracy: 0.6364 - val_loss: 0.2006 - val_accuracy: 0.9196 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 62ms/step - loss: 0.5290 - accuracy: 0.6618 - val_loss: 0.2413 - val_accuracy: 0.9196 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 67ms/step - loss: 0.5311 - accuracy: 0.6691 - val_loss: 0.3109 - val_accuracy: 0.8750 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 30s 129ms/step - loss: 0.6713 - accuracy: 0.6091 - val_loss: 0.1806 - val_accuracy: 0.9196 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 85ms/step - loss: 0.5897 - accuracy: 0.6582 - val_loss: 0.3016 - val_accuracy: 0.9107 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.5611 - accuracy: 0.6655 - val_loss: 0.2088 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 88ms/step - loss: 0.6246 - accuracy: 0.6200 - val_loss: 0.1455 - val_accuracy: 0.9732 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 17s 84ms/step - loss: 0.6065 - accuracy: 0.6109 - val_loss: 0.1472 - val_accuracy: 0.9643 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 18s 88ms/step - loss: 0.5812 - accuracy: 0.6218 - val_loss: 0.1274 - val_accuracy: 0.9643 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 18s 84ms/step - loss: 0.5743 - accuracy: 0.6600 - val_loss: 0.1677 - val_accuracy: 0.9375 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 18s 85ms/step - loss: 0.5711 - accuracy: 0.6127 - val_loss: 0.1690 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 18s 85ms/step - loss: 0.5911 - accuracy: 0.6655 - val_loss: 0.1664 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 19s 88ms/step - loss: 0.5740 - accuracy: 0.6327 - val_loss: 0.1832 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 18s 85ms/step - loss: 0.5775 - accuracy: 0.6545 - val_loss: 0.1932 - val_accuracy: 0.9375 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 18s 86ms/step - loss: 0.5412 - accuracy: 0.6636 - val_loss: 0.1524 - val_accuracy: 0.9554 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 18s 85ms/step - loss: 0.5657 - accuracy: 0.6509 - val_loss: 0.1780 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 19s 84ms/step - loss: 0.5398 - accuracy: 0.6691 - val_loss: 0.1415 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 18s 85ms/step - loss: 0.5430 - accuracy: 0.6818 - val_loss: 0.2457 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 18s 89ms/step - loss: 0.5360 - accuracy: 0.6509 - val_loss: 0.1801 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 28s 110ms/step - loss: 0.5611 - accuracy: 0.6500 - val_loss: 0.2337 - val_accuracy: 0.8889 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 63ms/step - loss: 0.5527 - accuracy: 0.6536 - val_loss: 0.2455 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.5294 - accuracy: 0.6554 - val_loss: 0.2160 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.5395 - accuracy: 0.6554 - val_loss: 0.1758 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 18s 69ms/step - loss: 0.5305 - accuracy: 0.6750 - val_loss: 0.1694 - val_accuracy: 0.9537 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 18s 69ms/step - loss: 0.5525 - accuracy: 0.6214 - val_loss: 0.1818 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 18s 63ms/step - loss: 0.5365 - accuracy: 0.6750 - val_loss: 0.2408 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 63ms/step - loss: 0.5140 - accuracy: 0.6821 - val_loss: 0.2233 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5043 - accuracy: 0.6875 - val_loss: 0.1722 - val_accuracy: 0.9352 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.5125 - accuracy: 0.6768 - val_loss: 0.2185 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.5100 - accuracy: 0.6750 - val_loss: 0.3141 - val_accuracy: 0.8889 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5259 - accuracy: 0.6679 - val_loss: 0.2276 - val_accuracy: 0.9352 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 16s 66ms/step - loss: 0.4933 - accuracy: 0.7196 - val_loss: 0.1517 - val_accuracy: 0.9444 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5328 - accuracy: 0.6500 - val_loss: 0.2735 - val_accuracy: 0.8796 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5043 - accuracy: 0.6768 - val_loss: 0.2003 - val_accuracy: 0.9167 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5144 - accuracy: 0.6607 - val_loss: 0.3663 - val_accuracy: 0.8889 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5200 - accuracy: 0.6625 - val_loss: 0.2275 - val_accuracy: 0.8981 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.5083 - accuracy: 0.6607 - val_loss: 0.1619 - val_accuracy: 0.9444 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.4943 - accuracy: 0.7036 - val_loss: 0.2574 - val_accuracy: 0.8889 - lr: 2.5000e-05\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5083 - accuracy: 0.6768 - val_loss: 0.2395 - val_accuracy: 0.9167 - lr: 2.5000e-05\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5078 - accuracy: 0.6518 - val_loss: 0.1950 - val_accuracy: 0.9074 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.5027 - accuracy: 0.6732 - val_loss: 0.1197 - val_accuracy: 0.9352 - lr: 2.5000e-05\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5150 - accuracy: 0.6750 - val_loss: 0.2870 - val_accuracy: 0.9167 - lr: 2.5000e-05\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.4958 - accuracy: 0.7018 - val_loss: 0.2502 - val_accuracy: 0.8889 - lr: 2.5000e-05\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.4906 - accuracy: 0.6964 - val_loss: 0.2628 - val_accuracy: 0.8981 - lr: 2.5000e-05\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.4973 - accuracy: 0.6607 - val_loss: 0.2715 - val_accuracy: 0.8796 - lr: 2.5000e-05\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5139 - accuracy: 0.6500 - val_loss: 0.2670 - val_accuracy: 0.8981 - lr: 2.5000e-05\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.5129 - accuracy: 0.6911 - val_loss: 0.2451 - val_accuracy: 0.9167 - lr: 1.2500e-05\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.4878 - accuracy: 0.6929 - val_loss: 0.2520 - val_accuracy: 0.9259 - lr: 1.2500e-05\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.4925 - accuracy: 0.7089 - val_loss: 0.1893 - val_accuracy: 0.9167 - lr: 1.2500e-05\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.5124 - accuracy: 0.6571 - val_loss: 0.3299 - val_accuracy: 0.8981 - lr: 1.2500e-05\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 16s 66ms/step - loss: 0.4893 - accuracy: 0.6875 - val_loss: 0.2573 - val_accuracy: 0.8981 - lr: 1.2500e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 31s 137ms/step - loss: 0.5379 - accuracy: 0.6536 - val_loss: 0.3540 - val_accuracy: 0.8981 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 19s 88ms/step - loss: 0.5506 - accuracy: 0.6482 - val_loss: 0.1399 - val_accuracy: 0.9537 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.5588 - accuracy: 0.6411 - val_loss: 0.2212 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 18s 85ms/step - loss: 0.5489 - accuracy: 0.6518 - val_loss: 0.3021 - val_accuracy: 0.8889 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 17s 85ms/step - loss: 0.5705 - accuracy: 0.6536 - val_loss: 0.2420 - val_accuracy: 0.8981 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 18s 84ms/step - loss: 0.5353 - accuracy: 0.6679 - val_loss: 0.2194 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 18s 84ms/step - loss: 0.5201 - accuracy: 0.6714 - val_loss: 0.2991 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 84ms/step - loss: 0.5061 - accuracy: 0.7018 - val_loss: 0.3037 - val_accuracy: 0.8796 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 17s 85ms/step - loss: 0.5226 - accuracy: 0.6786 - val_loss: 0.2867 - val_accuracy: 0.8889 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 18s 84ms/step - loss: 0.5258 - accuracy: 0.6625 - val_loss: 0.2207 - val_accuracy: 0.8889 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 18s 85ms/step - loss: 0.5167 - accuracy: 0.6786 - val_loss: 0.2328 - val_accuracy: 0.9352 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 18s 88ms/step - loss: 0.5155 - accuracy: 0.6661 - val_loss: 0.3420 - val_accuracy: 0.8704 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "=== Outer Fold 4 | Model: std_mobilenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 17s 45ms/step - loss: 0.7111 - accuracy: 0.5418 - val_loss: 0.6880 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.7003 - accuracy: 0.5473 - val_loss: 0.6876 - val_accuracy: 0.5536 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.7037 - accuracy: 0.5182 - val_loss: 0.6891 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.7021 - accuracy: 0.5345 - val_loss: 0.6950 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.7073 - accuracy: 0.5109 - val_loss: 0.6863 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6992 - accuracy: 0.5291 - val_loss: 0.6868 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.7054 - accuracy: 0.5164 - val_loss: 0.6904 - val_accuracy: 0.5268 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 13s 27ms/step - loss: 0.6941 - accuracy: 0.5073 - val_loss: 0.6873 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6917 - accuracy: 0.5164 - val_loss: 0.6868 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 14s 28ms/step - loss: 0.6945 - accuracy: 0.5364 - val_loss: 0.6899 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 14s 28ms/step - loss: 0.6880 - accuracy: 0.5436 - val_loss: 0.6906 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6889 - accuracy: 0.5600 - val_loss: 0.6886 - val_accuracy: 0.5357 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6829 - accuracy: 0.5491 - val_loss: 0.6978 - val_accuracy: 0.5357 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 13s 31ms/step - loss: 0.6803 - accuracy: 0.5655 - val_loss: 0.6860 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6862 - accuracy: 0.5418 - val_loss: 0.6821 - val_accuracy: 0.5625 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.6790 - accuracy: 0.5527 - val_loss: 0.6927 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6954 - accuracy: 0.5327 - val_loss: 0.6875 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.6724 - accuracy: 0.5564 - val_loss: 0.6883 - val_accuracy: 0.6071 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.6788 - accuracy: 0.5491 - val_loss: 0.6949 - val_accuracy: 0.5625 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6772 - accuracy: 0.5400 - val_loss: 0.6967 - val_accuracy: 0.5625 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6714 - accuracy: 0.5673 - val_loss: 0.6906 - val_accuracy: 0.5536 - lr: 2.5000e-05\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6758 - accuracy: 0.5582 - val_loss: 0.6880 - val_accuracy: 0.6071 - lr: 2.5000e-05\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6787 - accuracy: 0.5600 - val_loss: 0.6873 - val_accuracy: 0.5982 - lr: 2.5000e-05\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 13s 28ms/step - loss: 0.6787 - accuracy: 0.5582 - val_loss: 0.6886 - val_accuracy: 0.6250 - lr: 2.5000e-05\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6793 - accuracy: 0.5436 - val_loss: 0.6927 - val_accuracy: 0.5982 - lr: 2.5000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 18s 49ms/step - loss: 1.2017 - accuracy: 0.5073 - val_loss: 0.7057 - val_accuracy: 0.5357 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.7510 - accuracy: 0.5309 - val_loss: 0.7080 - val_accuracy: 0.5357 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6918 - accuracy: 0.5800 - val_loss: 0.7126 - val_accuracy: 0.5357 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 14s 37ms/step - loss: 0.7158 - accuracy: 0.5364 - val_loss: 0.7207 - val_accuracy: 0.5357 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.7117 - accuracy: 0.5291 - val_loss: 0.7653 - val_accuracy: 0.5357 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 39ms/step - loss: 0.6671 - accuracy: 0.5782 - val_loss: 0.7688 - val_accuracy: 0.5357 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6985 - accuracy: 0.5382 - val_loss: 0.7841 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 15s 35ms/step - loss: 0.6772 - accuracy: 0.5564 - val_loss: 0.7996 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6871 - accuracy: 0.5727 - val_loss: 0.7922 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 15s 36ms/step - loss: 0.6876 - accuracy: 0.5509 - val_loss: 0.8275 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 14s 38ms/step - loss: 0.6789 - accuracy: 0.5873 - val_loss: 0.8397 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 18s 44ms/step - loss: 0.7051 - accuracy: 0.5527 - val_loss: 0.6441 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 15s 33ms/step - loss: 0.7115 - accuracy: 0.5145 - val_loss: 0.6031 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 14s 28ms/step - loss: 0.7067 - accuracy: 0.4982 - val_loss: 0.6368 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 14s 30ms/step - loss: 0.7004 - accuracy: 0.4982 - val_loss: 0.6270 - val_accuracy: 0.4643 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 14s 31ms/step - loss: 0.7010 - accuracy: 0.5091 - val_loss: 0.6071 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 33ms/step - loss: 0.6899 - accuracy: 0.5145 - val_loss: 0.6179 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 15s 30ms/step - loss: 0.6940 - accuracy: 0.5109 - val_loss: 0.6014 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6915 - accuracy: 0.5218 - val_loss: 0.6202 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 14s 28ms/step - loss: 0.6990 - accuracy: 0.5073 - val_loss: 0.6330 - val_accuracy: 0.4821 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 14s 31ms/step - loss: 0.6922 - accuracy: 0.5345 - val_loss: 0.6153 - val_accuracy: 0.8036 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 15s 31ms/step - loss: 0.6906 - accuracy: 0.5091 - val_loss: 0.6324 - val_accuracy: 0.4732 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6925 - accuracy: 0.5382 - val_loss: 0.6219 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6989 - accuracy: 0.5000 - val_loss: 0.6427 - val_accuracy: 0.4643 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6893 - accuracy: 0.5345 - val_loss: 0.6240 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 14s 28ms/step - loss: 0.6898 - accuracy: 0.5109 - val_loss: 0.6295 - val_accuracy: 0.7054 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 14s 29ms/step - loss: 0.6892 - accuracy: 0.5618 - val_loss: 0.6324 - val_accuracy: 0.4554 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 13s 29ms/step - loss: 0.6870 - accuracy: 0.5218 - val_loss: 0.6324 - val_accuracy: 0.4643 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 18s 50ms/step - loss: 0.7902 - accuracy: 0.4891 - val_loss: 0.5998 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.7396 - accuracy: 0.5091 - val_loss: 0.6126 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.7263 - accuracy: 0.5000 - val_loss: 0.6021 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.7103 - accuracy: 0.5509 - val_loss: 0.6035 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.6983 - accuracy: 0.5436 - val_loss: 0.6136 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6784 - accuracy: 0.5800 - val_loss: 0.6110 - val_accuracy: 0.6518 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 14s 34ms/step - loss: 0.6897 - accuracy: 0.5691 - val_loss: 0.6307 - val_accuracy: 0.4732 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6865 - accuracy: 0.5855 - val_loss: 0.6445 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 14s 35ms/step - loss: 0.6676 - accuracy: 0.5782 - val_loss: 0.6481 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 13s 34ms/step - loss: 0.6641 - accuracy: 0.5836 - val_loss: 0.6719 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 14s 36ms/step - loss: 0.6602 - accuracy: 0.5636 - val_loss: 0.6775 - val_accuracy: 0.4643 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 19s 76ms/step - loss: 0.6658 - accuracy: 0.5964 - val_loss: 0.6877 - val_accuracy: 0.5185 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6595 - accuracy: 0.5893 - val_loss: 0.6912 - val_accuracy: 0.4907 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6622 - accuracy: 0.5893 - val_loss: 0.6933 - val_accuracy: 0.4630 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.6696 - accuracy: 0.5714 - val_loss: 0.6976 - val_accuracy: 0.4074 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 13s 28ms/step - loss: 0.6743 - accuracy: 0.5911 - val_loss: 0.7038 - val_accuracy: 0.4167 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6605 - accuracy: 0.5929 - val_loss: 0.7009 - val_accuracy: 0.4352 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 13s 28ms/step - loss: 0.6717 - accuracy: 0.5464 - val_loss: 0.7019 - val_accuracy: 0.4352 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.6676 - accuracy: 0.5661 - val_loss: 0.6999 - val_accuracy: 0.4259 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 34ms/step - loss: 0.6641 - accuracy: 0.6107 - val_loss: 0.7032 - val_accuracy: 0.4074 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6665 - accuracy: 0.5696 - val_loss: 0.7057 - val_accuracy: 0.4259 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 13s 29ms/step - loss: 0.6649 - accuracy: 0.5821 - val_loss: 0.7032 - val_accuracy: 0.4352 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 18s 49ms/step - loss: 0.7183 - accuracy: 0.5429 - val_loss: 0.6994 - val_accuracy: 0.5185 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.7010 - accuracy: 0.5661 - val_loss: 0.7060 - val_accuracy: 0.5185 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6861 - accuracy: 0.5536 - val_loss: 0.7136 - val_accuracy: 0.5185 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6768 - accuracy: 0.5625 - val_loss: 0.7268 - val_accuracy: 0.5185 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 15s 37ms/step - loss: 0.6455 - accuracy: 0.6179 - val_loss: 0.7369 - val_accuracy: 0.5185 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6709 - accuracy: 0.5804 - val_loss: 0.7570 - val_accuracy: 0.5185 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6634 - accuracy: 0.5982 - val_loss: 0.7720 - val_accuracy: 0.5185 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6639 - accuracy: 0.5857 - val_loss: 0.7933 - val_accuracy: 0.5185 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6547 - accuracy: 0.6179 - val_loss: 0.8132 - val_accuracy: 0.5185 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6561 - accuracy: 0.5964 - val_loss: 0.8323 - val_accuracy: 0.5185 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 38ms/step - loss: 0.6482 - accuracy: 0.5982 - val_loss: 0.8524 - val_accuracy: 0.5185 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 1s 683ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "\n",
      "=== Outer Fold 4 | Model: att_densenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 36s 224ms/step - loss: 0.6867 - accuracy: 0.6255 - val_loss: 0.5437 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 24s 178ms/step - loss: 0.5124 - accuracy: 0.7455 - val_loss: 0.4968 - val_accuracy: 0.7768 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.4693 - accuracy: 0.7709 - val_loss: 0.5021 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 24s 173ms/step - loss: 0.4355 - accuracy: 0.7964 - val_loss: 0.6472 - val_accuracy: 0.7411 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.3771 - accuracy: 0.8291 - val_loss: 0.5863 - val_accuracy: 0.7768 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.3252 - accuracy: 0.8527 - val_loss: 0.6340 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.2879 - accuracy: 0.8782 - val_loss: 0.6516 - val_accuracy: 0.7411 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.2173 - accuracy: 0.9164 - val_loss: 0.6937 - val_accuracy: 0.7500 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 23s 172ms/step - loss: 0.2153 - accuracy: 0.9091 - val_loss: 0.5162 - val_accuracy: 0.7589 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 173ms/step - loss: 0.1818 - accuracy: 0.9382 - val_loss: 0.6504 - val_accuracy: 0.7946 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.1837 - accuracy: 0.9164 - val_loss: 0.7637 - val_accuracy: 0.7589 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 24s 177ms/step - loss: 0.1392 - accuracy: 0.9527 - val_loss: 0.7473 - val_accuracy: 0.7768 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 37s 236ms/step - loss: 0.4889 - accuracy: 0.7400 - val_loss: 0.5057 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 25s 192ms/step - loss: 0.4681 - accuracy: 0.7745 - val_loss: 0.4853 - val_accuracy: 0.7857 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 25s 193ms/step - loss: 0.4242 - accuracy: 0.7945 - val_loss: 0.4807 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 25s 186ms/step - loss: 0.4362 - accuracy: 0.7855 - val_loss: 0.5392 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 25s 192ms/step - loss: 0.4300 - accuracy: 0.7800 - val_loss: 0.4806 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4131 - accuracy: 0.8091 - val_loss: 0.4976 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.3874 - accuracy: 0.8073 - val_loss: 0.5726 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 25s 186ms/step - loss: 0.3852 - accuracy: 0.8091 - val_loss: 0.5030 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 25s 191ms/step - loss: 0.4108 - accuracy: 0.7891 - val_loss: 0.4560 - val_accuracy: 0.8125 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.4108 - accuracy: 0.7927 - val_loss: 0.4913 - val_accuracy: 0.7768 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 25s 192ms/step - loss: 0.3965 - accuracy: 0.8055 - val_loss: 0.4309 - val_accuracy: 0.8661 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.3768 - accuracy: 0.8182 - val_loss: 0.4984 - val_accuracy: 0.8125 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.3940 - accuracy: 0.8036 - val_loss: 0.5070 - val_accuracy: 0.8214 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.3888 - accuracy: 0.8145 - val_loss: 0.5178 - val_accuracy: 0.8125 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.3588 - accuracy: 0.8309 - val_loss: 0.5020 - val_accuracy: 0.8304 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.3866 - accuracy: 0.8127 - val_loss: 0.5264 - val_accuracy: 0.8393 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 24s 186ms/step - loss: 0.3658 - accuracy: 0.8364 - val_loss: 0.5677 - val_accuracy: 0.8036 - lr: 2.5000e-06\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 24s 189ms/step - loss: 0.3766 - accuracy: 0.8273 - val_loss: 0.5883 - val_accuracy: 0.7946 - lr: 2.5000e-06\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 25s 186ms/step - loss: 0.3620 - accuracy: 0.8182 - val_loss: 0.5450 - val_accuracy: 0.8125 - lr: 2.5000e-06\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.3791 - accuracy: 0.8273 - val_loss: 0.5214 - val_accuracy: 0.8036 - lr: 2.5000e-06\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 25s 192ms/step - loss: 0.3621 - accuracy: 0.8345 - val_loss: 0.5147 - val_accuracy: 0.8214 - lr: 2.5000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 36s 225ms/step - loss: 0.5032 - accuracy: 0.7455 - val_loss: 0.2205 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 25s 172ms/step - loss: 0.4643 - accuracy: 0.7691 - val_loss: 0.3832 - val_accuracy: 0.8036 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.3758 - accuracy: 0.8327 - val_loss: 0.2430 - val_accuracy: 0.9018 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.3345 - accuracy: 0.8545 - val_loss: 0.2692 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.3320 - accuracy: 0.8545 - val_loss: 0.5185 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 24s 173ms/step - loss: 0.3010 - accuracy: 0.8655 - val_loss: 0.5517 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.2793 - accuracy: 0.9000 - val_loss: 0.5114 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.2583 - accuracy: 0.8982 - val_loss: 0.5444 - val_accuracy: 0.8304 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 24s 172ms/step - loss: 0.2632 - accuracy: 0.8873 - val_loss: 0.4131 - val_accuracy: 0.8661 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 173ms/step - loss: 0.2227 - accuracy: 0.9145 - val_loss: 0.5212 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 25s 177ms/step - loss: 0.2520 - accuracy: 0.8927 - val_loss: 0.5424 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 39s 238ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.2431 - val_accuracy: 0.9107 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 26s 193ms/step - loss: 0.4124 - accuracy: 0.8127 - val_loss: 0.1999 - val_accuracy: 0.9018 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.3872 - accuracy: 0.8309 - val_loss: 0.2560 - val_accuracy: 0.9196 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.3557 - accuracy: 0.8400 - val_loss: 0.2334 - val_accuracy: 0.9107 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.3624 - accuracy: 0.8509 - val_loss: 0.2225 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 25s 193ms/step - loss: 0.3621 - accuracy: 0.8436 - val_loss: 0.1977 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.3375 - accuracy: 0.8473 - val_loss: 0.2288 - val_accuracy: 0.9107 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.3353 - accuracy: 0.8436 - val_loss: 0.2618 - val_accuracy: 0.9018 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.3003 - accuracy: 0.8564 - val_loss: 0.2237 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.3259 - accuracy: 0.8455 - val_loss: 0.2350 - val_accuracy: 0.9196 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.3391 - accuracy: 0.8418 - val_loss: 0.2174 - val_accuracy: 0.9107 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.3338 - accuracy: 0.8509 - val_loss: 0.2379 - val_accuracy: 0.9196 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 24s 187ms/step - loss: 0.3202 - accuracy: 0.8527 - val_loss: 0.2415 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 25s 194ms/step - loss: 0.2971 - accuracy: 0.8655 - val_loss: 0.1973 - val_accuracy: 0.9196 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 24s 188ms/step - loss: 0.3017 - accuracy: 0.8818 - val_loss: 0.2675 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 24s 189ms/step - loss: 0.3332 - accuracy: 0.8545 - val_loss: 0.2475 - val_accuracy: 0.9018 - lr: 5.0000e-06\n",
      "Epoch 17/100\n",
      "69/69 [==============================] - 24s 188ms/step - loss: 0.3295 - accuracy: 0.8509 - val_loss: 0.2115 - val_accuracy: 0.9018 - lr: 5.0000e-06\n",
      "Epoch 18/100\n",
      "69/69 [==============================] - 24s 188ms/step - loss: 0.2907 - accuracy: 0.8745 - val_loss: 0.2339 - val_accuracy: 0.9018 - lr: 5.0000e-06\n",
      "Epoch 19/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.2998 - accuracy: 0.8800 - val_loss: 0.2649 - val_accuracy: 0.8839 - lr: 5.0000e-06\n",
      "Epoch 20/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.3074 - accuracy: 0.8727 - val_loss: 0.2639 - val_accuracy: 0.8839 - lr: 2.5000e-06\n",
      "Epoch 21/100\n",
      "69/69 [==============================] - 24s 188ms/step - loss: 0.3056 - accuracy: 0.8618 - val_loss: 0.3131 - val_accuracy: 0.9018 - lr: 2.5000e-06\n",
      "Epoch 22/100\n",
      "69/69 [==============================] - 25s 194ms/step - loss: 0.2992 - accuracy: 0.8745 - val_loss: 0.1781 - val_accuracy: 0.9286 - lr: 2.5000e-06\n",
      "Epoch 23/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.2907 - accuracy: 0.8764 - val_loss: 0.2273 - val_accuracy: 0.9196 - lr: 2.5000e-06\n",
      "Epoch 24/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.2972 - accuracy: 0.8600 - val_loss: 0.2960 - val_accuracy: 0.8839 - lr: 2.5000e-06\n",
      "Epoch 25/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.2915 - accuracy: 0.8782 - val_loss: 0.2539 - val_accuracy: 0.9107 - lr: 2.5000e-06\n",
      "Epoch 26/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.2844 - accuracy: 0.8782 - val_loss: 0.2649 - val_accuracy: 0.8661 - lr: 2.5000e-06\n",
      "Epoch 27/100\n",
      "69/69 [==============================] - 25s 187ms/step - loss: 0.2714 - accuracy: 0.8800 - val_loss: 0.3074 - val_accuracy: 0.9107 - lr: 2.5000e-06\n",
      "Epoch 28/100\n",
      "69/69 [==============================] - 25s 189ms/step - loss: 0.2897 - accuracy: 0.8836 - val_loss: 0.2548 - val_accuracy: 0.8750 - lr: 1.2500e-06\n",
      "Epoch 29/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.3022 - accuracy: 0.8836 - val_loss: 0.2264 - val_accuracy: 0.9018 - lr: 1.2500e-06\n",
      "Epoch 30/100\n",
      "69/69 [==============================] - 25s 188ms/step - loss: 0.2937 - accuracy: 0.8727 - val_loss: 0.2573 - val_accuracy: 0.8839 - lr: 1.2500e-06\n",
      "Epoch 31/100\n",
      "69/69 [==============================] - 26s 188ms/step - loss: 0.2955 - accuracy: 0.8709 - val_loss: 0.2585 - val_accuracy: 0.9196 - lr: 1.2500e-06\n",
      "Epoch 32/100\n",
      "69/69 [==============================] - 25s 193ms/step - loss: 0.2849 - accuracy: 0.8836 - val_loss: 0.2229 - val_accuracy: 0.9107 - lr: 1.2500e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 37s 225ms/step - loss: 0.4678 - accuracy: 0.8000 - val_loss: 0.0927 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 25s 174ms/step - loss: 0.4150 - accuracy: 0.8000 - val_loss: 0.2419 - val_accuracy: 0.9074 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.3866 - accuracy: 0.8286 - val_loss: 0.2568 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.3763 - accuracy: 0.8250 - val_loss: 0.2452 - val_accuracy: 0.8981 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 24s 174ms/step - loss: 0.3472 - accuracy: 0.8411 - val_loss: 0.3679 - val_accuracy: 0.8426 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.2940 - accuracy: 0.8679 - val_loss: 0.2122 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.3115 - accuracy: 0.8536 - val_loss: 0.3324 - val_accuracy: 0.9074 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.2681 - accuracy: 0.8804 - val_loss: 0.2492 - val_accuracy: 0.9074 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 24s 174ms/step - loss: 0.2595 - accuracy: 0.8768 - val_loss: 0.3430 - val_accuracy: 0.8704 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 24s 175ms/step - loss: 0.2323 - accuracy: 0.8929 - val_loss: 0.3335 - val_accuracy: 0.8981 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 24s 179ms/step - loss: 0.2219 - accuracy: 0.9161 - val_loss: 0.3300 - val_accuracy: 0.8704 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 40s 241ms/step - loss: 0.4023 - accuracy: 0.8286 - val_loss: 0.1036 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 25s 189ms/step - loss: 0.3492 - accuracy: 0.8464 - val_loss: 0.2180 - val_accuracy: 0.9352 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 26s 189ms/step - loss: 0.3732 - accuracy: 0.8339 - val_loss: 0.1207 - val_accuracy: 0.9630 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 25s 195ms/step - loss: 0.3687 - accuracy: 0.8375 - val_loss: 0.0992 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 25s 189ms/step - loss: 0.3371 - accuracy: 0.8357 - val_loss: 0.1124 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 25s 190ms/step - loss: 0.3493 - accuracy: 0.8321 - val_loss: 0.1477 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3751 - accuracy: 0.8304 - val_loss: 0.1514 - val_accuracy: 0.9352 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3491 - accuracy: 0.8607 - val_loss: 0.2489 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 25s 189ms/step - loss: 0.3322 - accuracy: 0.8500 - val_loss: 0.1994 - val_accuracy: 0.8981 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 25s 189ms/step - loss: 0.3572 - accuracy: 0.8411 - val_loss: 0.1557 - val_accuracy: 0.9259 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 25s 189ms/step - loss: 0.3368 - accuracy: 0.8500 - val_loss: 0.1485 - val_accuracy: 0.9537 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3338 - accuracy: 0.8482 - val_loss: 0.2394 - val_accuracy: 0.9074 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3336 - accuracy: 0.8643 - val_loss: 0.1836 - val_accuracy: 0.8981 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 26s 194ms/step - loss: 0.3118 - accuracy: 0.8714 - val_loss: 0.1811 - val_accuracy: 0.9167 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "\n",
      "=== Outer Fold 4 | Model: att_mobilenet ===\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 21s 81ms/step - loss: 0.6035 - accuracy: 0.6655 - val_loss: 0.6061 - val_accuracy: 0.6071 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 65ms/step - loss: 0.4889 - accuracy: 0.7473 - val_loss: 0.5701 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 16s 65ms/step - loss: 0.4127 - accuracy: 0.8036 - val_loss: 0.5374 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 16s 65ms/step - loss: 0.3461 - accuracy: 0.8473 - val_loss: 0.5238 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.2690 - accuracy: 0.8891 - val_loss: 0.6130 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 64ms/step - loss: 0.2314 - accuracy: 0.9182 - val_loss: 0.6599 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.1920 - accuracy: 0.9182 - val_loss: 0.8172 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.1477 - accuracy: 0.9436 - val_loss: 0.8474 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.1125 - accuracy: 0.9618 - val_loss: 1.1637 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.1132 - accuracy: 0.9709 - val_loss: 1.0767 - val_accuracy: 0.6518 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 65ms/step - loss: 0.1041 - accuracy: 0.9673 - val_loss: 1.1311 - val_accuracy: 0.6607 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.0954 - accuracy: 0.9655 - val_loss: 1.1883 - val_accuracy: 0.6696 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.0680 - accuracy: 0.9873 - val_loss: 1.2392 - val_accuracy: 0.6607 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 16s 65ms/step - loss: 0.0716 - accuracy: 0.9764 - val_loss: 1.4728 - val_accuracy: 0.6339 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 21s 85ms/step - loss: 0.5369 - accuracy: 0.7273 - val_loss: 0.5810 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 68ms/step - loss: 0.5110 - accuracy: 0.7455 - val_loss: 0.5963 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 72ms/step - loss: 0.4955 - accuracy: 0.7709 - val_loss: 0.5894 - val_accuracy: 0.6607 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 18s 72ms/step - loss: 0.4721 - accuracy: 0.7655 - val_loss: 0.5785 - val_accuracy: 0.6875 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 71ms/step - loss: 0.4786 - accuracy: 0.7564 - val_loss: 0.5717 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 71ms/step - loss: 0.4736 - accuracy: 0.7509 - val_loss: 0.5644 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.5681 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 70ms/step - loss: 0.4403 - accuracy: 0.8091 - val_loss: 0.5664 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4537 - accuracy: 0.7636 - val_loss: 0.5724 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 18s 70ms/step - loss: 0.4303 - accuracy: 0.7891 - val_loss: 0.5767 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4248 - accuracy: 0.8109 - val_loss: 0.5721 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4151 - accuracy: 0.8236 - val_loss: 0.5738 - val_accuracy: 0.7411 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4186 - accuracy: 0.8055 - val_loss: 0.5792 - val_accuracy: 0.7411 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4017 - accuracy: 0.8255 - val_loss: 0.5694 - val_accuracy: 0.7321 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4055 - accuracy: 0.8091 - val_loss: 0.5674 - val_accuracy: 0.7054 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "69/69 [==============================] - 17s 71ms/step - loss: 0.4273 - accuracy: 0.8073 - val_loss: 0.5745 - val_accuracy: 0.7143 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 22s 81ms/step - loss: 0.4203 - accuracy: 0.8291 - val_loss: 0.4672 - val_accuracy: 0.7321 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.3081 - accuracy: 0.8800 - val_loss: 0.5546 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 63ms/step - loss: 0.2947 - accuracy: 0.8545 - val_loss: 0.6603 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 67ms/step - loss: 0.2566 - accuracy: 0.8891 - val_loss: 0.5934 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.2048 - accuracy: 0.9255 - val_loss: 0.5886 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.1773 - accuracy: 0.9382 - val_loss: 0.8543 - val_accuracy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.1661 - accuracy: 0.9436 - val_loss: 0.6880 - val_accuracy: 0.7054 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.1176 - accuracy: 0.9582 - val_loss: 0.7323 - val_accuracy: 0.7589 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 63ms/step - loss: 0.0968 - accuracy: 0.9655 - val_loss: 0.7708 - val_accuracy: 0.7232 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 16s 64ms/step - loss: 0.1295 - accuracy: 0.9527 - val_loss: 0.8795 - val_accuracy: 0.6696 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 16s 65ms/step - loss: 0.1081 - accuracy: 0.9618 - val_loss: 0.9125 - val_accuracy: 0.6964 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "69/69 [==============================] - 24s 86ms/step - loss: 0.4580 - accuracy: 0.7836 - val_loss: 0.4832 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4508 - accuracy: 0.7764 - val_loss: 0.4951 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4253 - accuracy: 0.8309 - val_loss: 0.4994 - val_accuracy: 0.7411 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4537 - accuracy: 0.7800 - val_loss: 0.5113 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "69/69 [==============================] - 17s 69ms/step - loss: 0.4075 - accuracy: 0.8327 - val_loss: 0.5100 - val_accuracy: 0.7321 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.4166 - accuracy: 0.8182 - val_loss: 0.5245 - val_accuracy: 0.7411 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "69/69 [==============================] - 18s 68ms/step - loss: 0.4084 - accuracy: 0.8182 - val_loss: 0.5105 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "69/69 [==============================] - 17s 70ms/step - loss: 0.4250 - accuracy: 0.7964 - val_loss: 0.5157 - val_accuracy: 0.7589 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "69/69 [==============================] - 16s 69ms/step - loss: 0.3996 - accuracy: 0.8255 - val_loss: 0.5273 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "69/69 [==============================] - 17s 68ms/step - loss: 0.3824 - accuracy: 0.8345 - val_loss: 0.5250 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "69/69 [==============================] - 17s 70ms/step - loss: 0.3937 - accuracy: 0.8382 - val_loss: 0.5288 - val_accuracy: 0.7411 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 20s 79ms/step - loss: 0.4320 - accuracy: 0.7946 - val_loss: 0.4071 - val_accuracy: 0.7870 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.3748 - accuracy: 0.8339 - val_loss: 0.4480 - val_accuracy: 0.7593 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.2985 - accuracy: 0.8821 - val_loss: 0.5179 - val_accuracy: 0.7407 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.2789 - accuracy: 0.8768 - val_loss: 0.5440 - val_accuracy: 0.7037 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.2494 - accuracy: 0.8964 - val_loss: 0.4111 - val_accuracy: 0.8056 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.2131 - accuracy: 0.9250 - val_loss: 0.4671 - val_accuracy: 0.7685 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1669 - accuracy: 0.9357 - val_loss: 0.6622 - val_accuracy: 0.6759 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1729 - accuracy: 0.9357 - val_loss: 0.5570 - val_accuracy: 0.7407 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1164 - accuracy: 0.9643 - val_loss: 0.6906 - val_accuracy: 0.6944 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.1382 - accuracy: 0.9446 - val_loss: 0.9536 - val_accuracy: 0.6389 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.1048 - accuracy: 0.9589 - val_loss: 0.9366 - val_accuracy: 0.6481 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 22s 87ms/step - loss: 0.4568 - accuracy: 0.7946 - val_loss: 0.4779 - val_accuracy: 0.7407 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 16s 69ms/step - loss: 0.4619 - accuracy: 0.7821 - val_loss: 0.5495 - val_accuracy: 0.7037 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.4465 - accuracy: 0.7875 - val_loss: 0.5827 - val_accuracy: 0.6759 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.4636 - accuracy: 0.8036 - val_loss: 0.6070 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.4306 - accuracy: 0.8196 - val_loss: 0.6168 - val_accuracy: 0.6574 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.4328 - accuracy: 0.8143 - val_loss: 0.6078 - val_accuracy: 0.6667 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.4340 - accuracy: 0.8054 - val_loss: 0.6281 - val_accuracy: 0.6667 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.4316 - accuracy: 0.8054 - val_loss: 0.6025 - val_accuracy: 0.6574 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.4362 - accuracy: 0.7946 - val_loss: 0.6132 - val_accuracy: 0.6574 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.4162 - accuracy: 0.8232 - val_loss: 0.5969 - val_accuracy: 0.6204 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 69ms/step - loss: 0.4321 - accuracy: 0.8018 - val_loss: 0.5863 - val_accuracy: 0.6389 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "=== Outer Fold 5 | Model: std_densenet ===\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 28s 113ms/step - loss: 0.7172 - accuracy: 0.5089 - val_loss: 0.8611 - val_accuracy: 0.4911 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.6649 - accuracy: 0.5661 - val_loss: 0.7724 - val_accuracy: 0.4821 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.6443 - accuracy: 0.6036 - val_loss: 0.8714 - val_accuracy: 0.5089 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.6311 - accuracy: 0.6107 - val_loss: 0.9089 - val_accuracy: 0.4911 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.6213 - accuracy: 0.6000 - val_loss: 0.7431 - val_accuracy: 0.5357 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.6257 - accuracy: 0.6071 - val_loss: 0.9124 - val_accuracy: 0.5179 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.6200 - accuracy: 0.5696 - val_loss: 0.8431 - val_accuracy: 0.5268 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.5950 - accuracy: 0.6268 - val_loss: 0.8596 - val_accuracy: 0.5536 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.5927 - accuracy: 0.6161 - val_loss: 1.2166 - val_accuracy: 0.5536 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.5844 - accuracy: 0.6232 - val_loss: 0.9497 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 17s 66ms/step - loss: 0.5733 - accuracy: 0.6304 - val_loss: 0.9265 - val_accuracy: 0.5357 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.5650 - accuracy: 0.6589 - val_loss: 0.9665 - val_accuracy: 0.5536 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.5778 - accuracy: 0.6429 - val_loss: 0.8602 - val_accuracy: 0.5804 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.5729 - accuracy: 0.6089 - val_loss: 0.8357 - val_accuracy: 0.5804 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.5861 - accuracy: 0.6232 - val_loss: 0.9433 - val_accuracy: 0.5536 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 30s 132ms/step - loss: 0.7530 - accuracy: 0.5625 - val_loss: 0.7507 - val_accuracy: 0.5893 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 18s 85ms/step - loss: 0.6568 - accuracy: 0.5946 - val_loss: 0.8721 - val_accuracy: 0.5268 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 18s 85ms/step - loss: 0.6727 - accuracy: 0.5875 - val_loss: 0.7749 - val_accuracy: 0.5804 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.6562 - accuracy: 0.5893 - val_loss: 0.8517 - val_accuracy: 0.5982 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.6522 - accuracy: 0.5946 - val_loss: 0.9663 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 19s 86ms/step - loss: 0.6306 - accuracy: 0.6393 - val_loss: 0.8920 - val_accuracy: 0.5446 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 18s 93ms/step - loss: 0.5939 - accuracy: 0.6446 - val_loss: 0.9420 - val_accuracy: 0.5446 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 18s 87ms/step - loss: 0.6170 - accuracy: 0.6196 - val_loss: 0.9885 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 18s 89ms/step - loss: 0.5877 - accuracy: 0.6411 - val_loss: 0.9978 - val_accuracy: 0.5357 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.5860 - accuracy: 0.6482 - val_loss: 1.0040 - val_accuracy: 0.5268 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 18s 91ms/step - loss: 0.6010 - accuracy: 0.6214 - val_loss: 0.9095 - val_accuracy: 0.5893 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 28s 115ms/step - loss: 0.6662 - accuracy: 0.6000 - val_loss: 0.3179 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.6395 - accuracy: 0.5732 - val_loss: 0.3494 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.6193 - accuracy: 0.6214 - val_loss: 0.3298 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.6175 - accuracy: 0.5821 - val_loss: 0.3154 - val_accuracy: 0.8482 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 18s 68ms/step - loss: 0.6121 - accuracy: 0.6125 - val_loss: 0.3142 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.6122 - accuracy: 0.5786 - val_loss: 0.3201 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 18s 68ms/step - loss: 0.5757 - accuracy: 0.6375 - val_loss: 0.3119 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 64ms/step - loss: 0.5763 - accuracy: 0.6411 - val_loss: 0.3550 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.5804 - accuracy: 0.6232 - val_loss: 0.4035 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 17s 64ms/step - loss: 0.5706 - accuracy: 0.6250 - val_loss: 0.3298 - val_accuracy: 0.8304 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 17s 64ms/step - loss: 0.5790 - accuracy: 0.6214 - val_loss: 0.3575 - val_accuracy: 0.8482 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.5743 - accuracy: 0.6393 - val_loss: 0.3679 - val_accuracy: 0.8482 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.5533 - accuracy: 0.6464 - val_loss: 0.3599 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.5424 - accuracy: 0.6786 - val_loss: 0.3867 - val_accuracy: 0.8036 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.5512 - accuracy: 0.6696 - val_loss: 0.3570 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 18s 64ms/step - loss: 0.5593 - accuracy: 0.6321 - val_loss: 0.3480 - val_accuracy: 0.8393 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 18s 69ms/step - loss: 0.5679 - accuracy: 0.6625 - val_loss: 0.3597 - val_accuracy: 0.8304 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 34s 137ms/step - loss: 0.6584 - accuracy: 0.5839 - val_loss: 0.3262 - val_accuracy: 0.8482 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 19s 85ms/step - loss: 0.6601 - accuracy: 0.5964 - val_loss: 0.3585 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.6408 - accuracy: 0.6125 - val_loss: 0.4022 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.6389 - accuracy: 0.6304 - val_loss: 0.3275 - val_accuracy: 0.8393 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.6439 - accuracy: 0.6125 - val_loss: 0.3792 - val_accuracy: 0.8393 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.6062 - accuracy: 0.6339 - val_loss: 0.3475 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.5979 - accuracy: 0.5982 - val_loss: 0.3963 - val_accuracy: 0.8214 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.5975 - accuracy: 0.6304 - val_loss: 0.3656 - val_accuracy: 0.8571 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.6074 - accuracy: 0.6250 - val_loss: 0.3419 - val_accuracy: 0.8750 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.5731 - accuracy: 0.6482 - val_loss: 0.3886 - val_accuracy: 0.8214 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 19s 90ms/step - loss: 0.6028 - accuracy: 0.6125 - val_loss: 0.3770 - val_accuracy: 0.8482 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 27s 112ms/step - loss: 0.6337 - accuracy: 0.6089 - val_loss: 0.2267 - val_accuracy: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.5867 - accuracy: 0.6304 - val_loss: 0.2222 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.5819 - accuracy: 0.6107 - val_loss: 0.2090 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.5795 - accuracy: 0.6464 - val_loss: 0.2170 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 17s 64ms/step - loss: 0.5907 - accuracy: 0.6286 - val_loss: 0.2609 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.5727 - accuracy: 0.6161 - val_loss: 0.2708 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.5612 - accuracy: 0.6464 - val_loss: 0.2542 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.5662 - accuracy: 0.6375 - val_loss: 0.2600 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 17s 65ms/step - loss: 0.5591 - accuracy: 0.6250 - val_loss: 0.2202 - val_accuracy: 0.9375 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.5483 - accuracy: 0.6411 - val_loss: 0.2484 - val_accuracy: 0.9286 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.5479 - accuracy: 0.6339 - val_loss: 0.2385 - val_accuracy: 0.9286 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.5384 - accuracy: 0.6732 - val_loss: 0.2378 - val_accuracy: 0.9018 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.5492 - accuracy: 0.6554 - val_loss: 0.2270 - val_accuracy: 0.9196 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 31s 135ms/step - loss: 0.6447 - accuracy: 0.5839 - val_loss: 0.2366 - val_accuracy: 0.9375 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 19s 96ms/step - loss: 0.6064 - accuracy: 0.6232 - val_loss: 0.2065 - val_accuracy: 0.9554 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.6066 - accuracy: 0.6411 - val_loss: 0.2082 - val_accuracy: 0.9375 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.5812 - accuracy: 0.6429 - val_loss: 0.2283 - val_accuracy: 0.8929 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 18s 87ms/step - loss: 0.6078 - accuracy: 0.5839 - val_loss: 0.2401 - val_accuracy: 0.9018 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 18s 87ms/step - loss: 0.5766 - accuracy: 0.6518 - val_loss: 0.2687 - val_accuracy: 0.8929 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.5926 - accuracy: 0.6304 - val_loss: 0.2956 - val_accuracy: 0.8839 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 18s 92ms/step - loss: 0.5793 - accuracy: 0.6375 - val_loss: 0.2391 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 19s 86ms/step - loss: 0.5684 - accuracy: 0.6554 - val_loss: 0.2555 - val_accuracy: 0.8661 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 18s 86ms/step - loss: 0.5730 - accuracy: 0.6464 - val_loss: 0.2419 - val_accuracy: 0.8839 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 18s 87ms/step - loss: 0.5969 - accuracy: 0.6268 - val_loss: 0.2636 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 18s 92ms/step - loss: 0.5734 - accuracy: 0.6411 - val_loss: 0.2883 - val_accuracy: 0.8839 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "\n",
      "=== Outer Fold 5 | Model: std_mobilenet ===\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 17s 44ms/step - loss: 0.7475 - accuracy: 0.4750 - val_loss: 0.6979 - val_accuracy: 0.4732 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.7023 - accuracy: 0.5482 - val_loss: 0.7251 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 31ms/step - loss: 0.7037 - accuracy: 0.5357 - val_loss: 0.7205 - val_accuracy: 0.4821 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 14s 31ms/step - loss: 0.6774 - accuracy: 0.5679 - val_loss: 0.7412 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6996 - accuracy: 0.5482 - val_loss: 0.7586 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 14s 31ms/step - loss: 0.6819 - accuracy: 0.5571 - val_loss: 0.7767 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.7020 - accuracy: 0.5125 - val_loss: 0.7671 - val_accuracy: 0.4554 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 31ms/step - loss: 0.6862 - accuracy: 0.5429 - val_loss: 0.7705 - val_accuracy: 0.4554 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.6784 - accuracy: 0.5661 - val_loss: 0.7731 - val_accuracy: 0.4464 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.6882 - accuracy: 0.5482 - val_loss: 0.7818 - val_accuracy: 0.4554 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 32ms/step - loss: 0.6950 - accuracy: 0.5036 - val_loss: 0.7936 - val_accuracy: 0.4821 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 18s 50ms/step - loss: 0.7165 - accuracy: 0.5589 - val_loss: 0.7024 - val_accuracy: 0.4554 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6789 - accuracy: 0.5768 - val_loss: 0.7033 - val_accuracy: 0.4643 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6633 - accuracy: 0.5982 - val_loss: 0.7051 - val_accuracy: 0.4643 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 15s 42ms/step - loss: 0.6766 - accuracy: 0.5911 - val_loss: 0.7082 - val_accuracy: 0.4732 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 15s 37ms/step - loss: 0.6637 - accuracy: 0.5732 - val_loss: 0.7117 - val_accuracy: 0.4554 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6387 - accuracy: 0.6018 - val_loss: 0.7131 - val_accuracy: 0.4464 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 14s 38ms/step - loss: 0.6511 - accuracy: 0.6196 - val_loss: 0.7160 - val_accuracy: 0.4464 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6377 - accuracy: 0.6250 - val_loss: 0.7169 - val_accuracy: 0.4464 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6151 - accuracy: 0.6393 - val_loss: 0.7169 - val_accuracy: 0.4375 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6348 - accuracy: 0.6250 - val_loss: 0.7125 - val_accuracy: 0.4464 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6446 - accuracy: 0.6196 - val_loss: 0.7133 - val_accuracy: 0.4464 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 18s 50ms/step - loss: 0.7234 - accuracy: 0.5250 - val_loss: 0.6836 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 15s 32ms/step - loss: 0.7222 - accuracy: 0.5214 - val_loss: 0.6735 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 32ms/step - loss: 0.7090 - accuracy: 0.5196 - val_loss: 0.6623 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 14s 28ms/step - loss: 0.7101 - accuracy: 0.5375 - val_loss: 0.6659 - val_accuracy: 0.6339 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6975 - accuracy: 0.5518 - val_loss: 0.6708 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.7013 - accuracy: 0.5321 - val_loss: 0.6597 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.7092 - accuracy: 0.5179 - val_loss: 0.6681 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.7023 - accuracy: 0.5196 - val_loss: 0.6659 - val_accuracy: 0.5893 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 32ms/step - loss: 0.6854 - accuracy: 0.5500 - val_loss: 0.6518 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 14s 28ms/step - loss: 0.6910 - accuracy: 0.5357 - val_loss: 0.6591 - val_accuracy: 0.5625 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.7001 - accuracy: 0.5321 - val_loss: 0.6564 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.6894 - accuracy: 0.5393 - val_loss: 0.6587 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 14s 28ms/step - loss: 0.6908 - accuracy: 0.5232 - val_loss: 0.6573 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 15s 30ms/step - loss: 0.6771 - accuracy: 0.5446 - val_loss: 0.6588 - val_accuracy: 0.5714 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.6842 - accuracy: 0.5375 - val_loss: 0.6609 - val_accuracy: 0.6161 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 15s 31ms/step - loss: 0.6887 - accuracy: 0.5214 - val_loss: 0.6602 - val_accuracy: 0.5000 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.6924 - accuracy: 0.5089 - val_loss: 0.6571 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 15s 32ms/step - loss: 0.6873 - accuracy: 0.5250 - val_loss: 0.6533 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 14s 31ms/step - loss: 0.6900 - accuracy: 0.5429 - val_loss: 0.6542 - val_accuracy: 0.6786 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 22s 54ms/step - loss: 0.8373 - accuracy: 0.5179 - val_loss: 0.6558 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 15s 36ms/step - loss: 0.7224 - accuracy: 0.5214 - val_loss: 0.6567 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 16s 38ms/step - loss: 0.7269 - accuracy: 0.5357 - val_loss: 0.6557 - val_accuracy: 0.5625 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 39ms/step - loss: 0.7133 - accuracy: 0.5393 - val_loss: 0.6556 - val_accuracy: 0.4911 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 38ms/step - loss: 0.6992 - accuracy: 0.5232 - val_loss: 0.6598 - val_accuracy: 0.4196 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 38ms/step - loss: 0.6896 - accuracy: 0.5679 - val_loss: 0.6633 - val_accuracy: 0.4464 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 15s 37ms/step - loss: 0.6838 - accuracy: 0.5536 - val_loss: 0.6681 - val_accuracy: 0.4732 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 38ms/step - loss: 0.6744 - accuracy: 0.5554 - val_loss: 0.6732 - val_accuracy: 0.5000 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 42ms/step - loss: 0.6730 - accuracy: 0.5661 - val_loss: 0.6770 - val_accuracy: 0.5000 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 15s 36ms/step - loss: 0.6814 - accuracy: 0.5679 - val_loss: 0.6781 - val_accuracy: 0.5000 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6576 - accuracy: 0.6036 - val_loss: 0.6833 - val_accuracy: 0.5000 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6622 - accuracy: 0.5482 - val_loss: 0.6857 - val_accuracy: 0.5000 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6725 - accuracy: 0.5714 - val_loss: 0.6846 - val_accuracy: 0.5000 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 15s 38ms/step - loss: 0.6602 - accuracy: 0.5821 - val_loss: 0.6872 - val_accuracy: 0.5000 - lr: 2.5000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 17s 44ms/step - loss: 0.7020 - accuracy: 0.5268 - val_loss: 0.5709 - val_accuracy: 0.7768 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 14s 34ms/step - loss: 0.7163 - accuracy: 0.4857 - val_loss: 0.6059 - val_accuracy: 0.4911 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 33ms/step - loss: 0.6997 - accuracy: 0.5196 - val_loss: 0.6033 - val_accuracy: 0.4911 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 14s 33ms/step - loss: 0.6917 - accuracy: 0.5339 - val_loss: 0.6695 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 14s 34ms/step - loss: 0.7128 - accuracy: 0.4875 - val_loss: 0.6049 - val_accuracy: 0.7768 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 14s 29ms/step - loss: 0.7050 - accuracy: 0.5232 - val_loss: 0.6301 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 14s 31ms/step - loss: 0.7018 - accuracy: 0.5036 - val_loss: 0.5964 - val_accuracy: 0.7857 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 33ms/step - loss: 0.6893 - accuracy: 0.5161 - val_loss: 0.5999 - val_accuracy: 0.7411 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.6929 - accuracy: 0.5232 - val_loss: 0.5922 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 14s 30ms/step - loss: 0.6975 - accuracy: 0.5196 - val_loss: 0.5959 - val_accuracy: 0.8036 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 31ms/step - loss: 0.7071 - accuracy: 0.4929 - val_loss: 0.6141 - val_accuracy: 0.5000 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 18s 50ms/step - loss: 0.7212 - accuracy: 0.5375 - val_loss: 0.5657 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 15s 39ms/step - loss: 0.6894 - accuracy: 0.5375 - val_loss: 0.5695 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.7127 - accuracy: 0.5107 - val_loss: 0.5656 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.7018 - accuracy: 0.5339 - val_loss: 0.5646 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6715 - accuracy: 0.5554 - val_loss: 0.5680 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 15s 38ms/step - loss: 0.6869 - accuracy: 0.5625 - val_loss: 0.5597 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6738 - accuracy: 0.5750 - val_loss: 0.5721 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6959 - accuracy: 0.5268 - val_loss: 0.5680 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 14s 40ms/step - loss: 0.6747 - accuracy: 0.5732 - val_loss: 0.5774 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6564 - accuracy: 0.6143 - val_loss: 0.5892 - val_accuracy: 0.7857 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6497 - accuracy: 0.5982 - val_loss: 0.5954 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 14s 36ms/step - loss: 0.6534 - accuracy: 0.6071 - val_loss: 0.5895 - val_accuracy: 0.7857 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 15s 38ms/step - loss: 0.6558 - accuracy: 0.6054 - val_loss: 0.5976 - val_accuracy: 0.7589 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 15s 36ms/step - loss: 0.6469 - accuracy: 0.5911 - val_loss: 0.6112 - val_accuracy: 0.7946 - lr: 5.0000e-06\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 14s 37ms/step - loss: 0.6428 - accuracy: 0.6089 - val_loss: 0.6052 - val_accuracy: 0.7768 - lr: 5.0000e-06\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 14s 38ms/step - loss: 0.6484 - accuracy: 0.5786 - val_loss: 0.6125 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 1s 713ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "\n",
      "=== Outer Fold 5 | Model: att_densenet ===\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 36s 222ms/step - loss: 0.7024 - accuracy: 0.6554 - val_loss: 0.5896 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 25s 179ms/step - loss: 0.4924 - accuracy: 0.7607 - val_loss: 0.5737 - val_accuracy: 0.6964 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 24s 175ms/step - loss: 0.4274 - accuracy: 0.8125 - val_loss: 0.6561 - val_accuracy: 0.6250 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.3351 - accuracy: 0.8500 - val_loss: 0.6431 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 24s 174ms/step - loss: 0.3131 - accuracy: 0.8804 - val_loss: 0.6586 - val_accuracy: 0.6696 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.2838 - accuracy: 0.8857 - val_loss: 1.0305 - val_accuracy: 0.6518 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.2317 - accuracy: 0.9143 - val_loss: 1.0117 - val_accuracy: 0.6161 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.1910 - accuracy: 0.9268 - val_loss: 1.3961 - val_accuracy: 0.5714 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.1776 - accuracy: 0.9339 - val_loss: 0.9347 - val_accuracy: 0.6429 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.1998 - accuracy: 0.9125 - val_loss: 1.3114 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 25s 173ms/step - loss: 0.1571 - accuracy: 0.9393 - val_loss: 1.5074 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 24s 178ms/step - loss: 0.1447 - accuracy: 0.9411 - val_loss: 1.5206 - val_accuracy: 0.6250 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 39s 237ms/step - loss: 0.4798 - accuracy: 0.7554 - val_loss: 0.6037 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.4472 - accuracy: 0.8054 - val_loss: 0.7088 - val_accuracy: 0.6429 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.3870 - accuracy: 0.8321 - val_loss: 0.8286 - val_accuracy: 0.6250 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.4182 - accuracy: 0.8161 - val_loss: 0.8562 - val_accuracy: 0.6161 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 26s 189ms/step - loss: 0.4015 - accuracy: 0.8250 - val_loss: 0.8335 - val_accuracy: 0.6696 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3994 - accuracy: 0.8321 - val_loss: 1.0298 - val_accuracy: 0.5982 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.3795 - accuracy: 0.8375 - val_loss: 0.9532 - val_accuracy: 0.6607 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 25s 187ms/step - loss: 0.3698 - accuracy: 0.8375 - val_loss: 1.0355 - val_accuracy: 0.6429 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3900 - accuracy: 0.8321 - val_loss: 0.9671 - val_accuracy: 0.6250 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3674 - accuracy: 0.8536 - val_loss: 0.8335 - val_accuracy: 0.6429 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 25s 193ms/step - loss: 0.3612 - accuracy: 0.8536 - val_loss: 0.9048 - val_accuracy: 0.6339 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 35s 221ms/step - loss: 0.6103 - accuracy: 0.6804 - val_loss: 0.3371 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 24s 179ms/step - loss: 0.5097 - accuracy: 0.7286 - val_loss: 0.2827 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.4442 - accuracy: 0.7893 - val_loss: 0.3023 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 23s 171ms/step - loss: 0.4461 - accuracy: 0.7768 - val_loss: 0.3574 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.3891 - accuracy: 0.8196 - val_loss: 0.2957 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.3328 - accuracy: 0.8571 - val_loss: 0.4109 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.3132 - accuracy: 0.8500 - val_loss: 0.4191 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 25s 172ms/step - loss: 0.2969 - accuracy: 0.8696 - val_loss: 0.4117 - val_accuracy: 0.7946 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.2569 - accuracy: 0.8786 - val_loss: 0.4138 - val_accuracy: 0.8214 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.2385 - accuracy: 0.8911 - val_loss: 0.5067 - val_accuracy: 0.7679 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.2194 - accuracy: 0.8964 - val_loss: 0.4962 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 24s 177ms/step - loss: 0.2524 - accuracy: 0.8893 - val_loss: 0.4447 - val_accuracy: 0.8036 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 40s 239ms/step - loss: 0.4528 - accuracy: 0.7857 - val_loss: 0.2958 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 26s 196ms/step - loss: 0.4433 - accuracy: 0.7839 - val_loss: 0.2936 - val_accuracy: 0.8393 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.4250 - accuracy: 0.7893 - val_loss: 0.3378 - val_accuracy: 0.8571 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 26s 194ms/step - loss: 0.4143 - accuracy: 0.8036 - val_loss: 0.2915 - val_accuracy: 0.8839 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.3862 - accuracy: 0.8125 - val_loss: 0.3168 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 26s 189ms/step - loss: 0.3931 - accuracy: 0.8089 - val_loss: 0.3451 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.3842 - accuracy: 0.8107 - val_loss: 0.3521 - val_accuracy: 0.8393 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.3814 - accuracy: 0.8250 - val_loss: 0.3026 - val_accuracy: 0.8750 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 27s 189ms/step - loss: 0.3925 - accuracy: 0.8054 - val_loss: 0.3531 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 27s 189ms/step - loss: 0.3557 - accuracy: 0.8500 - val_loss: 0.3295 - val_accuracy: 0.8393 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 26s 189ms/step - loss: 0.3753 - accuracy: 0.8232 - val_loss: 0.3171 - val_accuracy: 0.8393 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 26s 189ms/step - loss: 0.3548 - accuracy: 0.8357 - val_loss: 0.3179 - val_accuracy: 0.8393 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 26s 188ms/step - loss: 0.3384 - accuracy: 0.8482 - val_loss: 0.3883 - val_accuracy: 0.8125 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 26s 194ms/step - loss: 0.3585 - accuracy: 0.8268 - val_loss: 0.3003 - val_accuracy: 0.8571 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 37s 225ms/step - loss: 0.4881 - accuracy: 0.7429 - val_loss: 0.1822 - val_accuracy: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 25s 173ms/step - loss: 0.4274 - accuracy: 0.7964 - val_loss: 0.3001 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.3625 - accuracy: 0.8286 - val_loss: 0.1930 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 24s 176ms/step - loss: 0.3490 - accuracy: 0.8196 - val_loss: 0.3016 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.3301 - accuracy: 0.8339 - val_loss: 0.2546 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 24s 173ms/step - loss: 0.3116 - accuracy: 0.8536 - val_loss: 0.2787 - val_accuracy: 0.8839 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 24s 174ms/step - loss: 0.2968 - accuracy: 0.8554 - val_loss: 0.2231 - val_accuracy: 0.8839 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.2853 - accuracy: 0.8750 - val_loss: 0.1862 - val_accuracy: 0.9107 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.2482 - accuracy: 0.8964 - val_loss: 0.2490 - val_accuracy: 0.8929 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 24s 172ms/step - loss: 0.2346 - accuracy: 0.8786 - val_loss: 0.1974 - val_accuracy: 0.9107 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 24s 179ms/step - loss: 0.2535 - accuracy: 0.8714 - val_loss: 0.1897 - val_accuracy: 0.9107 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 39s 240ms/step - loss: 0.4074 - accuracy: 0.7929 - val_loss: 0.1507 - val_accuracy: 0.9464 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 25s 190ms/step - loss: 0.3752 - accuracy: 0.8036 - val_loss: 0.2045 - val_accuracy: 0.9196 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3735 - accuracy: 0.8143 - val_loss: 0.2176 - val_accuracy: 0.9018 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 25s 189ms/step - loss: 0.3616 - accuracy: 0.8196 - val_loss: 0.1612 - val_accuracy: 0.9018 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 25s 190ms/step - loss: 0.3374 - accuracy: 0.8446 - val_loss: 0.1883 - val_accuracy: 0.9018 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3398 - accuracy: 0.8411 - val_loss: 0.1579 - val_accuracy: 0.9286 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 25s 189ms/step - loss: 0.3375 - accuracy: 0.8464 - val_loss: 0.1853 - val_accuracy: 0.9196 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 25s 194ms/step - loss: 0.3507 - accuracy: 0.8268 - val_loss: 0.1042 - val_accuracy: 0.9643 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3259 - accuracy: 0.8393 - val_loss: 0.1362 - val_accuracy: 0.9554 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 25s 190ms/step - loss: 0.3400 - accuracy: 0.8304 - val_loss: 0.1725 - val_accuracy: 0.9196 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3162 - accuracy: 0.8589 - val_loss: 0.1082 - val_accuracy: 0.9464 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3313 - accuracy: 0.8393 - val_loss: 0.1973 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3233 - accuracy: 0.8375 - val_loss: 0.1716 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 25s 189ms/step - loss: 0.3392 - accuracy: 0.8375 - val_loss: 0.1364 - val_accuracy: 0.9196 - lr: 2.5000e-06\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 25s 189ms/step - loss: 0.3146 - accuracy: 0.8429 - val_loss: 0.1667 - val_accuracy: 0.9196 - lr: 2.5000e-06\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 25s 190ms/step - loss: 0.3106 - accuracy: 0.8375 - val_loss: 0.1379 - val_accuracy: 0.9464 - lr: 2.5000e-06\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 25s 188ms/step - loss: 0.3252 - accuracy: 0.8429 - val_loss: 0.1982 - val_accuracy: 0.9018 - lr: 2.5000e-06\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 25s 194ms/step - loss: 0.3481 - accuracy: 0.8268 - val_loss: 0.1805 - val_accuracy: 0.9107 - lr: 2.5000e-06\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "\n",
      "=== Outer Fold 5 | Model: att_mobilenet ===\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 21s 81ms/step - loss: 0.5424 - accuracy: 0.7589 - val_loss: 0.5904 - val_accuracy: 0.6875 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.4030 - accuracy: 0.8232 - val_loss: 0.5701 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.3358 - accuracy: 0.8464 - val_loss: 0.5864 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.2602 - accuracy: 0.8964 - val_loss: 0.6476 - val_accuracy: 0.6071 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.2297 - accuracy: 0.9018 - val_loss: 0.7777 - val_accuracy: 0.5982 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.1636 - accuracy: 0.9446 - val_loss: 0.8374 - val_accuracy: 0.5982 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1574 - accuracy: 0.9446 - val_loss: 1.1410 - val_accuracy: 0.6607 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0983 - accuracy: 0.9679 - val_loss: 0.8802 - val_accuracy: 0.6071 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0762 - accuracy: 0.9804 - val_loss: 1.1508 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0937 - accuracy: 0.9625 - val_loss: 1.2735 - val_accuracy: 0.5804 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0598 - accuracy: 0.9839 - val_loss: 1.3373 - val_accuracy: 0.5893 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 16s 65ms/step - loss: 0.0898 - accuracy: 0.9661 - val_loss: 1.3197 - val_accuracy: 0.5982 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 24s 85ms/step - loss: 0.5503 - accuracy: 0.7107 - val_loss: 0.5705 - val_accuracy: 0.6964 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.5106 - accuracy: 0.7429 - val_loss: 0.5634 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.4788 - accuracy: 0.7982 - val_loss: 0.5645 - val_accuracy: 0.6786 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.4578 - accuracy: 0.8036 - val_loss: 0.5708 - val_accuracy: 0.6964 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.4469 - accuracy: 0.8000 - val_loss: 0.5866 - val_accuracy: 0.7054 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.4564 - accuracy: 0.7982 - val_loss: 0.5899 - val_accuracy: 0.7054 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.4379 - accuracy: 0.8125 - val_loss: 0.5977 - val_accuracy: 0.6964 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.4375 - accuracy: 0.8018 - val_loss: 0.6072 - val_accuracy: 0.6964 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.4236 - accuracy: 0.8125 - val_loss: 0.6232 - val_accuracy: 0.7054 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.4178 - accuracy: 0.8250 - val_loss: 0.6352 - val_accuracy: 0.7143 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.4038 - accuracy: 0.8268 - val_loss: 0.6435 - val_accuracy: 0.7054 - lr: 5.0000e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 16s 70ms/step - loss: 0.4006 - accuracy: 0.8214 - val_loss: 0.6393 - val_accuracy: 0.7143 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 20s 80ms/step - loss: 0.5054 - accuracy: 0.7339 - val_loss: 0.4346 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 63ms/step - loss: 0.4027 - accuracy: 0.8125 - val_loss: 0.4652 - val_accuracy: 0.7679 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.3660 - accuracy: 0.8357 - val_loss: 0.4425 - val_accuracy: 0.7768 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.3412 - accuracy: 0.8500 - val_loss: 0.4374 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.2720 - accuracy: 0.8625 - val_loss: 0.3978 - val_accuracy: 0.8393 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.2117 - accuracy: 0.9196 - val_loss: 0.6185 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 66ms/step - loss: 0.1805 - accuracy: 0.9375 - val_loss: 0.6307 - val_accuracy: 0.7054 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1263 - accuracy: 0.9554 - val_loss: 0.4888 - val_accuracy: 0.7768 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 17s 64ms/step - loss: 0.1238 - accuracy: 0.9571 - val_loss: 0.8275 - val_accuracy: 0.6786 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 17s 63ms/step - loss: 0.1061 - accuracy: 0.9589 - val_loss: 0.8378 - val_accuracy: 0.6429 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0831 - accuracy: 0.9768 - val_loss: 0.7301 - val_accuracy: 0.7143 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0546 - accuracy: 0.9857 - val_loss: 0.9286 - val_accuracy: 0.6250 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0515 - accuracy: 0.9875 - val_loss: 0.8033 - val_accuracy: 0.6875 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.0668 - accuracy: 0.9768 - val_loss: 0.5303 - val_accuracy: 0.7232 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.0610 - accuracy: 0.9786 - val_loss: 0.7384 - val_accuracy: 0.7321 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 21s 84ms/step - loss: 0.4711 - accuracy: 0.7607 - val_loss: 0.6158 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.4477 - accuracy: 0.7857 - val_loss: 0.6159 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.4519 - accuracy: 0.7911 - val_loss: 0.5845 - val_accuracy: 0.7500 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 17s 71ms/step - loss: 0.4506 - accuracy: 0.7786 - val_loss: 0.5792 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 18s 70ms/step - loss: 0.4378 - accuracy: 0.7982 - val_loss: 0.5461 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.4192 - accuracy: 0.8143 - val_loss: 0.5206 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 18s 68ms/step - loss: 0.3993 - accuracy: 0.8161 - val_loss: 0.5230 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.4043 - accuracy: 0.8018 - val_loss: 0.5255 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 18s 70ms/step - loss: 0.4086 - accuracy: 0.8107 - val_loss: 0.5059 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 18s 70ms/step - loss: 0.4143 - accuracy: 0.8054 - val_loss: 0.4993 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 18s 71ms/step - loss: 0.4038 - accuracy: 0.8268 - val_loss: 0.4973 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 17s 70ms/step - loss: 0.3873 - accuracy: 0.8214 - val_loss: 0.4832 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 18s 71ms/step - loss: 0.3721 - accuracy: 0.8464 - val_loss: 0.4774 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 18s 70ms/step - loss: 0.3688 - accuracy: 0.8393 - val_loss: 0.4696 - val_accuracy: 0.8393 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 18s 71ms/step - loss: 0.3793 - accuracy: 0.8232 - val_loss: 0.4534 - val_accuracy: 0.8214 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 17s 71ms/step - loss: 0.3677 - accuracy: 0.8286 - val_loss: 0.4382 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 18s 71ms/step - loss: 0.3659 - accuracy: 0.8375 - val_loss: 0.4366 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 18s 70ms/step - loss: 0.3492 - accuracy: 0.8357 - val_loss: 0.4345 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 18s 69ms/step - loss: 0.3369 - accuracy: 0.8429 - val_loss: 0.4361 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 16s 70ms/step - loss: 0.3471 - accuracy: 0.8482 - val_loss: 0.4277 - val_accuracy: 0.7857 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3330 - accuracy: 0.8554 - val_loss: 0.4333 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 16s 70ms/step - loss: 0.3334 - accuracy: 0.8661 - val_loss: 0.4274 - val_accuracy: 0.8304 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3126 - accuracy: 0.8732 - val_loss: 0.4242 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.3190 - accuracy: 0.8482 - val_loss: 0.4305 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3006 - accuracy: 0.8893 - val_loss: 0.4198 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3264 - accuracy: 0.8768 - val_loss: 0.4278 - val_accuracy: 0.7946 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3151 - accuracy: 0.8589 - val_loss: 0.4368 - val_accuracy: 0.7857 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3120 - accuracy: 0.8661 - val_loss: 0.4358 - val_accuracy: 0.8036 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.3057 - accuracy: 0.8821 - val_loss: 0.4517 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.3062 - accuracy: 0.8714 - val_loss: 0.4396 - val_accuracy: 0.8125 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.2947 - accuracy: 0.8750 - val_loss: 0.4560 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.2933 - accuracy: 0.8714 - val_loss: 0.4871 - val_accuracy: 0.7500 - lr: 5.0000e-06\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 17s 69ms/step - loss: 0.2946 - accuracy: 0.8679 - val_loss: 0.4628 - val_accuracy: 0.7500 - lr: 5.0000e-06\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.2902 - accuracy: 0.8786 - val_loss: 0.4555 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 16s 70ms/step - loss: 0.2809 - accuracy: 0.8857 - val_loss: 0.4843 - val_accuracy: 0.7232 - lr: 5.0000e-06\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 20s 79ms/step - loss: 0.4076 - accuracy: 0.7786 - val_loss: 0.3738 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.3268 - accuracy: 0.8500 - val_loss: 0.3644 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.2952 - accuracy: 0.8821 - val_loss: 0.3565 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.2902 - accuracy: 0.8750 - val_loss: 0.3504 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.2573 - accuracy: 0.8875 - val_loss: 0.3059 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.2264 - accuracy: 0.9071 - val_loss: 0.3426 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.2319 - accuracy: 0.8929 - val_loss: 0.3373 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1848 - accuracy: 0.9232 - val_loss: 0.4319 - val_accuracy: 0.8125 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1701 - accuracy: 0.9375 - val_loss: 0.3784 - val_accuracy: 0.8661 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1776 - accuracy: 0.9214 - val_loss: 0.3216 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1340 - accuracy: 0.9536 - val_loss: 0.3131 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.1539 - accuracy: 0.9357 - val_loss: 0.3277 - val_accuracy: 0.8393 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 16s 62ms/step - loss: 0.1203 - accuracy: 0.9607 - val_loss: 0.3748 - val_accuracy: 0.8125 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 16s 63ms/step - loss: 0.0919 - accuracy: 0.9732 - val_loss: 0.3889 - val_accuracy: 0.8214 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 16s 64ms/step - loss: 0.1058 - accuracy: 0.9607 - val_loss: 0.3395 - val_accuracy: 0.8661 - lr: 5.0000e-05\n",
      "Epoch 1/100\n",
      "70/70 [==============================] - 21s 87ms/step - loss: 0.3182 - accuracy: 0.8589 - val_loss: 0.4358 - val_accuracy: 0.7857 - lr: 1.0000e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.2869 - accuracy: 0.8804 - val_loss: 0.4575 - val_accuracy: 0.7589 - lr: 1.0000e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 17s 67ms/step - loss: 0.3095 - accuracy: 0.8750 - val_loss: 0.4925 - val_accuracy: 0.7411 - lr: 1.0000e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.2837 - accuracy: 0.8804 - val_loss: 0.4726 - val_accuracy: 0.7768 - lr: 1.0000e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.2857 - accuracy: 0.8714 - val_loss: 0.4967 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.2782 - accuracy: 0.8821 - val_loss: 0.4718 - val_accuracy: 0.7679 - lr: 1.0000e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.2796 - accuracy: 0.8786 - val_loss: 0.4650 - val_accuracy: 0.7946 - lr: 5.0000e-06\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.2799 - accuracy: 0.8786 - val_loss: 0.4887 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 16s 67ms/step - loss: 0.2589 - accuracy: 0.8982 - val_loss: 0.4743 - val_accuracy: 0.7589 - lr: 5.0000e-06\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 16s 68ms/step - loss: 0.2732 - accuracy: 0.8982 - val_loss: 0.4672 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 17s 68ms/step - loss: 0.2634 - accuracy: 0.8946 - val_loss: 0.5008 - val_accuracy: 0.7143 - lr: 5.0000e-06\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# === Eğitim Fonksiyonu ===\n",
    "def train_model(model, train_ds, val_ds, epochs, lr, freeze, freeze_ratio, class_weight=None):\n",
    "    if freeze:\n",
    "        freeze_densenet(model)\n",
    "    else:\n",
    "        unfreeze_densenet(model, 1 - freeze_ratio)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
    "    ]\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks, class_weight=class_weight, verbose=1)\n",
    "    return model\n",
    "\n",
    "# === Nested CV ve ROC Küsmi ===\n",
    "all_outer_results = defaultdict(list)\n",
    "outer_kf = GroupKFold(n_splits=num_outer_folds)\n",
    "for outer_i, (trainval_idx, test_idx) in enumerate(outer_kf.split(X_radiomics_all, y_all, groups=patient_ids_all), start=1):\n",
    "    for model_name, model_builder in model_builders.items():\n",
    "        print(f\"\\n=== Outer Fold {outer_i} | Model: {model_name} ===\")\n",
    "        X_tr_val_rad = X_radiomics_all[trainval_idx]; y_tr_val = y_all[trainval_idx]\n",
    "        X_test_rad   = X_radiomics_all[test_idx];     y_test    = y_all[test_idx]\n",
    "        paths_tr_val = img_paths_all[trainval_idx];   paths_test = img_paths_all[test_idx]\n",
    "        X_tr_val_sel, _, scaler, selector = radiomics_preprocessing(X_tr_val_rad, y_tr_val, k=k)\n",
    "        X_test_sc = scaler.transform(X_test_rad)\n",
    "        X_test_sel = selector.transform(X_test_sc)\n",
    "        groups_inner = patient_ids_all[trainval_idx]\n",
    "        inner_kf = GroupKFold(n_splits=num_inner_folds)\n",
    "        prev_weights = None\n",
    "        model = model_builder(num_radiomics=k, num_classes=2)\n",
    "\n",
    "        for inner_i, (tr_idx, val_idx) in enumerate(inner_kf.split(X_tr_val_sel, y_tr_val, groups=groups_inner), start=1):\n",
    "            X_tr_rad = X_tr_val_sel[tr_idx]; y_tr = y_tr_val[tr_idx]; p_tr = paths_tr_val[tr_idx]\n",
    "            X_val_rad = X_tr_val_sel[val_idx]; y_val = y_tr_val[val_idx]; p_val = paths_tr_val[val_idx]\n",
    "\n",
    "            if model_name in ['std_densenet', 'std_mobilenet']:\n",
    "                train_ds = create_augmented_dataset_single_input(p_tr, y_tr, batch_size=8, shuffle=True, augmentation=train_augs, n_augs=4)\n",
    "                val_ds = create_augmented_dataset_single_input(p_val, y_val, batch_size=8, shuffle=False, augmentation=val_augs, n_augs=1)\n",
    "            else:\n",
    "                train_ds = create_augmented_dataset(p_tr, X_tr_rad, y_tr, batch_size=8, shuffle=True, augmentation=train_augs, n_augs=4)\n",
    "                val_ds = create_augmented_dataset(p_val, X_val_rad, y_val, batch_size=8, shuffle=False, augmentation=val_augs, n_augs=1)\n",
    "\n",
    "            if inner_i > 1 and prev_weights is not None:\n",
    "                model.load_weights(prev_weights)\n",
    "\n",
    "            cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n",
    "            cw_dict = dict(enumerate(cw))\n",
    "\n",
    "            train_model(model, train_ds, val_ds, epochs=EP, lr=1e-4, freeze=True, freeze_ratio=1.0, class_weight=cw_dict)\n",
    "            train_model(model, train_ds, val_ds, epochs=EP, lr=1e-5, freeze=False, freeze_ratio=0.7, class_weight=cw_dict)\n",
    "\n",
    "            prev_weights = f\"model_{model_name}_outer{outer_i}_inner{inner_i}.h5\"\n",
    "            model.save_weights(prev_weights)\n",
    "\n",
    "        if model_name in ['std_densenet', 'std_mobilenet']:\n",
    "            test_ds = create_augmented_dataset_single_input(paths_test, y_test, batch_size=8, shuffle=False, augmentation=None, n_augs=0)\n",
    "        else:\n",
    "            test_ds = create_augmented_dataset(paths_test, X_test_sel, y_test, batch_size=8, shuffle=False, augmentation=None, n_augs=0)\n",
    "\n",
    "        preds, probs, labs = [], [], []\n",
    "        for (batch_in, batch_lab) in test_ds:\n",
    "            if model_name in ['std_densenet', 'std_mobilenet']:\n",
    "                imgs = batch_in  # Tek input\n",
    "                out = model.predict(imgs)\n",
    "            else:\n",
    "                imgs, rads = batch_in  # İki input\n",
    "                out = model.predict([imgs, rads])\n",
    "            probs.extend(out[:, 1])\n",
    "            preds.extend(np.argmax(out, axis=1))\n",
    "            labs.extend(batch_lab.numpy())\n",
    "\n",
    "        cm = confusion_matrix(labs, preds)\n",
    "        fpr, tpr, _ = roc_curve(labs, probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        acc = accuracy_score(labs, preds)\n",
    "        prec = precision_score(labs, preds, zero_division=0)\n",
    "        rec = recall_score(labs, preds, zero_division=0)\n",
    "        f1 = f1_score(labs, preds, zero_division=0)\n",
    "\n",
    "        all_outer_results[model_name].append({\n",
    "            'fold': outer_i,\n",
    "            'metrics': {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'auc': roc_auc},\n",
    "            'confusion_matrix': cm,\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr,\n",
    "            'labels': labs,\n",
    "            'preds': preds\n",
    "        })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Eğitim Fonksiyonu ===\n",
    "# def train_model(model, train_ds, val_ds, epochs, lr, freeze, freeze_ratio, class_weight=None):\n",
    "#     if freeze:\n",
    "#         freeze_densenet(model)\n",
    "#     else:\n",
    "#         unfreeze_densenet(model, 1 - freeze_ratio)\n",
    "#     model.compile(optimizer=keras.optimizers.Adam(lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     callbacks = [\n",
    "#         EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "#         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
    "#     ]\n",
    "#     model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks, class_weight=class_weight, verbose=1)\n",
    "#     return model\n",
    "\n",
    "# # === Nested CV ve ROC Küsmi ===\n",
    "# all_outer_results = defaultdict(list)\n",
    "# outer_kf = GroupKFold(n_splits=num_outer_folds)\n",
    "# for outer_i, (trainval_idx, test_idx) in enumerate(outer_kf.split(X_radiomics_all, y_all, groups=patient_ids_all), start=1):\n",
    "#     for model_name, model_builder in model_builders.items():\n",
    "#         print(f\"\\n=== Outer Fold {outer_i} | Model: {model_name} ===\")\n",
    "#         X_tr_val_rad = X_radiomics_all[trainval_idx]; y_tr_val = y_all[trainval_idx]\n",
    "#         X_test_rad   = X_radiomics_all[test_idx];     y_test    = y_all[test_idx]\n",
    "#         paths_tr_val = img_paths_all[trainval_idx];   paths_test = img_paths_all[test_idx]\n",
    "#         X_tr_val_sel, _, scaler, selector = radiomics_preprocessing(X_tr_val_rad, y_tr_val, k=k)\n",
    "#         X_test_sc = scaler.transform(X_test_rad)\n",
    "#         X_test_sel = selector.transform(X_test_sc)\n",
    "#         groups_inner = patient_ids_all[trainval_idx]\n",
    "#         inner_kf = GroupKFold(n_splits=num_inner_folds)\n",
    "#         prev_weights = None\n",
    "#         model = model_builder(num_radiomics=k, num_classes=2)\n",
    "#         for inner_i, (tr_idx, val_idx) in enumerate(inner_kf.split(X_tr_val_sel, y_tr_val, groups=groups_inner), start=1):\n",
    "#             X_tr_rad = X_tr_val_sel[tr_idx]; y_tr = y_tr_val[tr_idx]; p_tr = paths_tr_val[tr_idx]\n",
    "#             X_val_rad = X_tr_val_sel[val_idx]; y_val = y_tr_val[val_idx]; p_val = paths_tr_val[val_idx]\n",
    "#             # train_ds = create_augmented_dataset(p_tr, X_tr_rad, y_tr, batch_size=8, shuffle=True, augmentation=train_augs, n_augs=2)\n",
    "#             # val_ds = create_augmented_dataset(p_val, X_val_rad, y_val, batch_size=8, shuffle=False, augmentation=val_augs, n_augs=1)\n",
    " \n",
    "#             if model_name in ['std_densenet', 'std_mobilenet']:\n",
    "#                 train_ds = create_augmented_dataset_single_input(p_tr, y_tr, batch_size=8, shuffle=True, augmentation=train_augs, n_augs=2)\n",
    "#                 val_ds = create_augmented_dataset_single_input(p_val, y_val, batch_size=8, shuffle=False, augmentation=val_augs, n_augs=1)\n",
    "#             else:\n",
    "#                 train_ds = create_augmented_dataset(p_tr, X_tr_rad, y_tr, batch_size=8, shuffle=True, augmentation=train_augs, n_augs=2)\n",
    "#                 val_ds = create_augmented_dataset(p_val, X_val_rad, y_val, batch_size=8, shuffle=False, augmentation=val_augs, n_augs=1)\n",
    "\n",
    "  \n",
    "#             if inner_i > 1 and prev_weights is not None:\n",
    "#                 model.load_weights(prev_weights)\n",
    "#             cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n",
    "#             cw_dict = dict(enumerate(cw))\n",
    "#             train_model(model, train_ds, val_ds, epochs=EP, lr=1e-4, freeze=True, freeze_ratio=1.0, class_weight=cw_dict)\n",
    "#             train_model(model, train_ds, val_ds, epochs=EP, lr=1e-5, freeze=False, freeze_ratio=0.7, class_weight=cw_dict)\n",
    "#             prev_weights = f\"model_{model_name}_outer{outer_i}_inner{inner_i}.h5\"\n",
    "#             model.save_weights(prev_weights)\n",
    "#         if model_name in ['std_densenet', 'std_mobilenet']:\n",
    "#             test_ds = create_augmented_dataset_single_input(paths_test, y_test, batch_size=8, shuffle=False, augmentation=None, n_augs=0)\n",
    "#         else:\n",
    "#             test_ds = create_augmented_dataset(paths_test, X_test_sel, y_test, batch_size=8, shuffle=False, augmentation=None, n_augs=0)\n",
    "\n",
    "#         # test_ds = create_augmented_dataset(paths_test, X_test_sel, y_test, batch_size=8, shuffle=False, augmentation=None, n_augs=0)\n",
    "#         model.load_weights(prev_weights)\n",
    "#         preds, probs, labs = [], [], []\n",
    "#         for (batch_in, batch_lab) in test_ds:\n",
    "#             if model_name in ['std_densenet', 'std_mobilenet']:\n",
    "#                 imgs = batch_in  # Tek input\n",
    "#                 out = model.predict(imgs)\n",
    "#             else:\n",
    "#                 imgs, rads = batch_in  # İki input\n",
    "#                 out = model.predict([imgs, rads])        \n",
    "#             # imgs, rads = batch_in\n",
    "#             # out = model.predict((imgs, rads))\n",
    "#             probs.extend(out[:,1])\n",
    "#             preds.extend(np.argmax(out, axis=1))\n",
    "#             labs.extend(batch_lab.numpy())\n",
    "\n",
    "#         cm = confusion_matrix(labs, preds)\n",
    "#         fpr, tpr,_ = roc_curve(labs, probs)\n",
    "#         roc_auc = auc(fpr, tpr)\n",
    "#         acc = accuracy_score(labs, preds)\n",
    "#         prec = precision_score(labs, preds, zero_division=0)\n",
    "#         rec = recall_score(labs, preds, zero_division=0)\n",
    "#         f1 = f1_score(labs, preds, zero_division=0)\n",
    "\n",
    "#         all_outer_results[model_name].append({\n",
    "#             'fold': outer_i,\n",
    "#             'metrics': {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'auc': roc_auc},\n",
    "#             'confusion_matrix': cm,\n",
    "#             'fpr': fpr,\n",
    "#             'tpr': tpr,\n",
    "#             'labels': labs,\n",
    "#             'preds': preds\n",
    "#         })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Ortalama ROC Curve Çizimi (Tek grafikte) ===\n",
    "os.makedirs('roc_plots', exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for model_name, fold_results in all_outer_results.items():\n",
    "    all_fprs = [r['fpr'] for r in fold_results]\n",
    "    all_tprs = [r['tpr'] for r in fold_results]\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    interp_tprs = [np.interp(mean_fpr, fpr, tpr) for fpr, tpr in zip(all_fprs, all_tprs)]\n",
    "    mean_tpr = np.mean(interp_tprs, axis=0)\n",
    "    std_tpr = np.std(interp_tprs, axis=0)\n",
    "    \n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std([auc(fpr, tpr) for fpr, tpr in zip(all_fprs, all_tprs)])\n",
    "\n",
    "    plt.plot(mean_fpr, mean_tpr, lw=2,\n",
    "             label=f'{model_name} (AUC={mean_auc:.4f} ± {std_auc:.4f})')\n",
    "    plt.fill_between(mean_fpr, mean_tpr - std_tpr, mean_tpr + std_tpr, alpha=0.2)\n",
    "\n",
    "plt.title('Average ROC Curves ± Std for All Models', fontsize=20)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.savefig('roc_plots/avg_roc_all_models.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Ortalama ROC Curve Çizimi ===\n",
    "# os.makedirs('roc_plots', exist_ok=True)\n",
    "# for model_name, fold_results in all_outer_results.items():\n",
    "#     all_fprs = [r['fpr'] for r in fold_results]\n",
    "#     all_tprs = [r['tpr'] for r in fold_results]\n",
    "#     mean_fpr = np.linspace(0, 1, 100)\n",
    "#     interp_tprs = [np.interp(mean_fpr, fpr, tpr) for fpr, tpr in zip(all_fprs, all_tprs)]\n",
    "#     mean_tpr = np.mean(interp_tprs, axis=0)\n",
    "#     std_tpr = np.std(interp_tprs, axis=0)\n",
    "#     mean_auc = auc(mean_fpr, mean_tpr)\n",
    "#     std_auc = np.std([auc(fpr, tpr) for fpr, tpr in zip(all_fprs, all_tprs)])\n",
    "#     plt.figure(figsize=(14, 8))\n",
    "#     plt.plot(mean_fpr, mean_tpr, label=f'{model_name} Mean (AUC={mean_auc:.4f})', lw=2)\n",
    "#     plt.fill_between(mean_fpr, mean_tpr - std_tpr, mean_tpr + std_tpr, alpha=0.2)\n",
    "#     plt.title(f'Average ROC Curve ± Std — {model_name}', fontsize=20)\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.grid(True)\n",
    "#     plt.savefig(f'roc_plots/avg_roc_{model_name}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fold': 1,\n",
       "  'metrics': {'accuracy': 0.7857142857142857,\n",
       "   'precision': 0.8095238095238095,\n",
       "   'recall': 0.7727272727272727,\n",
       "   'f1': 0.7906976744186046,\n",
       "   'auc': 0.8613636363636363},\n",
       "  'confusion_matrix': array([[16,  4],\n",
       "         [ 5, 17]], dtype=int64),\n",
       "  'fpr': array([0.  , 0.  , 0.  , 0.05, 0.05, 0.1 , 0.1 , 0.2 , 0.2 , 0.5 , 0.5 ,\n",
       "         0.6 , 0.6 , 1.  ]),\n",
       "  'tpr': array([0.        , 0.04545455, 0.40909091, 0.40909091, 0.54545455,\n",
       "         0.54545455, 0.77272727, 0.77272727, 0.81818182, 0.81818182,\n",
       "         0.90909091, 0.90909091, 1.        , 1.        ]),\n",
       "  'labels': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'preds': [0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0]},\n",
       " {'fold': 2,\n",
       "  'metrics': {'accuracy': 0.7857142857142857,\n",
       "   'precision': 0.8095238095238095,\n",
       "   'recall': 0.7727272727272727,\n",
       "   'f1': 0.7906976744186046,\n",
       "   'auc': 0.8363636363636364},\n",
       "  'confusion_matrix': array([[16,  4],\n",
       "         [ 5, 17]], dtype=int64),\n",
       "  'fpr': array([0.  , 0.  , 0.  , 0.05, 0.05, 0.1 , 0.1 , 0.2 , 0.2 , 0.5 , 0.5 ,\n",
       "         0.55, 0.55, 0.6 , 0.6 , 0.8 , 0.8 , 1.  ]),\n",
       "  'tpr': array([0.        , 0.04545455, 0.40909091, 0.40909091, 0.63636364,\n",
       "         0.63636364, 0.72727273, 0.72727273, 0.77272727, 0.77272727,\n",
       "         0.86363636, 0.86363636, 0.90909091, 0.90909091, 0.95454545,\n",
       "         0.95454545, 1.        , 1.        ]),\n",
       "  'labels': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'preds': [0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1]},\n",
       " {'fold': 3,\n",
       "  'metrics': {'accuracy': 0.6666666666666666,\n",
       "   'precision': 0.625,\n",
       "   'recall': 0.75,\n",
       "   'f1': 0.6818181818181818,\n",
       "   'auc': 0.740909090909091},\n",
       "  'confusion_matrix': array([[13,  9],\n",
       "         [ 5, 15]], dtype=int64),\n",
       "  'fpr': array([0.        , 0.        , 0.        , 0.04545455, 0.04545455,\n",
       "         0.18181818, 0.18181818, 0.22727273, 0.22727273, 0.31818182,\n",
       "         0.31818182, 0.36363636, 0.36363636, 0.40909091, 0.40909091,\n",
       "         0.45454545, 0.45454545, 0.68181818, 0.68181818, 1.        ,\n",
       "         1.        ]),\n",
       "  'tpr': array([0.  , 0.05, 0.25, 0.25, 0.3 , 0.3 , 0.55, 0.55, 0.6 , 0.6 , 0.7 ,\n",
       "         0.7 , 0.75, 0.75, 0.8 , 0.8 , 0.9 , 0.9 , 0.95, 0.95, 1.  ]),\n",
       "  'labels': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'preds': [1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1]},\n",
       " {'fold': 4,\n",
       "  'metrics': {'accuracy': 0.6190476190476191,\n",
       "   'precision': 0.625,\n",
       "   'recall': 0.5,\n",
       "   'f1': 0.5555555555555556,\n",
       "   'auc': 0.7954545454545454},\n",
       "  'confusion_matrix': array([[16,  6],\n",
       "         [10, 10]], dtype=int64),\n",
       "  'fpr': array([0.        , 0.        , 0.        , 0.22727273, 0.22727273,\n",
       "         0.31818182, 0.31818182, 0.77272727, 0.77272727, 1.        ]),\n",
       "  'tpr': array([0.  , 0.05, 0.4 , 0.4 , 0.5 , 0.5 , 0.95, 0.95, 1.  , 1.  ]),\n",
       "  'labels': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'preds': [0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0]},\n",
       " {'fold': 5,\n",
       "  'metrics': {'accuracy': 0.575,\n",
       "   'precision': 0.5882352941176471,\n",
       "   'recall': 0.5,\n",
       "   'f1': 0.5405405405405406,\n",
       "   'auc': 0.7175},\n",
       "  'confusion_matrix': array([[13,  7],\n",
       "         [10, 10]], dtype=int64),\n",
       "  'fpr': array([0.  , 0.  , 0.  , 0.05, 0.05, 0.1 , 0.1 , 0.25, 0.25, 0.35, 0.35,\n",
       "         0.55, 0.55, 0.75, 0.75, 0.8 , 0.8 , 1.  ]),\n",
       "  'tpr': array([0.  , 0.05, 0.3 , 0.3 , 0.4 , 0.4 , 0.45, 0.45, 0.5 , 0.5 , 0.75,\n",
       "         0.75, 0.85, 0.85, 0.9 , 0.9 , 1.  , 1.  ]),\n",
       "  'labels': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'preds': [0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outer_results['att_densenet']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myworksv4_quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
